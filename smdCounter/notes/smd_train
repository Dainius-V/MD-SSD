root@MT-desktop:/jetson-inference/python/training/detection/ssd# python3 train_ssd.py --dataset-type=voc --data=data/smd --model-dir=models/smd --batch-size=2 --workers=1 --epochs=50                 
2021-05-21 19:23:29 - Using CUDA...
2021-05-21 19:23:29 - Namespace(balance_data=False, base_net=None, base_net_lr=0.001, batch_size=2, checkpoint_folder='models/smd', dataset_type='voc', datasets=['data/smd'], debug_steps=10, extra_layers_lr=None, freeze_base_net=False, freeze_net=False, gamma=0.1, lr=0.01, mb2_width_mult=1.0, milestones='80,100', momentum=0.9, net='mb1-ssd', num_epochs=50, num_workers=1, pretrained_ssd='models/mobilenet-v1-ssd-mp-0_675.pth', resume=None, scheduler='cosine', t_max=100, use_cuda=True, validation_epochs=1, weight_decay=0.0005)
2021-05-21 19:23:29 - Prepare training datasets.
2021-05-21 19:23:30 - VOC Labels read from file: ('BACKGROUND', 'Condensator', 'Resistor', 'Diode', 'Inductor', 'Transistor')
2021-05-21 19:23:30 - Stored labels into file models/smd/labels.txt.
2021-05-21 19:23:30 - Train dataset size: 1004
2021-05-21 19:23:30 - Prepare Validation datasets.
2021-05-21 19:23:31 - VOC Labels read from file: ('BACKGROUND', 'Condensator', 'Resistor', 'Diode', 'Inductor', 'Transistor')
2021-05-21 19:23:31 - Validation dataset size: 1004
2021-05-21 19:23:31 - Build network.
2021-05-21 19:23:31 - Init from pretrained ssd models/mobilenet-v1-ssd-mp-0_675.pth
2021-05-21 19:23:31 - Took 0.51 seconds to load the model.
2021-05-21 19:23:45 - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.
2021-05-21 19:23:45 - Uses CosineAnnealingLR scheduler.
2021-05-21 19:23:45 - Start training from epoch 0.
/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
2021-05-21 19:24:08 - Epoch: 0, Step: 10/502, Avg Loss: 21.4583, Avg Regression Loss 11.0046, Avg Classification Loss: 10.4537
2021-05-21 19:24:15 - Epoch: 0, Step: 20/502, Avg Loss: 15.3056, Avg Regression Loss 7.0698, Avg Classification Loss: 8.2358
2021-05-21 19:24:20 - Epoch: 0, Step: 30/502, Avg Loss: 16.5617, Avg Regression Loss 8.1606, Avg Classification Loss: 8.4011
2021-05-21 19:24:25 - Epoch: 0, Step: 40/502, Avg Loss: 10.3310, Avg Regression Loss 4.4367, Avg Classification Loss: 5.8944
2021-05-21 19:24:33 - Epoch: 0, Step: 50/502, Avg Loss: 11.3002, Avg Regression Loss 6.0897, Avg Classification Loss: 5.2105
2021-05-21 19:24:38 - Epoch: 0, Step: 60/502, Avg Loss: 12.2919, Avg Regression Loss 6.4960, Avg Classification Loss: 5.7959
2021-05-21 19:24:47 - Epoch: 0, Step: 70/502, Avg Loss: 11.8875, Avg Regression Loss 6.5577, Avg Classification Loss: 5.3299
2021-05-21 19:24:52 - Epoch: 0, Step: 80/502, Avg Loss: 12.4533, Avg Regression Loss 7.1113, Avg Classification Loss: 5.3420
2021-05-21 19:25:09 - Epoch: 0, Step: 90/502, Avg Loss: 13.9095, Avg Regression Loss 8.9871, Avg Classification Loss: 4.9224
2021-05-21 19:25:13 - Epoch: 0, Step: 100/502, Avg Loss: 9.7442, Avg Regression Loss 4.7454, Avg Classification Loss: 4.9988
2021-05-21 19:25:19 - Epoch: 0, Step: 110/502, Avg Loss: 11.1022, Avg Regression Loss 6.5666, Avg Classification Loss: 4.5356
2021-05-21 19:25:23 - Epoch: 0, Step: 120/502, Avg Loss: 9.8268, Avg Regression Loss 5.0643, Avg Classification Loss: 4.7626
2021-05-21 19:25:28 - Epoch: 0, Step: 130/502, Avg Loss: 10.7240, Avg Regression Loss 6.0842, Avg Classification Loss: 4.6398
2021-05-21 19:25:33 - Epoch: 0, Step: 140/502, Avg Loss: 10.0729, Avg Regression Loss 5.5722, Avg Classification Loss: 4.5007
2021-05-21 19:25:41 - Epoch: 0, Step: 150/502, Avg Loss: 9.8096, Avg Regression Loss 5.2940, Avg Classification Loss: 4.5156
2021-05-21 19:25:49 - Epoch: 0, Step: 160/502, Avg Loss: 11.7621, Avg Regression Loss 7.1748, Avg Classification Loss: 4.5873
2021-05-21 19:25:55 - Epoch: 0, Step: 170/502, Avg Loss: 9.5196, Avg Regression Loss 5.1194, Avg Classification Loss: 4.4002
2021-05-21 19:26:01 - Epoch: 0, Step: 180/502, Avg Loss: 12.1393, Avg Regression Loss 7.5910, Avg Classification Loss: 4.5483
2021-05-21 19:26:06 - Epoch: 0, Step: 190/502, Avg Loss: 9.6674, Avg Regression Loss 5.5227, Avg Classification Loss: 4.1447
2021-05-21 19:26:11 - Epoch: 0, Step: 200/502, Avg Loss: 8.9634, Avg Regression Loss 4.6569, Avg Classification Loss: 4.3065
2021-05-21 19:26:16 - Epoch: 0, Step: 210/502, Avg Loss: 9.4835, Avg Regression Loss 5.1267, Avg Classification Loss: 4.3568
2021-05-21 19:26:21 - Epoch: 0, Step: 220/502, Avg Loss: 9.5547, Avg Regression Loss 5.3977, Avg Classification Loss: 4.1570
2021-05-21 19:26:28 - Epoch: 0, Step: 230/502, Avg Loss: 11.1839, Avg Regression Loss 6.4223, Avg Classification Loss: 4.7616
2021-05-21 19:26:33 - Epoch: 0, Step: 240/502, Avg Loss: 9.1298, Avg Regression Loss 4.7778, Avg Classification Loss: 4.3520
2021-05-21 19:26:38 - Epoch: 0, Step: 250/502, Avg Loss: 9.3190, Avg Regression Loss 5.1822, Avg Classification Loss: 4.1368
2021-05-21 19:26:44 - Epoch: 0, Step: 260/502, Avg Loss: 9.7347, Avg Regression Loss 5.5382, Avg Classification Loss: 4.1964
2021-05-21 19:26:49 - Epoch: 0, Step: 270/502, Avg Loss: 9.0007, Avg Regression Loss 4.9647, Avg Classification Loss: 4.0360
2021-05-21 19:26:54 - Epoch: 0, Step: 280/502, Avg Loss: 9.6452, Avg Regression Loss 5.5579, Avg Classification Loss: 4.0873
2021-05-21 19:26:58 - Epoch: 0, Step: 290/502, Avg Loss: 7.7432, Avg Regression Loss 3.7927, Avg Classification Loss: 3.9505
2021-05-21 19:27:06 - Epoch: 0, Step: 300/502, Avg Loss: 8.7122, Avg Regression Loss 4.5778, Avg Classification Loss: 4.1344
2021-05-21 19:27:11 - Epoch: 0, Step: 310/502, Avg Loss: 8.1207, Avg Regression Loss 4.2151, Avg Classification Loss: 3.9056
2021-05-21 19:27:16 - Epoch: 0, Step: 320/502, Avg Loss: 8.6511, Avg Regression Loss 4.4667, Avg Classification Loss: 4.1844
2021-05-21 19:27:20 - Epoch: 0, Step: 330/502, Avg Loss: 8.2146, Avg Regression Loss 4.3914, Avg Classification Loss: 3.8233
2021-05-21 19:27:25 - Epoch: 0, Step: 340/502, Avg Loss: 7.9371, Avg Regression Loss 4.0954, Avg Classification Loss: 3.8418
2021-05-21 19:27:31 - Epoch: 0, Step: 350/502, Avg Loss: 8.2528, Avg Regression Loss 4.3797, Avg Classification Loss: 3.8731
2021-05-21 19:27:36 - Epoch: 0, Step: 360/502, Avg Loss: 8.2614, Avg Regression Loss 4.2985, Avg Classification Loss: 3.9630
2021-05-21 19:27:45 - Epoch: 0, Step: 370/502, Avg Loss: 8.4676, Avg Regression Loss 4.6521, Avg Classification Loss: 3.8155
2021-05-21 19:27:49 - Epoch: 0, Step: 380/502, Avg Loss: 8.7178, Avg Regression Loss 4.7953, Avg Classification Loss: 3.9225
2021-05-21 19:27:55 - Epoch: 0, Step: 390/502, Avg Loss: 8.4801, Avg Regression Loss 4.4750, Avg Classification Loss: 4.0051
2021-05-21 19:28:00 - Epoch: 0, Step: 400/502, Avg Loss: 8.5375, Avg Regression Loss 4.5452, Avg Classification Loss: 3.9923
2021-05-21 19:28:06 - Epoch: 0, Step: 410/502, Avg Loss: 7.1453, Avg Regression Loss 3.3159, Avg Classification Loss: 3.8294
2021-05-21 19:28:12 - Epoch: 0, Step: 420/502, Avg Loss: 9.2303, Avg Regression Loss 4.7236, Avg Classification Loss: 4.5067
2021-05-21 19:28:16 - Epoch: 0, Step: 430/502, Avg Loss: 7.5553, Avg Regression Loss 3.6930, Avg Classification Loss: 3.8623
2021-05-21 19:28:21 - Epoch: 0, Step: 440/502, Avg Loss: 8.7060, Avg Regression Loss 4.8229, Avg Classification Loss: 3.8831
2021-05-21 19:28:25 - Epoch: 0, Step: 450/502, Avg Loss: 7.6749, Avg Regression Loss 3.9270, Avg Classification Loss: 3.7479
2021-05-21 19:28:31 - Epoch: 0, Step: 460/502, Avg Loss: 9.0664, Avg Regression Loss 4.9312, Avg Classification Loss: 4.1352
2021-05-21 19:28:36 - Epoch: 0, Step: 470/502, Avg Loss: 7.7723, Avg Regression Loss 3.9249, Avg Classification Loss: 3.8474
2021-05-21 19:28:41 - Epoch: 0, Step: 480/502, Avg Loss: 8.3652, Avg Regression Loss 4.4224, Avg Classification Loss: 3.9427
2021-05-21 19:28:46 - Epoch: 0, Step: 490/502, Avg Loss: 8.5048, Avg Regression Loss 4.5422, Avg Classification Loss: 3.9626
2021-05-21 19:28:51 - Epoch: 0, Step: 500/502, Avg Loss: 7.4867, Avg Regression Loss 3.4549, Avg Classification Loss: 4.0318
2021-05-21 19:29:52 - Epoch: 0, Validation Loss: 6.8266, Validation Regression Loss 3.0012, Validation Classification Loss: 3.8254
2021-05-21 19:29:52 - Saved model models/smd/mb1-ssd-Epoch-0-Loss-6.826609945392229.pth
2021-05-21 19:30:05 - Epoch: 1, Step: 10/502, Avg Loss: 9.4427, Avg Regression Loss 5.0241, Avg Classification Loss: 4.4186
2021-05-21 19:30:11 - Epoch: 1, Step: 20/502, Avg Loss: 8.5084, Avg Regression Loss 4.4573, Avg Classification Loss: 4.0511
2021-05-21 19:30:18 - Epoch: 1, Step: 30/502, Avg Loss: 6.7600, Avg Regression Loss 2.9745, Avg Classification Loss: 3.7855
2021-05-21 19:30:23 - Epoch: 1, Step: 40/502, Avg Loss: 8.0452, Avg Regression Loss 3.9914, Avg Classification Loss: 4.0538
2021-05-21 19:30:28 - Epoch: 1, Step: 50/502, Avg Loss: 6.7516, Avg Regression Loss 3.1471, Avg Classification Loss: 3.6044
2021-05-21 19:30:33 - Epoch: 1, Step: 60/502, Avg Loss: 7.4513, Avg Regression Loss 3.6985, Avg Classification Loss: 3.7528
2021-05-21 19:30:38 - Epoch: 1, Step: 70/502, Avg Loss: 7.9979, Avg Regression Loss 4.0643, Avg Classification Loss: 3.9336
2021-05-21 19:30:48 - Epoch: 1, Step: 80/502, Avg Loss: 8.2696, Avg Regression Loss 4.4108, Avg Classification Loss: 3.8587
2021-05-21 19:30:53 - Epoch: 1, Step: 90/502, Avg Loss: 8.8141, Avg Regression Loss 4.8923, Avg Classification Loss: 3.9217
2021-05-21 19:30:58 - Epoch: 1, Step: 100/502, Avg Loss: 6.4120, Avg Regression Loss 2.7746, Avg Classification Loss: 3.6374
2021-05-21 19:31:09 - Epoch: 1, Step: 110/502, Avg Loss: 7.1803, Avg Regression Loss 3.4956, Avg Classification Loss: 3.6847
2021-05-21 19:31:20 - Epoch: 1, Step: 120/502, Avg Loss: 8.6648, Avg Regression Loss 4.7016, Avg Classification Loss: 3.9632
2021-05-21 19:31:24 - Epoch: 1, Step: 130/502, Avg Loss: 8.1018, Avg Regression Loss 4.1456, Avg Classification Loss: 3.9562
2021-05-21 19:31:29 - Epoch: 1, Step: 140/502, Avg Loss: 7.6828, Avg Regression Loss 3.8026, Avg Classification Loss: 3.8802
2021-05-21 19:31:42 - Epoch: 1, Step: 150/502, Avg Loss: 7.7927, Avg Regression Loss 3.9851, Avg Classification Loss: 3.8077
2021-05-21 19:31:47 - Epoch: 1, Step: 160/502, Avg Loss: 8.2607, Avg Regression Loss 4.3471, Avg Classification Loss: 3.9136
2021-05-21 19:31:53 - Epoch: 1, Step: 170/502, Avg Loss: 8.5989, Avg Regression Loss 4.5867, Avg Classification Loss: 4.0122
2021-05-21 19:31:58 - Epoch: 1, Step: 180/502, Avg Loss: 7.1052, Avg Regression Loss 3.3721, Avg Classification Loss: 3.7331
2021-05-21 19:32:04 - Epoch: 1, Step: 190/502, Avg Loss: 5.9234, Avg Regression Loss 2.1982, Avg Classification Loss: 3.7252
2021-05-21 19:32:09 - Epoch: 1, Step: 200/502, Avg Loss: 7.5198, Avg Regression Loss 3.6448, Avg Classification Loss: 3.8750
2021-05-21 19:32:13 - Epoch: 1, Step: 210/502, Avg Loss: 7.1640, Avg Regression Loss 3.5472, Avg Classification Loss: 3.6167
2021-05-21 19:32:19 - Epoch: 1, Step: 220/502, Avg Loss: 7.8891, Avg Regression Loss 4.3333, Avg Classification Loss: 3.5558
2021-05-21 19:32:23 - Epoch: 1, Step: 230/502, Avg Loss: 7.6707, Avg Regression Loss 3.7369, Avg Classification Loss: 3.9337
2021-05-21 19:32:28 - Epoch: 1, Step: 240/502, Avg Loss: 6.3226, Avg Regression Loss 2.6417, Avg Classification Loss: 3.6808
2021-05-21 19:32:33 - Epoch: 1, Step: 250/502, Avg Loss: 7.3235, Avg Regression Loss 3.5437, Avg Classification Loss: 3.7798
2021-05-21 19:32:38 - Epoch: 1, Step: 260/502, Avg Loss: 6.2048, Avg Regression Loss 2.5273, Avg Classification Loss: 3.6776
2021-05-21 19:32:43 - Epoch: 1, Step: 270/502, Avg Loss: 8.4799, Avg Regression Loss 4.5209, Avg Classification Loss: 3.9590
2021-05-21 19:32:48 - Epoch: 1, Step: 280/502, Avg Loss: 6.9545, Avg Regression Loss 3.1991, Avg Classification Loss: 3.7554
2021-05-21 19:32:53 - Epoch: 1, Step: 290/502, Avg Loss: 7.3424, Avg Regression Loss 3.6878, Avg Classification Loss: 3.6546
2021-05-21 19:33:04 - Epoch: 1, Step: 300/502, Avg Loss: 7.9604, Avg Regression Loss 3.9696, Avg Classification Loss: 3.9909
2021-05-21 19:33:09 - Epoch: 1, Step: 310/502, Avg Loss: 7.1399, Avg Regression Loss 3.5183, Avg Classification Loss: 3.6216
2021-05-21 19:33:14 - Epoch: 1, Step: 320/502, Avg Loss: 7.1856, Avg Regression Loss 3.4950, Avg Classification Loss: 3.6905
2021-05-21 19:33:19 - Epoch: 1, Step: 330/502, Avg Loss: 6.4153, Avg Regression Loss 2.7817, Avg Classification Loss: 3.6335
2021-05-21 19:33:25 - Epoch: 1, Step: 340/502, Avg Loss: 7.7499, Avg Regression Loss 3.9095, Avg Classification Loss: 3.8404
2021-05-21 19:33:29 - Epoch: 1, Step: 350/502, Avg Loss: 7.3069, Avg Regression Loss 3.7259, Avg Classification Loss: 3.5810
2021-05-21 19:33:35 - Epoch: 1, Step: 360/502, Avg Loss: 8.2088, Avg Regression Loss 4.4253, Avg Classification Loss: 3.7835
2021-05-21 19:33:40 - Epoch: 1, Step: 370/502, Avg Loss: 7.1375, Avg Regression Loss 3.1042, Avg Classification Loss: 4.0333
2021-05-21 19:33:46 - Epoch: 1, Step: 380/502, Avg Loss: 7.0522, Avg Regression Loss 3.2433, Avg Classification Loss: 3.8089
2021-05-21 19:33:52 - Epoch: 1, Step: 390/502, Avg Loss: 7.6969, Avg Regression Loss 3.9847, Avg Classification Loss: 3.7122
2021-05-21 19:33:57 - Epoch: 1, Step: 400/502, Avg Loss: 7.8796, Avg Regression Loss 4.0808, Avg Classification Loss: 3.7988
2021-05-21 19:34:02 - Epoch: 1, Step: 410/502, Avg Loss: 7.0264, Avg Regression Loss 3.1969, Avg Classification Loss: 3.8296
2021-05-21 19:34:07 - Epoch: 1, Step: 420/502, Avg Loss: 7.3353, Avg Regression Loss 3.6462, Avg Classification Loss: 3.6892
2021-05-21 19:34:12 - Epoch: 1, Step: 430/502, Avg Loss: 7.2904, Avg Regression Loss 3.6215, Avg Classification Loss: 3.6690
2021-05-21 19:34:17 - Epoch: 1, Step: 440/502, Avg Loss: 6.6143, Avg Regression Loss 3.0482, Avg Classification Loss: 3.5660
2021-05-21 19:34:22 - Epoch: 1, Step: 450/502, Avg Loss: 8.7304, Avg Regression Loss 4.9961, Avg Classification Loss: 3.7343
2021-05-21 19:34:26 - Epoch: 1, Step: 460/502, Avg Loss: 7.6158, Avg Regression Loss 3.7933, Avg Classification Loss: 3.8225
2021-05-21 19:34:32 - Epoch: 1, Step: 470/502, Avg Loss: 8.4930, Avg Regression Loss 4.7108, Avg Classification Loss: 3.7822
2021-05-21 19:34:37 - Epoch: 1, Step: 480/502, Avg Loss: 7.6190, Avg Regression Loss 3.8238, Avg Classification Loss: 3.7952
2021-05-21 19:34:41 - Epoch: 1, Step: 490/502, Avg Loss: 7.6747, Avg Regression Loss 3.8286, Avg Classification Loss: 3.8461
2021-05-21 19:34:46 - Epoch: 1, Step: 500/502, Avg Loss: 6.5163, Avg Regression Loss 2.7236, Avg Classification Loss: 3.7927
2021-05-21 19:35:48 - Epoch: 1, Validation Loss: 5.7144, Validation Regression Loss 2.1412, Validation Classification Loss: 3.5732
2021-05-21 19:35:48 - Saved model models/smd/mb1-ssd-Epoch-1-Loss-5.714429534763929.pth
2021-05-21 19:35:56 - Epoch: 2, Step: 10/502, Avg Loss: 7.0719, Avg Regression Loss 3.1816, Avg Classification Loss: 3.8903
2021-05-21 19:36:04 - Epoch: 2, Step: 20/502, Avg Loss: 7.5555, Avg Regression Loss 3.6933, Avg Classification Loss: 3.8623
2021-05-21 19:36:13 - Epoch: 2, Step: 30/502, Avg Loss: 6.5416, Avg Regression Loss 2.7621, Avg Classification Loss: 3.7795
2021-05-21 19:36:18 - Epoch: 2, Step: 40/502, Avg Loss: 6.0910, Avg Regression Loss 2.5125, Avg Classification Loss: 3.5784
2021-05-21 19:36:22 - Epoch: 2, Step: 50/502, Avg Loss: 6.0509, Avg Regression Loss 2.3777, Avg Classification Loss: 3.6732
2021-05-21 19:36:27 - Epoch: 2, Step: 60/502, Avg Loss: 7.4203, Avg Regression Loss 3.6506, Avg Classification Loss: 3.7697
2021-05-21 19:36:31 - Epoch: 2, Step: 70/502, Avg Loss: 7.4992, Avg Regression Loss 3.8212, Avg Classification Loss: 3.6780
2021-05-21 19:36:36 - Epoch: 2, Step: 80/502, Avg Loss: 7.2315, Avg Regression Loss 3.4928, Avg Classification Loss: 3.7387
2021-05-21 19:36:41 - Epoch: 2, Step: 90/502, Avg Loss: 6.9984, Avg Regression Loss 3.3722, Avg Classification Loss: 3.6262
2021-05-21 19:37:00 - Epoch: 2, Step: 100/502, Avg Loss: 7.2900, Avg Regression Loss 3.5675, Avg Classification Loss: 3.7225
2021-05-21 19:37:05 - Epoch: 2, Step: 110/502, Avg Loss: 7.6997, Avg Regression Loss 3.9487, Avg Classification Loss: 3.7511
2021-05-21 19:37:12 - Epoch: 2, Step: 120/502, Avg Loss: 7.0616, Avg Regression Loss 3.3788, Avg Classification Loss: 3.6829
2021-05-21 19:37:16 - Epoch: 2, Step: 130/502, Avg Loss: 7.0723, Avg Regression Loss 3.3545, Avg Classification Loss: 3.7178
2021-05-21 19:37:22 - Epoch: 2, Step: 140/502, Avg Loss: 6.3633, Avg Regression Loss 2.6984, Avg Classification Loss: 3.6649
2021-05-21 19:37:27 - Epoch: 2, Step: 150/502, Avg Loss: 7.8601, Avg Regression Loss 4.0967, Avg Classification Loss: 3.7634
2021-05-21 19:37:32 - Epoch: 2, Step: 160/502, Avg Loss: 7.9109, Avg Regression Loss 4.1327, Avg Classification Loss: 3.7782
2021-05-21 19:37:37 - Epoch: 2, Step: 170/502, Avg Loss: 6.5027, Avg Regression Loss 2.9195, Avg Classification Loss: 3.5833
2021-05-21 19:37:42 - Epoch: 2, Step: 180/502, Avg Loss: 6.5517, Avg Regression Loss 2.9257, Avg Classification Loss: 3.6260
2021-05-21 19:37:46 - Epoch: 2, Step: 190/502, Avg Loss: 6.0869, Avg Regression Loss 2.4108, Avg Classification Loss: 3.6761
2021-05-21 19:37:52 - Epoch: 2, Step: 200/502, Avg Loss: 7.3005, Avg Regression Loss 3.6200, Avg Classification Loss: 3.6805
2021-05-21 19:37:58 - Epoch: 2, Step: 210/502, Avg Loss: 6.9334, Avg Regression Loss 3.3267, Avg Classification Loss: 3.6067
2021-05-21 19:38:03 - Epoch: 2, Step: 220/502, Avg Loss: 6.3429, Avg Regression Loss 2.6897, Avg Classification Loss: 3.6532
2021-05-21 19:38:08 - Epoch: 2, Step: 230/502, Avg Loss: 5.8851, Avg Regression Loss 2.3573, Avg Classification Loss: 3.5278
2021-05-21 19:38:12 - Epoch: 2, Step: 240/502, Avg Loss: 6.4323, Avg Regression Loss 2.7911, Avg Classification Loss: 3.6412
2021-05-21 19:38:17 - Epoch: 2, Step: 250/502, Avg Loss: 6.4060, Avg Regression Loss 2.8378, Avg Classification Loss: 3.5682
2021-05-21 19:38:23 - Epoch: 2, Step: 260/502, Avg Loss: 6.2868, Avg Regression Loss 2.5987, Avg Classification Loss: 3.6882
2021-05-21 19:38:28 - Epoch: 2, Step: 270/502, Avg Loss: 6.3932, Avg Regression Loss 2.6015, Avg Classification Loss: 3.7917
2021-05-21 19:38:32 - Epoch: 2, Step: 280/502, Avg Loss: 6.7771, Avg Regression Loss 3.1103, Avg Classification Loss: 3.6668
2021-05-21 19:38:37 - Epoch: 2, Step: 290/502, Avg Loss: 6.7137, Avg Regression Loss 2.8266, Avg Classification Loss: 3.8871
2021-05-21 19:38:42 - Epoch: 2, Step: 300/502, Avg Loss: 7.0492, Avg Regression Loss 3.3821, Avg Classification Loss: 3.6671
2021-05-21 19:38:46 - Epoch: 2, Step: 310/502, Avg Loss: 6.4539, Avg Regression Loss 2.6872, Avg Classification Loss: 3.7667
2021-05-21 19:38:51 - Epoch: 2, Step: 320/502, Avg Loss: 6.3652, Avg Regression Loss 2.9440, Avg Classification Loss: 3.4212
2021-05-21 19:39:00 - Epoch: 2, Step: 330/502, Avg Loss: 5.8405, Avg Regression Loss 2.3581, Avg Classification Loss: 3.4824
2021-05-21 19:39:05 - Epoch: 2, Step: 340/502, Avg Loss: 6.4216, Avg Regression Loss 2.7339, Avg Classification Loss: 3.6877
2021-05-21 19:39:11 - Epoch: 2, Step: 350/502, Avg Loss: 6.6677, Avg Regression Loss 3.0915, Avg Classification Loss: 3.5762
2021-05-21 19:39:16 - Epoch: 2, Step: 360/502, Avg Loss: 6.6777, Avg Regression Loss 2.8742, Avg Classification Loss: 3.8036
2021-05-21 19:39:26 - Epoch: 2, Step: 370/502, Avg Loss: 7.1085, Avg Regression Loss 3.4940, Avg Classification Loss: 3.6145
2021-05-21 19:39:31 - Epoch: 2, Step: 380/502, Avg Loss: 6.7994, Avg Regression Loss 3.0700, Avg Classification Loss: 3.7293
2021-05-21 19:39:38 - Epoch: 2, Step: 390/502, Avg Loss: 6.5398, Avg Regression Loss 2.8315, Avg Classification Loss: 3.7083
2021-05-21 19:39:43 - Epoch: 2, Step: 400/502, Avg Loss: 6.8622, Avg Regression Loss 3.3498, Avg Classification Loss: 3.5124
2021-05-21 19:39:48 - Epoch: 2, Step: 410/502, Avg Loss: 6.7625, Avg Regression Loss 3.1003, Avg Classification Loss: 3.6622
2021-05-21 19:39:54 - Epoch: 2, Step: 420/502, Avg Loss: 6.7514, Avg Regression Loss 3.1110, Avg Classification Loss: 3.6405
2021-05-21 19:39:59 - Epoch: 2, Step: 430/502, Avg Loss: 6.7835, Avg Regression Loss 3.0792, Avg Classification Loss: 3.7042
2021-05-21 19:40:03 - Epoch: 2, Step: 440/502, Avg Loss: 6.7909, Avg Regression Loss 3.0765, Avg Classification Loss: 3.7144
2021-05-21 19:40:08 - Epoch: 2, Step: 450/502, Avg Loss: 6.3196, Avg Regression Loss 2.8457, Avg Classification Loss: 3.4739
2021-05-21 19:40:13 - Epoch: 2, Step: 460/502, Avg Loss: 6.7289, Avg Regression Loss 3.0460, Avg Classification Loss: 3.6829
2021-05-21 19:40:18 - Epoch: 2, Step: 470/502, Avg Loss: 7.2253, Avg Regression Loss 3.5594, Avg Classification Loss: 3.6660
2021-05-21 19:40:23 - Epoch: 2, Step: 480/502, Avg Loss: 7.2246, Avg Regression Loss 3.6973, Avg Classification Loss: 3.5273
2021-05-21 19:40:28 - Epoch: 2, Step: 490/502, Avg Loss: 6.8476, Avg Regression Loss 2.7651, Avg Classification Loss: 4.0824
2021-05-21 19:40:33 - Epoch: 2, Step: 500/502, Avg Loss: 6.0780, Avg Regression Loss 2.5192, Avg Classification Loss: 3.5588
2021-05-21 19:41:34 - Epoch: 2, Validation Loss: 5.6762, Validation Regression Loss 2.0247, Validation Classification Loss: 3.6515
2021-05-21 19:41:34 - Saved model models/smd/mb1-ssd-Epoch-2-Loss-5.676214711124678.pth
2021-05-21 19:41:40 - Epoch: 3, Step: 10/502, Avg Loss: 7.9935, Avg Regression Loss 3.9205, Avg Classification Loss: 4.0731
2021-05-21 19:41:45 - Epoch: 3, Step: 20/502, Avg Loss: 7.1337, Avg Regression Loss 3.4772, Avg Classification Loss: 3.6566
2021-05-21 19:41:52 - Epoch: 3, Step: 30/502, Avg Loss: 7.1464, Avg Regression Loss 3.1058, Avg Classification Loss: 4.0406
2021-05-21 19:41:57 - Epoch: 3, Step: 40/502, Avg Loss: 6.1084, Avg Regression Loss 2.4673, Avg Classification Loss: 3.6411
2021-05-21 19:42:02 - Epoch: 3, Step: 50/502, Avg Loss: 7.0709, Avg Regression Loss 3.4848, Avg Classification Loss: 3.5862
2021-05-21 19:42:07 - Epoch: 3, Step: 60/502, Avg Loss: 6.8049, Avg Regression Loss 3.0226, Avg Classification Loss: 3.7823
2021-05-21 19:42:11 - Epoch: 3, Step: 70/502, Avg Loss: 5.9803, Avg Regression Loss 2.4791, Avg Classification Loss: 3.5012
2021-05-21 19:42:18 - Epoch: 3, Step: 80/502, Avg Loss: 7.1023, Avg Regression Loss 3.5329, Avg Classification Loss: 3.5694
2021-05-21 19:42:25 - Epoch: 3, Step: 90/502, Avg Loss: 7.7324, Avg Regression Loss 4.1897, Avg Classification Loss: 3.5427
2021-05-21 19:42:31 - Epoch: 3, Step: 100/502, Avg Loss: 6.2514, Avg Regression Loss 2.4760, Avg Classification Loss: 3.7753
2021-05-21 19:42:41 - Epoch: 3, Step: 110/502, Avg Loss: 6.6977, Avg Regression Loss 2.9387, Avg Classification Loss: 3.7590
2021-05-21 19:42:46 - Epoch: 3, Step: 120/502, Avg Loss: 6.8969, Avg Regression Loss 3.1810, Avg Classification Loss: 3.7158
2021-05-21 19:42:51 - Epoch: 3, Step: 130/502, Avg Loss: 6.5117, Avg Regression Loss 2.8556, Avg Classification Loss: 3.6561
2021-05-21 19:42:56 - Epoch: 3, Step: 140/502, Avg Loss: 5.8715, Avg Regression Loss 2.2150, Avg Classification Loss: 3.6565
2021-05-21 19:43:10 - Epoch: 3, Step: 150/502, Avg Loss: 6.8226, Avg Regression Loss 2.9951, Avg Classification Loss: 3.8275
2021-05-21 19:43:16 - Epoch: 3, Step: 160/502, Avg Loss: 7.3107, Avg Regression Loss 3.4722, Avg Classification Loss: 3.8385
2021-05-21 19:43:21 - Epoch: 3, Step: 170/502, Avg Loss: 7.6590, Avg Regression Loss 4.0560, Avg Classification Loss: 3.6030
2021-05-21 19:43:26 - Epoch: 3, Step: 180/502, Avg Loss: 6.5362, Avg Regression Loss 2.9219, Avg Classification Loss: 3.6143
2021-05-21 19:43:31 - Epoch: 3, Step: 190/502, Avg Loss: 6.8114, Avg Regression Loss 3.1750, Avg Classification Loss: 3.6364
2021-05-21 19:43:36 - Epoch: 3, Step: 200/502, Avg Loss: 6.0226, Avg Regression Loss 2.5179, Avg Classification Loss: 3.5046
2021-05-21 19:43:41 - Epoch: 3, Step: 210/502, Avg Loss: 6.2194, Avg Regression Loss 2.7739, Avg Classification Loss: 3.4455
2021-05-21 19:43:47 - Epoch: 3, Step: 220/502, Avg Loss: 7.1560, Avg Regression Loss 3.2801, Avg Classification Loss: 3.8759
2021-05-21 19:43:52 - Epoch: 3, Step: 230/502, Avg Loss: 8.1798, Avg Regression Loss 4.3581, Avg Classification Loss: 3.8216
2021-05-21 19:43:56 - Epoch: 3, Step: 240/502, Avg Loss: 5.6331, Avg Regression Loss 1.8403, Avg Classification Loss: 3.7928
2021-05-21 19:44:01 - Epoch: 3, Step: 250/502, Avg Loss: 6.5204, Avg Regression Loss 2.9325, Avg Classification Loss: 3.5880
2021-05-21 19:44:08 - Epoch: 3, Step: 260/502, Avg Loss: 6.9686, Avg Regression Loss 3.3397, Avg Classification Loss: 3.6289
2021-05-21 19:44:13 - Epoch: 3, Step: 270/502, Avg Loss: 6.0631, Avg Regression Loss 2.4972, Avg Classification Loss: 3.5659
2021-05-21 19:44:18 - Epoch: 3, Step: 280/502, Avg Loss: 6.9100, Avg Regression Loss 3.2702, Avg Classification Loss: 3.6397
2021-05-21 19:44:31 - Epoch: 3, Step: 290/502, Avg Loss: 7.5160, Avg Regression Loss 3.7800, Avg Classification Loss: 3.7360
2021-05-21 19:44:36 - Epoch: 3, Step: 300/502, Avg Loss: 7.0296, Avg Regression Loss 3.3796, Avg Classification Loss: 3.6500
2021-05-21 19:44:42 - Epoch: 3, Step: 310/502, Avg Loss: 6.3142, Avg Regression Loss 2.8263, Avg Classification Loss: 3.4878
2021-05-21 19:44:46 - Epoch: 3, Step: 320/502, Avg Loss: 5.6083, Avg Regression Loss 2.1666, Avg Classification Loss: 3.4417
2021-05-21 19:44:51 - Epoch: 3, Step: 330/502, Avg Loss: 5.7477, Avg Regression Loss 2.0628, Avg Classification Loss: 3.6849
2021-05-21 19:44:56 - Epoch: 3, Step: 340/502, Avg Loss: 7.2578, Avg Regression Loss 3.7743, Avg Classification Loss: 3.4835
2021-05-21 19:45:00 - Epoch: 3, Step: 350/502, Avg Loss: 6.2875, Avg Regression Loss 2.8453, Avg Classification Loss: 3.4422
2021-05-21 19:45:10 - Epoch: 3, Step: 360/502, Avg Loss: 6.5983, Avg Regression Loss 3.0368, Avg Classification Loss: 3.5615
2021-05-21 19:45:15 - Epoch: 3, Step: 370/502, Avg Loss: 6.4342, Avg Regression Loss 2.8124, Avg Classification Loss: 3.6218
2021-05-21 19:45:20 - Epoch: 3, Step: 380/502, Avg Loss: 5.9008, Avg Regression Loss 2.3009, Avg Classification Loss: 3.5998
2021-05-21 19:45:25 - Epoch: 3, Step: 390/502, Avg Loss: 6.5336, Avg Regression Loss 2.8303, Avg Classification Loss: 3.7032
2021-05-21 19:45:30 - Epoch: 3, Step: 400/502, Avg Loss: 6.3021, Avg Regression Loss 2.7230, Avg Classification Loss: 3.5791
2021-05-21 19:45:35 - Epoch: 3, Step: 410/502, Avg Loss: 5.6249, Avg Regression Loss 2.2279, Avg Classification Loss: 3.3970
2021-05-21 19:45:40 - Epoch: 3, Step: 420/502, Avg Loss: 6.3843, Avg Regression Loss 2.7014, Avg Classification Loss: 3.6829
2021-05-21 19:45:44 - Epoch: 3, Step: 430/502, Avg Loss: 6.0490, Avg Regression Loss 2.3272, Avg Classification Loss: 3.7217
2021-05-21 19:45:50 - Epoch: 3, Step: 440/502, Avg Loss: 6.3117, Avg Regression Loss 2.8130, Avg Classification Loss: 3.4988
2021-05-21 19:45:54 - Epoch: 3, Step: 450/502, Avg Loss: 5.9499, Avg Regression Loss 2.4990, Avg Classification Loss: 3.4509
2021-05-21 19:46:00 - Epoch: 3, Step: 460/502, Avg Loss: 7.0138, Avg Regression Loss 3.3611, Avg Classification Loss: 3.6527
2021-05-21 19:46:04 - Epoch: 3, Step: 470/502, Avg Loss: 6.4212, Avg Regression Loss 2.6799, Avg Classification Loss: 3.7413
2021-05-21 19:46:09 - Epoch: 3, Step: 480/502, Avg Loss: 6.0488, Avg Regression Loss 2.4819, Avg Classification Loss: 3.5670
2021-05-21 19:46:15 - Epoch: 3, Step: 490/502, Avg Loss: 6.5574, Avg Regression Loss 2.9076, Avg Classification Loss: 3.6498
2021-05-21 19:46:20 - Epoch: 3, Step: 500/502, Avg Loss: 6.8690, Avg Regression Loss 3.2096, Avg Classification Loss: 3.6594
2021-05-21 19:47:20 - Epoch: 3, Validation Loss: 5.9725, Validation Regression Loss 2.3964, Validation Classification Loss: 3.5761
2021-05-21 19:47:20 - Saved model models/smd/mb1-ssd-Epoch-3-Loss-5.972537411636566.pth
2021-05-21 19:47:26 - Epoch: 4, Step: 10/502, Avg Loss: 7.6796, Avg Regression Loss 3.5366, Avg Classification Loss: 4.1430
2021-05-21 19:47:38 - Epoch: 4, Step: 20/502, Avg Loss: 7.7910, Avg Regression Loss 4.2695, Avg Classification Loss: 3.5215
2021-05-21 19:47:43 - Epoch: 4, Step: 30/502, Avg Loss: 6.6752, Avg Regression Loss 3.1416, Avg Classification Loss: 3.5336
2021-05-21 19:47:48 - Epoch: 4, Step: 40/502, Avg Loss: 6.6049, Avg Regression Loss 2.8867, Avg Classification Loss: 3.7182
2021-05-21 19:47:53 - Epoch: 4, Step: 50/502, Avg Loss: 6.8175, Avg Regression Loss 3.1987, Avg Classification Loss: 3.6187
2021-05-21 19:47:59 - Epoch: 4, Step: 60/502, Avg Loss: 6.8739, Avg Regression Loss 3.2072, Avg Classification Loss: 3.6667
2021-05-21 19:48:04 - Epoch: 4, Step: 70/502, Avg Loss: 6.0659, Avg Regression Loss 2.5146, Avg Classification Loss: 3.5514
2021-05-21 19:48:08 - Epoch: 4, Step: 80/502, Avg Loss: 6.7349, Avg Regression Loss 3.0753, Avg Classification Loss: 3.6596
2021-05-21 19:48:13 - Epoch: 4, Step: 90/502, Avg Loss: 6.2964, Avg Regression Loss 2.7772, Avg Classification Loss: 3.5192
2021-05-21 19:48:39 - Epoch: 4, Step: 100/502, Avg Loss: 6.9565, Avg Regression Loss 3.3640, Avg Classification Loss: 3.5925
2021-05-21 19:48:45 - Epoch: 4, Step: 110/502, Avg Loss: 6.5862, Avg Regression Loss 2.9274, Avg Classification Loss: 3.6587
2021-05-21 19:48:50 - Epoch: 4, Step: 120/502, Avg Loss: 7.3326, Avg Regression Loss 3.4493, Avg Classification Loss: 3.8833
2021-05-21 19:48:55 - Epoch: 4, Step: 130/502, Avg Loss: 6.4878, Avg Regression Loss 2.8907, Avg Classification Loss: 3.5971
2021-05-21 19:49:01 - Epoch: 4, Step: 140/502, Avg Loss: 6.9563, Avg Regression Loss 3.1748, Avg Classification Loss: 3.7815
2021-05-21 19:49:05 - Epoch: 4, Step: 150/502, Avg Loss: 6.0174, Avg Regression Loss 2.4107, Avg Classification Loss: 3.6067
2021-05-21 19:49:15 - Epoch: 4, Step: 160/502, Avg Loss: 6.9437, Avg Regression Loss 3.2524, Avg Classification Loss: 3.6913
2021-05-21 19:49:23 - Epoch: 4, Step: 170/502, Avg Loss: 7.3422, Avg Regression Loss 3.5106, Avg Classification Loss: 3.8316
2021-05-21 19:49:28 - Epoch: 4, Step: 180/502, Avg Loss: 6.1221, Avg Regression Loss 2.6146, Avg Classification Loss: 3.5075
2021-05-21 19:49:33 - Epoch: 4, Step: 190/502, Avg Loss: 5.7099, Avg Regression Loss 2.2759, Avg Classification Loss: 3.4341
2021-05-21 19:49:37 - Epoch: 4, Step: 200/502, Avg Loss: 5.9439, Avg Regression Loss 2.3271, Avg Classification Loss: 3.6169
2021-05-21 19:49:45 - Epoch: 4, Step: 210/502, Avg Loss: 6.6769, Avg Regression Loss 3.2195, Avg Classification Loss: 3.4574
2021-05-21 19:49:52 - Epoch: 4, Step: 220/502, Avg Loss: 6.2932, Avg Regression Loss 2.7281, Avg Classification Loss: 3.5651
2021-05-21 19:49:58 - Epoch: 4, Step: 230/502, Avg Loss: 5.8755, Avg Regression Loss 2.3693, Avg Classification Loss: 3.5062
2021-05-21 19:50:03 - Epoch: 4, Step: 240/502, Avg Loss: 6.3271, Avg Regression Loss 2.8477, Avg Classification Loss: 3.4794
2021-05-21 19:50:08 - Epoch: 4, Step: 250/502, Avg Loss: 6.4150, Avg Regression Loss 2.7627, Avg Classification Loss: 3.6523
2021-05-21 19:50:13 - Epoch: 4, Step: 260/502, Avg Loss: 6.3209, Avg Regression Loss 2.8452, Avg Classification Loss: 3.4757
2021-05-21 19:50:18 - Epoch: 4, Step: 270/502, Avg Loss: 6.3190, Avg Regression Loss 2.4616, Avg Classification Loss: 3.8575
2021-05-21 19:50:22 - Epoch: 4, Step: 280/502, Avg Loss: 5.8908, Avg Regression Loss 2.2710, Avg Classification Loss: 3.6199
2021-05-21 19:50:27 - Epoch: 4, Step: 290/502, Avg Loss: 6.4801, Avg Regression Loss 2.8383, Avg Classification Loss: 3.6419
2021-05-21 19:50:33 - Epoch: 4, Step: 300/502, Avg Loss: 6.8204, Avg Regression Loss 3.2657, Avg Classification Loss: 3.5547
2021-05-21 19:50:37 - Epoch: 4, Step: 310/502, Avg Loss: 6.0033, Avg Regression Loss 2.4568, Avg Classification Loss: 3.5464
2021-05-21 19:50:43 - Epoch: 4, Step: 320/502, Avg Loss: 5.7688, Avg Regression Loss 2.1843, Avg Classification Loss: 3.5845
2021-05-21 19:50:47 - Epoch: 4, Step: 330/502, Avg Loss: 6.0598, Avg Regression Loss 2.5496, Avg Classification Loss: 3.5102
2021-05-21 19:50:52 - Epoch: 4, Step: 340/502, Avg Loss: 5.8437, Avg Regression Loss 2.1383, Avg Classification Loss: 3.7055
2021-05-21 19:50:57 - Epoch: 4, Step: 350/502, Avg Loss: 5.8962, Avg Regression Loss 2.4624, Avg Classification Loss: 3.4338
2021-05-21 19:51:16 - Epoch: 4, Step: 360/502, Avg Loss: 7.7917, Avg Regression Loss 4.0195, Avg Classification Loss: 3.7722
2021-05-21 19:51:22 - Epoch: 4, Step: 370/502, Avg Loss: 6.3343, Avg Regression Loss 2.6296, Avg Classification Loss: 3.7048
2021-05-21 19:51:27 - Epoch: 4, Step: 380/502, Avg Loss: 6.1280, Avg Regression Loss 2.3367, Avg Classification Loss: 3.7913
2021-05-21 19:51:31 - Epoch: 4, Step: 390/502, Avg Loss: 6.3909, Avg Regression Loss 2.8336, Avg Classification Loss: 3.5573
2021-05-21 19:51:36 - Epoch: 4, Step: 400/502, Avg Loss: 6.4853, Avg Regression Loss 2.6880, Avg Classification Loss: 3.7974
2021-05-21 19:51:41 - Epoch: 4, Step: 410/502, Avg Loss: 6.1964, Avg Regression Loss 2.7427, Avg Classification Loss: 3.4537
2021-05-21 19:51:47 - Epoch: 4, Step: 420/502, Avg Loss: 5.7488, Avg Regression Loss 2.1372, Avg Classification Loss: 3.6116
2021-05-21 19:51:52 - Epoch: 4, Step: 430/502, Avg Loss: 5.8425, Avg Regression Loss 2.2257, Avg Classification Loss: 3.6168
2021-05-21 19:51:57 - Epoch: 4, Step: 440/502, Avg Loss: 5.7495, Avg Regression Loss 2.2501, Avg Classification Loss: 3.4995
2021-05-21 19:52:01 - Epoch: 4, Step: 450/502, Avg Loss: 6.9786, Avg Regression Loss 3.2732, Avg Classification Loss: 3.7055
2021-05-21 19:52:07 - Epoch: 4, Step: 460/502, Avg Loss: 7.3355, Avg Regression Loss 3.7445, Avg Classification Loss: 3.5910
2021-05-21 19:52:12 - Epoch: 4, Step: 470/502, Avg Loss: 5.5401, Avg Regression Loss 2.0529, Avg Classification Loss: 3.4872
2021-05-21 19:52:17 - Epoch: 4, Step: 480/502, Avg Loss: 6.1378, Avg Regression Loss 2.4420, Avg Classification Loss: 3.6958
2021-05-21 19:52:22 - Epoch: 4, Step: 490/502, Avg Loss: 5.7742, Avg Regression Loss 2.3328, Avg Classification Loss: 3.4415
2021-05-21 19:52:27 - Epoch: 4, Step: 500/502, Avg Loss: 6.2999, Avg Regression Loss 2.7144, Avg Classification Loss: 3.5855
2021-05-21 19:53:28 - Epoch: 4, Validation Loss: 5.4330, Validation Regression Loss 1.9377, Validation Classification Loss: 3.4953
2021-05-21 19:53:29 - Saved model models/smd/mb1-ssd-Epoch-4-Loss-5.432980457625066.pth
2021-05-21 19:53:35 - Epoch: 5, Step: 10/502, Avg Loss: 6.9757, Avg Regression Loss 2.9757, Avg Classification Loss: 3.9999
2021-05-21 19:53:40 - Epoch: 5, Step: 20/502, Avg Loss: 6.7269, Avg Regression Loss 2.9508, Avg Classification Loss: 3.7761
2021-05-21 19:53:46 - Epoch: 5, Step: 30/502, Avg Loss: 6.6618, Avg Regression Loss 2.8094, Avg Classification Loss: 3.8524
2021-05-21 19:53:52 - Epoch: 5, Step: 40/502, Avg Loss: 5.4899, Avg Regression Loss 2.0536, Avg Classification Loss: 3.4363
2021-05-21 19:53:57 - Epoch: 5, Step: 50/502, Avg Loss: 5.9826, Avg Regression Loss 2.3554, Avg Classification Loss: 3.6271
2021-05-21 19:54:02 - Epoch: 5, Step: 60/502, Avg Loss: 5.5323, Avg Regression Loss 2.1615, Avg Classification Loss: 3.3708
2021-05-21 19:54:07 - Epoch: 5, Step: 70/502, Avg Loss: 5.6832, Avg Regression Loss 2.2742, Avg Classification Loss: 3.4090
2021-05-21 19:54:14 - Epoch: 5, Step: 80/502, Avg Loss: 5.7233, Avg Regression Loss 2.1540, Avg Classification Loss: 3.5693
2021-05-21 19:54:19 - Epoch: 5, Step: 90/502, Avg Loss: 6.2879, Avg Regression Loss 2.5645, Avg Classification Loss: 3.7234
2021-05-21 19:54:23 - Epoch: 5, Step: 100/502, Avg Loss: 5.5344, Avg Regression Loss 1.9468, Avg Classification Loss: 3.5876
2021-05-21 19:54:28 - Epoch: 5, Step: 110/502, Avg Loss: 5.4397, Avg Regression Loss 1.7184, Avg Classification Loss: 3.7214
2021-05-21 19:54:33 - Epoch: 5, Step: 120/502, Avg Loss: 5.8498, Avg Regression Loss 2.2156, Avg Classification Loss: 3.6342
2021-05-21 19:54:38 - Epoch: 5, Step: 130/502, Avg Loss: 6.5585, Avg Regression Loss 3.0181, Avg Classification Loss: 3.5404
2021-05-21 19:54:43 - Epoch: 5, Step: 140/502, Avg Loss: 6.4529, Avg Regression Loss 2.9302, Avg Classification Loss: 3.5227
2021-05-21 19:55:02 - Epoch: 5, Step: 150/502, Avg Loss: 8.4838, Avg Regression Loss 4.8235, Avg Classification Loss: 3.6604
2021-05-21 19:55:07 - Epoch: 5, Step: 160/502, Avg Loss: 7.2040, Avg Regression Loss 3.3512, Avg Classification Loss: 3.8528
2021-05-21 19:55:15 - Epoch: 5, Step: 170/502, Avg Loss: 7.0768, Avg Regression Loss 3.5061, Avg Classification Loss: 3.5708
2021-05-21 19:55:20 - Epoch: 5, Step: 180/502, Avg Loss: 5.9941, Avg Regression Loss 2.3352, Avg Classification Loss: 3.6589
2021-05-21 19:55:25 - Epoch: 5, Step: 190/502, Avg Loss: 6.2941, Avg Regression Loss 2.8011, Avg Classification Loss: 3.4930
2021-05-21 19:55:30 - Epoch: 5, Step: 200/502, Avg Loss: 5.4438, Avg Regression Loss 1.8136, Avg Classification Loss: 3.6302
2021-05-21 19:55:35 - Epoch: 5, Step: 210/502, Avg Loss: 6.4730, Avg Regression Loss 2.8624, Avg Classification Loss: 3.6106
2021-05-21 19:55:41 - Epoch: 5, Step: 220/502, Avg Loss: 5.7565, Avg Regression Loss 2.1263, Avg Classification Loss: 3.6302
2021-05-21 19:55:46 - Epoch: 5, Step: 230/502, Avg Loss: 6.0455, Avg Regression Loss 2.4389, Avg Classification Loss: 3.6066
2021-05-21 19:55:51 - Epoch: 5, Step: 240/502, Avg Loss: 5.6001, Avg Regression Loss 1.8967, Avg Classification Loss: 3.7034
2021-05-21 19:55:56 - Epoch: 5, Step: 250/502, Avg Loss: 6.2264, Avg Regression Loss 2.6461, Avg Classification Loss: 3.5803
2021-05-21 19:56:01 - Epoch: 5, Step: 260/502, Avg Loss: 6.3012, Avg Regression Loss 2.6781, Avg Classification Loss: 3.6231
2021-05-21 19:56:11 - Epoch: 5, Step: 270/502, Avg Loss: 5.6131, Avg Regression Loss 2.1376, Avg Classification Loss: 3.4755
2021-05-21 19:56:16 - Epoch: 5, Step: 280/502, Avg Loss: 6.0905, Avg Regression Loss 2.5851, Avg Classification Loss: 3.5054
2021-05-21 19:56:21 - Epoch: 5, Step: 290/502, Avg Loss: 6.2014, Avg Regression Loss 2.6573, Avg Classification Loss: 3.5440
2021-05-21 19:56:31 - Epoch: 5, Step: 300/502, Avg Loss: 5.6126, Avg Regression Loss 1.9901, Avg Classification Loss: 3.6226
2021-05-21 19:56:36 - Epoch: 5, Step: 310/502, Avg Loss: 5.6880, Avg Regression Loss 2.0898, Avg Classification Loss: 3.5982
2021-05-21 19:56:41 - Epoch: 5, Step: 320/502, Avg Loss: 6.5441, Avg Regression Loss 3.0271, Avg Classification Loss: 3.5169
2021-05-21 19:56:46 - Epoch: 5, Step: 330/502, Avg Loss: 5.3426, Avg Regression Loss 1.9868, Avg Classification Loss: 3.3558
2021-05-21 19:56:51 - Epoch: 5, Step: 340/502, Avg Loss: 6.2514, Avg Regression Loss 2.7472, Avg Classification Loss: 3.5042
2021-05-21 19:56:55 - Epoch: 5, Step: 350/502, Avg Loss: 6.5147, Avg Regression Loss 2.7352, Avg Classification Loss: 3.7795
2021-05-21 19:57:02 - Epoch: 5, Step: 360/502, Avg Loss: 6.7271, Avg Regression Loss 3.0771, Avg Classification Loss: 3.6499
2021-05-21 19:57:07 - Epoch: 5, Step: 370/502, Avg Loss: 7.2147, Avg Regression Loss 3.4249, Avg Classification Loss: 3.7898
2021-05-21 19:57:13 - Epoch: 5, Step: 380/502, Avg Loss: 6.2189, Avg Regression Loss 2.6524, Avg Classification Loss: 3.5665
2021-05-21 19:57:18 - Epoch: 5, Step: 390/502, Avg Loss: 6.9686, Avg Regression Loss 3.4343, Avg Classification Loss: 3.5343
2021-05-21 19:57:23 - Epoch: 5, Step: 400/502, Avg Loss: 5.7470, Avg Regression Loss 2.2664, Avg Classification Loss: 3.4806
2021-05-21 19:57:28 - Epoch: 5, Step: 410/502, Avg Loss: 5.7783, Avg Regression Loss 2.2656, Avg Classification Loss: 3.5127
2021-05-21 19:57:34 - Epoch: 5, Step: 420/502, Avg Loss: 6.0516, Avg Regression Loss 2.4798, Avg Classification Loss: 3.5718
2021-05-21 19:57:39 - Epoch: 5, Step: 430/502, Avg Loss: 5.6108, Avg Regression Loss 2.0113, Avg Classification Loss: 3.5995
2021-05-21 19:57:45 - Epoch: 5, Step: 440/502, Avg Loss: 7.1175, Avg Regression Loss 3.4371, Avg Classification Loss: 3.6804
2021-05-21 19:57:49 - Epoch: 5, Step: 450/502, Avg Loss: 5.4448, Avg Regression Loss 1.8397, Avg Classification Loss: 3.6052
2021-05-21 19:57:54 - Epoch: 5, Step: 460/502, Avg Loss: 5.6919, Avg Regression Loss 2.1273, Avg Classification Loss: 3.5646
2021-05-21 19:57:58 - Epoch: 5, Step: 470/502, Avg Loss: 5.7494, Avg Regression Loss 2.2361, Avg Classification Loss: 3.5133
2021-05-21 19:58:03 - Epoch: 5, Step: 480/502, Avg Loss: 6.5127, Avg Regression Loss 3.0300, Avg Classification Loss: 3.4827
2021-05-21 19:58:11 - Epoch: 5, Step: 490/502, Avg Loss: 6.0792, Avg Regression Loss 2.5308, Avg Classification Loss: 3.5484
2021-05-21 19:58:16 - Epoch: 5, Step: 500/502, Avg Loss: 5.4343, Avg Regression Loss 1.9461, Avg Classification Loss: 3.4882
2021-05-21 19:59:17 - Epoch: 5, Validation Loss: 4.8954, Validation Regression Loss 1.4855, Validation Classification Loss: 3.4099
2021-05-21 19:59:17 - Saved model models/smd/mb1-ssd-Epoch-5-Loss-4.895376493731343.pth
2021-05-21 19:59:23 - Epoch: 6, Step: 10/502, Avg Loss: 6.2297, Avg Regression Loss 2.3391, Avg Classification Loss: 3.8906
2021-05-21 19:59:29 - Epoch: 6, Step: 20/502, Avg Loss: 5.6075, Avg Regression Loss 1.9853, Avg Classification Loss: 3.6222
2021-05-21 19:59:34 - Epoch: 6, Step: 30/502, Avg Loss: 5.5983, Avg Regression Loss 2.1205, Avg Classification Loss: 3.4778
2021-05-21 19:59:40 - Epoch: 6, Step: 40/502, Avg Loss: 6.3393, Avg Regression Loss 2.6937, Avg Classification Loss: 3.6456
2021-05-21 19:59:45 - Epoch: 6, Step: 50/502, Avg Loss: 5.7217, Avg Regression Loss 2.1138, Avg Classification Loss: 3.6080
2021-05-21 19:59:50 - Epoch: 6, Step: 60/502, Avg Loss: 6.1937, Avg Regression Loss 2.7158, Avg Classification Loss: 3.4779
2021-05-21 19:59:57 - Epoch: 6, Step: 70/502, Avg Loss: 7.1273, Avg Regression Loss 3.4860, Avg Classification Loss: 3.6413
2021-05-21 20:00:03 - Epoch: 6, Step: 80/502, Avg Loss: 6.1745, Avg Regression Loss 2.8140, Avg Classification Loss: 3.3606
2021-05-21 20:00:14 - Epoch: 6, Step: 90/502, Avg Loss: 6.1013, Avg Regression Loss 2.5608, Avg Classification Loss: 3.5405
2021-05-21 20:00:19 - Epoch: 6, Step: 100/502, Avg Loss: 6.6461, Avg Regression Loss 2.9572, Avg Classification Loss: 3.6888
2021-05-21 20:00:25 - Epoch: 6, Step: 110/502, Avg Loss: 5.8124, Avg Regression Loss 2.1974, Avg Classification Loss: 3.6150
2021-05-21 20:00:29 - Epoch: 6, Step: 120/502, Avg Loss: 5.9929, Avg Regression Loss 2.4043, Avg Classification Loss: 3.5886
2021-05-21 20:00:35 - Epoch: 6, Step: 130/502, Avg Loss: 5.5619, Avg Regression Loss 2.1264, Avg Classification Loss: 3.4355
2021-05-21 20:00:39 - Epoch: 6, Step: 140/502, Avg Loss: 6.6390, Avg Regression Loss 2.8729, Avg Classification Loss: 3.7661
2021-05-21 20:00:44 - Epoch: 6, Step: 150/502, Avg Loss: 5.9856, Avg Regression Loss 2.1894, Avg Classification Loss: 3.7962
2021-05-21 20:00:49 - Epoch: 6, Step: 160/502, Avg Loss: 6.0425, Avg Regression Loss 2.4215, Avg Classification Loss: 3.6210
2021-05-21 20:00:54 - Epoch: 6, Step: 170/502, Avg Loss: 5.6687, Avg Regression Loss 1.9556, Avg Classification Loss: 3.7131
2021-05-21 20:00:58 - Epoch: 6, Step: 180/502, Avg Loss: 5.5825, Avg Regression Loss 2.0225, Avg Classification Loss: 3.5600
2021-05-21 20:01:03 - Epoch: 6, Step: 190/502, Avg Loss: 5.5912, Avg Regression Loss 1.9548, Avg Classification Loss: 3.6364
2021-05-21 20:01:08 - Epoch: 6, Step: 200/502, Avg Loss: 5.6791, Avg Regression Loss 2.1647, Avg Classification Loss: 3.5144
2021-05-21 20:01:19 - Epoch: 6, Step: 210/502, Avg Loss: 6.2808, Avg Regression Loss 2.5251, Avg Classification Loss: 3.7557
2021-05-21 20:01:24 - Epoch: 6, Step: 220/502, Avg Loss: 5.8047, Avg Regression Loss 2.3986, Avg Classification Loss: 3.4061
2021-05-21 20:01:29 - Epoch: 6, Step: 230/502, Avg Loss: 5.8175, Avg Regression Loss 2.3722, Avg Classification Loss: 3.4453
2021-05-21 20:01:34 - Epoch: 6, Step: 240/502, Avg Loss: 5.7546, Avg Regression Loss 2.1998, Avg Classification Loss: 3.5548
2021-05-21 20:01:39 - Epoch: 6, Step: 250/502, Avg Loss: 5.8041, Avg Regression Loss 2.3052, Avg Classification Loss: 3.4989
2021-05-21 20:01:51 - Epoch: 6, Step: 260/502, Avg Loss: 5.9199, Avg Regression Loss 2.2945, Avg Classification Loss: 3.6254
2021-05-21 20:02:00 - Epoch: 6, Step: 270/502, Avg Loss: 6.0698, Avg Regression Loss 2.3216, Avg Classification Loss: 3.7482
2021-05-21 20:02:04 - Epoch: 6, Step: 280/502, Avg Loss: 6.3252, Avg Regression Loss 2.7347, Avg Classification Loss: 3.5905
2021-05-21 20:02:09 - Epoch: 6, Step: 290/502, Avg Loss: 4.8957, Avg Regression Loss 1.4522, Avg Classification Loss: 3.4435
2021-05-21 20:02:16 - Epoch: 6, Step: 300/502, Avg Loss: 5.5135, Avg Regression Loss 2.0396, Avg Classification Loss: 3.4739
2021-05-21 20:02:21 - Epoch: 6, Step: 310/502, Avg Loss: 5.2003, Avg Regression Loss 1.6571, Avg Classification Loss: 3.5432
2021-05-21 20:02:25 - Epoch: 6, Step: 320/502, Avg Loss: 5.7049, Avg Regression Loss 1.9854, Avg Classification Loss: 3.7195
2021-05-21 20:02:32 - Epoch: 6, Step: 330/502, Avg Loss: 5.5209, Avg Regression Loss 1.9209, Avg Classification Loss: 3.6000
2021-05-21 20:02:37 - Epoch: 6, Step: 340/502, Avg Loss: 6.0964, Avg Regression Loss 2.4399, Avg Classification Loss: 3.6564
2021-05-21 20:02:42 - Epoch: 6, Step: 350/502, Avg Loss: 5.4969, Avg Regression Loss 2.0713, Avg Classification Loss: 3.4256
2021-05-21 20:02:47 - Epoch: 6, Step: 360/502, Avg Loss: 6.0570, Avg Regression Loss 2.4390, Avg Classification Loss: 3.6180
2021-05-21 20:02:51 - Epoch: 6, Step: 370/502, Avg Loss: 6.0428, Avg Regression Loss 2.4115, Avg Classification Loss: 3.6313
2021-05-21 20:02:57 - Epoch: 6, Step: 380/502, Avg Loss: 6.1632, Avg Regression Loss 2.5937, Avg Classification Loss: 3.5696
2021-05-21 20:03:02 - Epoch: 6, Step: 390/502, Avg Loss: 5.6084, Avg Regression Loss 2.1463, Avg Classification Loss: 3.4621
2021-05-21 20:03:07 - Epoch: 6, Step: 400/502, Avg Loss: 6.2805, Avg Regression Loss 2.6149, Avg Classification Loss: 3.6656
2021-05-21 20:03:13 - Epoch: 6, Step: 410/502, Avg Loss: 6.0205, Avg Regression Loss 2.5491, Avg Classification Loss: 3.4714
2021-05-21 20:03:17 - Epoch: 6, Step: 420/502, Avg Loss: 5.7541, Avg Regression Loss 2.2568, Avg Classification Loss: 3.4973
2021-05-21 20:03:23 - Epoch: 6, Step: 430/502, Avg Loss: 6.7299, Avg Regression Loss 3.3365, Avg Classification Loss: 3.3935
2021-05-21 20:03:28 - Epoch: 6, Step: 440/502, Avg Loss: 5.8727, Avg Regression Loss 2.2063, Avg Classification Loss: 3.6664
2021-05-21 20:03:33 - Epoch: 6, Step: 450/502, Avg Loss: 5.0139, Avg Regression Loss 1.5237, Avg Classification Loss: 3.4903
2021-05-21 20:03:42 - Epoch: 6, Step: 460/502, Avg Loss: 6.0162, Avg Regression Loss 2.4581, Avg Classification Loss: 3.5580
2021-05-21 20:03:46 - Epoch: 6, Step: 470/502, Avg Loss: 5.8370, Avg Regression Loss 2.4235, Avg Classification Loss: 3.4135
2021-05-21 20:03:51 - Epoch: 6, Step: 480/502, Avg Loss: 6.3988, Avg Regression Loss 2.7728, Avg Classification Loss: 3.6260
2021-05-21 20:03:56 - Epoch: 6, Step: 490/502, Avg Loss: 5.5716, Avg Regression Loss 2.1061, Avg Classification Loss: 3.4655
2021-05-21 20:04:00 - Epoch: 6, Step: 500/502, Avg Loss: 5.8888, Avg Regression Loss 2.4219, Avg Classification Loss: 3.4668
2021-05-21 20:05:02 - Epoch: 6, Validation Loss: 4.9786, Validation Regression Loss 1.4606, Validation Classification Loss: 3.5180
2021-05-21 20:05:02 - Saved model models/smd/mb1-ssd-Epoch-6-Loss-4.978620377669771.pth
2021-05-21 20:05:08 - Epoch: 7, Step: 10/502, Avg Loss: 6.7321, Avg Regression Loss 2.8168, Avg Classification Loss: 3.9153
2021-05-21 20:05:14 - Epoch: 7, Step: 20/502, Avg Loss: 6.2195, Avg Regression Loss 2.7227, Avg Classification Loss: 3.4967
2021-05-21 20:05:19 - Epoch: 7, Step: 30/502, Avg Loss: 5.9195, Avg Regression Loss 2.5020, Avg Classification Loss: 3.4175
2021-05-21 20:05:25 - Epoch: 7, Step: 40/502, Avg Loss: 6.0197, Avg Regression Loss 2.4855, Avg Classification Loss: 3.5342
2021-05-21 20:05:30 - Epoch: 7, Step: 50/502, Avg Loss: 4.7574, Avg Regression Loss 1.2562, Avg Classification Loss: 3.5012
2021-05-21 20:05:36 - Epoch: 7, Step: 60/502, Avg Loss: 5.5346, Avg Regression Loss 2.0603, Avg Classification Loss: 3.4743
2021-05-21 20:05:41 - Epoch: 7, Step: 70/502, Avg Loss: 6.5972, Avg Regression Loss 2.9620, Avg Classification Loss: 3.6353
2021-05-21 20:05:46 - Epoch: 7, Step: 80/502, Avg Loss: 5.5609, Avg Regression Loss 1.8923, Avg Classification Loss: 3.6686
2021-05-21 20:05:53 - Epoch: 7, Step: 90/502, Avg Loss: 5.6062, Avg Regression Loss 2.0007, Avg Classification Loss: 3.6055
2021-05-21 20:06:03 - Epoch: 7, Step: 100/502, Avg Loss: 5.7897, Avg Regression Loss 2.2311, Avg Classification Loss: 3.5586
2021-05-21 20:06:21 - Epoch: 7, Step: 110/502, Avg Loss: 6.7355, Avg Regression Loss 3.1508, Avg Classification Loss: 3.5847
2021-05-21 20:06:28 - Epoch: 7, Step: 120/502, Avg Loss: 5.5473, Avg Regression Loss 1.9996, Avg Classification Loss: 3.5476
2021-05-21 20:06:32 - Epoch: 7, Step: 130/502, Avg Loss: 6.5826, Avg Regression Loss 2.8464, Avg Classification Loss: 3.7363
2021-05-21 20:06:37 - Epoch: 7, Step: 140/502, Avg Loss: 5.2508, Avg Regression Loss 1.5633, Avg Classification Loss: 3.6875
2021-05-21 20:06:46 - Epoch: 7, Step: 150/502, Avg Loss: 6.4781, Avg Regression Loss 2.7545, Avg Classification Loss: 3.7235
2021-05-21 20:06:50 - Epoch: 7, Step: 160/502, Avg Loss: 6.9365, Avg Regression Loss 3.0370, Avg Classification Loss: 3.8995
2021-05-21 20:06:55 - Epoch: 7, Step: 170/502, Avg Loss: 6.1115, Avg Regression Loss 2.4436, Avg Classification Loss: 3.6678
2021-05-21 20:07:00 - Epoch: 7, Step: 180/502, Avg Loss: 6.0730, Avg Regression Loss 2.4706, Avg Classification Loss: 3.6025
2021-05-21 20:07:04 - Epoch: 7, Step: 190/502, Avg Loss: 6.0388, Avg Regression Loss 2.6507, Avg Classification Loss: 3.3881
2021-05-21 20:07:10 - Epoch: 7, Step: 200/502, Avg Loss: 6.3627, Avg Regression Loss 2.9648, Avg Classification Loss: 3.3979
2021-05-21 20:07:14 - Epoch: 7, Step: 210/502, Avg Loss: 6.0855, Avg Regression Loss 2.6931, Avg Classification Loss: 3.3924
2021-05-21 20:07:20 - Epoch: 7, Step: 220/502, Avg Loss: 6.6926, Avg Regression Loss 3.0654, Avg Classification Loss: 3.6271
2021-05-21 20:07:25 - Epoch: 7, Step: 230/502, Avg Loss: 5.9279, Avg Regression Loss 2.3003, Avg Classification Loss: 3.6277
2021-05-21 20:07:29 - Epoch: 7, Step: 240/502, Avg Loss: 5.9039, Avg Regression Loss 2.3305, Avg Classification Loss: 3.5735
2021-05-21 20:07:37 - Epoch: 7, Step: 250/502, Avg Loss: 5.0916, Avg Regression Loss 1.6682, Avg Classification Loss: 3.4233
2021-05-21 20:07:45 - Epoch: 7, Step: 260/502, Avg Loss: 5.5532, Avg Regression Loss 2.0423, Avg Classification Loss: 3.5109
2021-05-21 20:07:50 - Epoch: 7, Step: 270/502, Avg Loss: 5.4181, Avg Regression Loss 1.9607, Avg Classification Loss: 3.4574
2021-05-21 20:07:54 - Epoch: 7, Step: 280/502, Avg Loss: 6.3033, Avg Regression Loss 2.5441, Avg Classification Loss: 3.7592
2021-05-21 20:07:59 - Epoch: 7, Step: 290/502, Avg Loss: 6.5368, Avg Regression Loss 2.8630, Avg Classification Loss: 3.6738
2021-05-21 20:08:05 - Epoch: 7, Step: 300/502, Avg Loss: 5.6523, Avg Regression Loss 2.1596, Avg Classification Loss: 3.4928
2021-05-21 20:08:10 - Epoch: 7, Step: 310/502, Avg Loss: 5.4740, Avg Regression Loss 1.9359, Avg Classification Loss: 3.5381
2021-05-21 20:08:14 - Epoch: 7, Step: 320/502, Avg Loss: 5.6319, Avg Regression Loss 1.9925, Avg Classification Loss: 3.6394
2021-05-21 20:08:23 - Epoch: 7, Step: 330/502, Avg Loss: 4.9880, Avg Regression Loss 1.6859, Avg Classification Loss: 3.3021
2021-05-21 20:08:28 - Epoch: 7, Step: 340/502, Avg Loss: 5.6061, Avg Regression Loss 2.1039, Avg Classification Loss: 3.5022
2021-05-21 20:08:33 - Epoch: 7, Step: 350/502, Avg Loss: 5.9912, Avg Regression Loss 2.4917, Avg Classification Loss: 3.4996
2021-05-21 20:08:38 - Epoch: 7, Step: 360/502, Avg Loss: 6.2476, Avg Regression Loss 2.5528, Avg Classification Loss: 3.6947
2021-05-21 20:08:47 - Epoch: 7, Step: 370/502, Avg Loss: 5.6964, Avg Regression Loss 2.0837, Avg Classification Loss: 3.6127
2021-05-21 20:08:52 - Epoch: 7, Step: 380/502, Avg Loss: 5.8493, Avg Regression Loss 2.1602, Avg Classification Loss: 3.6891
2021-05-21 20:08:59 - Epoch: 7, Step: 390/502, Avg Loss: 6.4569, Avg Regression Loss 3.0077, Avg Classification Loss: 3.4492
2021-05-21 20:09:03 - Epoch: 7, Step: 400/502, Avg Loss: 6.2671, Avg Regression Loss 2.5662, Avg Classification Loss: 3.7010
2021-05-21 20:09:09 - Epoch: 7, Step: 410/502, Avg Loss: 5.5435, Avg Regression Loss 1.9106, Avg Classification Loss: 3.6329
2021-05-21 20:09:14 - Epoch: 7, Step: 420/502, Avg Loss: 5.6939, Avg Regression Loss 2.2415, Avg Classification Loss: 3.4524
2021-05-21 20:09:19 - Epoch: 7, Step: 430/502, Avg Loss: 5.9467, Avg Regression Loss 2.4424, Avg Classification Loss: 3.5043
2021-05-21 20:09:24 - Epoch: 7, Step: 440/502, Avg Loss: 5.4731, Avg Regression Loss 2.0080, Avg Classification Loss: 3.4651
2021-05-21 20:09:28 - Epoch: 7, Step: 450/502, Avg Loss: 5.0498, Avg Regression Loss 1.7142, Avg Classification Loss: 3.3356
2021-05-21 20:09:36 - Epoch: 7, Step: 460/502, Avg Loss: 5.9801, Avg Regression Loss 2.5014, Avg Classification Loss: 3.4787
2021-05-21 20:09:41 - Epoch: 7, Step: 470/502, Avg Loss: 6.1915, Avg Regression Loss 2.6346, Avg Classification Loss: 3.5569
2021-05-21 20:09:47 - Epoch: 7, Step: 480/502, Avg Loss: 6.2964, Avg Regression Loss 2.6911, Avg Classification Loss: 3.6053
2021-05-21 20:09:55 - Epoch: 7, Step: 490/502, Avg Loss: 5.6511, Avg Regression Loss 2.1854, Avg Classification Loss: 3.4657
2021-05-21 20:10:00 - Epoch: 7, Step: 500/502, Avg Loss: 6.1798, Avg Regression Loss 2.6033, Avg Classification Loss: 3.5765
2021-05-21 20:11:01 - Epoch: 7, Validation Loss: 4.9200, Validation Regression Loss 1.4224, Validation Classification Loss: 3.4976
2021-05-21 20:11:01 - Saved model models/smd/mb1-ssd-Epoch-7-Loss-4.919970288694618.pth
2021-05-21 20:11:07 - Epoch: 8, Step: 10/502, Avg Loss: 6.3967, Avg Regression Loss 2.1926, Avg Classification Loss: 4.2041
2021-05-21 20:11:12 - Epoch: 8, Step: 20/502, Avg Loss: 5.9175, Avg Regression Loss 2.4038, Avg Classification Loss: 3.5138
2021-05-21 20:11:19 - Epoch: 8, Step: 30/502, Avg Loss: 5.4304, Avg Regression Loss 1.9962, Avg Classification Loss: 3.4342
2021-05-21 20:11:26 - Epoch: 8, Step: 40/502, Avg Loss: 5.5875, Avg Regression Loss 2.2245, Avg Classification Loss: 3.3630
2021-05-21 20:11:30 - Epoch: 8, Step: 50/502, Avg Loss: 5.0874, Avg Regression Loss 1.7290, Avg Classification Loss: 3.3585
2021-05-21 20:11:35 - Epoch: 8, Step: 60/502, Avg Loss: 5.9517, Avg Regression Loss 2.4751, Avg Classification Loss: 3.4766
2021-05-21 20:11:40 - Epoch: 8, Step: 70/502, Avg Loss: 5.9539, Avg Regression Loss 2.2827, Avg Classification Loss: 3.6711
2021-05-21 20:11:45 - Epoch: 8, Step: 80/502, Avg Loss: 6.0223, Avg Regression Loss 2.3886, Avg Classification Loss: 3.6337
2021-05-21 20:11:51 - Epoch: 8, Step: 90/502, Avg Loss: 6.1774, Avg Regression Loss 2.5329, Avg Classification Loss: 3.6445
2021-05-21 20:12:10 - Epoch: 8, Step: 100/502, Avg Loss: 5.5907, Avg Regression Loss 2.1056, Avg Classification Loss: 3.4851
2021-05-21 20:12:15 - Epoch: 8, Step: 110/502, Avg Loss: 5.3351, Avg Regression Loss 1.8004, Avg Classification Loss: 3.5347
2021-05-21 20:12:20 - Epoch: 8, Step: 120/502, Avg Loss: 5.5997, Avg Regression Loss 2.0669, Avg Classification Loss: 3.5328
2021-05-21 20:12:25 - Epoch: 8, Step: 130/502, Avg Loss: 6.2116, Avg Regression Loss 2.6792, Avg Classification Loss: 3.5323
2021-05-21 20:12:29 - Epoch: 8, Step: 140/502, Avg Loss: 6.2332, Avg Regression Loss 2.7380, Avg Classification Loss: 3.4952
2021-05-21 20:12:34 - Epoch: 8, Step: 150/502, Avg Loss: 6.0585, Avg Regression Loss 2.7340, Avg Classification Loss: 3.3245
2021-05-21 20:12:44 - Epoch: 8, Step: 160/502, Avg Loss: 5.4996, Avg Regression Loss 2.1341, Avg Classification Loss: 3.3655
2021-05-21 20:12:50 - Epoch: 8, Step: 170/502, Avg Loss: 5.1159, Avg Regression Loss 1.5242, Avg Classification Loss: 3.5917
2021-05-21 20:12:54 - Epoch: 8, Step: 180/502, Avg Loss: 4.9250, Avg Regression Loss 1.5820, Avg Classification Loss: 3.3430
2021-05-21 20:12:59 - Epoch: 8, Step: 190/502, Avg Loss: 6.2860, Avg Regression Loss 2.6351, Avg Classification Loss: 3.6509
2021-05-21 20:13:04 - Epoch: 8, Step: 200/502, Avg Loss: 5.8647, Avg Regression Loss 2.3279, Avg Classification Loss: 3.5368
2021-05-21 20:13:09 - Epoch: 8, Step: 210/502, Avg Loss: 5.9928, Avg Regression Loss 2.3607, Avg Classification Loss: 3.6321
2021-05-21 20:13:15 - Epoch: 8, Step: 220/502, Avg Loss: 5.5050, Avg Regression Loss 2.0637, Avg Classification Loss: 3.4413
2021-05-21 20:13:24 - Epoch: 8, Step: 230/502, Avg Loss: 5.6423, Avg Regression Loss 2.0850, Avg Classification Loss: 3.5574
2021-05-21 20:13:29 - Epoch: 8, Step: 240/502, Avg Loss: 5.3453, Avg Regression Loss 1.6721, Avg Classification Loss: 3.6732
2021-05-21 20:13:35 - Epoch: 8, Step: 250/502, Avg Loss: 5.5692, Avg Regression Loss 2.0062, Avg Classification Loss: 3.5630
2021-05-21 20:13:40 - Epoch: 8, Step: 260/502, Avg Loss: 5.3851, Avg Regression Loss 1.9652, Avg Classification Loss: 3.4199
2021-05-21 20:13:45 - Epoch: 8, Step: 270/502, Avg Loss: 6.0114, Avg Regression Loss 2.3937, Avg Classification Loss: 3.6177
2021-05-21 20:13:49 - Epoch: 8, Step: 280/502, Avg Loss: 5.1636, Avg Regression Loss 1.8036, Avg Classification Loss: 3.3600
2021-05-21 20:13:54 - Epoch: 8, Step: 290/502, Avg Loss: 5.8933, Avg Regression Loss 2.4590, Avg Classification Loss: 3.4343
2021-05-21 20:13:59 - Epoch: 8, Step: 300/502, Avg Loss: 5.5870, Avg Regression Loss 2.1617, Avg Classification Loss: 3.4252
2021-05-21 20:14:04 - Epoch: 8, Step: 310/502, Avg Loss: 5.0295, Avg Regression Loss 1.6333, Avg Classification Loss: 3.3962
2021-05-21 20:14:09 - Epoch: 8, Step: 320/502, Avg Loss: 5.5846, Avg Regression Loss 2.0479, Avg Classification Loss: 3.5367
2021-05-21 20:14:18 - Epoch: 8, Step: 330/502, Avg Loss: 4.5342, Avg Regression Loss 1.2978, Avg Classification Loss: 3.2365
2021-05-21 20:14:22 - Epoch: 8, Step: 340/502, Avg Loss: 5.8243, Avg Regression Loss 2.2813, Avg Classification Loss: 3.5430
2021-05-21 20:14:27 - Epoch: 8, Step: 350/502, Avg Loss: 5.3272, Avg Regression Loss 1.9045, Avg Classification Loss: 3.4227
2021-05-21 20:14:32 - Epoch: 8, Step: 360/502, Avg Loss: 5.7474, Avg Regression Loss 2.3221, Avg Classification Loss: 3.4253
2021-05-21 20:14:37 - Epoch: 8, Step: 370/502, Avg Loss: 5.2312, Avg Regression Loss 1.8785, Avg Classification Loss: 3.3527
2021-05-21 20:14:42 - Epoch: 8, Step: 380/502, Avg Loss: 5.3066, Avg Regression Loss 1.7991, Avg Classification Loss: 3.5075
2021-05-21 20:14:48 - Epoch: 8, Step: 390/502, Avg Loss: 5.9542, Avg Regression Loss 2.4843, Avg Classification Loss: 3.4698
2021-05-21 20:14:52 - Epoch: 8, Step: 400/502, Avg Loss: 6.4863, Avg Regression Loss 2.8928, Avg Classification Loss: 3.5935
2021-05-21 20:14:57 - Epoch: 8, Step: 410/502, Avg Loss: 4.8675, Avg Regression Loss 1.6155, Avg Classification Loss: 3.2520
2021-05-21 20:15:03 - Epoch: 8, Step: 420/502, Avg Loss: 5.9750, Avg Regression Loss 2.4587, Avg Classification Loss: 3.5162
2021-05-21 20:15:11 - Epoch: 8, Step: 430/502, Avg Loss: 5.8874, Avg Regression Loss 2.3016, Avg Classification Loss: 3.5858
2021-05-21 20:15:16 - Epoch: 8, Step: 440/502, Avg Loss: 5.5020, Avg Regression Loss 2.0883, Avg Classification Loss: 3.4136
2021-05-21 20:15:21 - Epoch: 8, Step: 450/502, Avg Loss: 5.4393, Avg Regression Loss 2.1310, Avg Classification Loss: 3.3083
2021-05-21 20:15:29 - Epoch: 8, Step: 460/502, Avg Loss: 5.2731, Avg Regression Loss 1.8138, Avg Classification Loss: 3.4593
2021-05-21 20:15:34 - Epoch: 8, Step: 470/502, Avg Loss: 5.9236, Avg Regression Loss 2.3210, Avg Classification Loss: 3.6026
2021-05-21 20:15:41 - Epoch: 8, Step: 480/502, Avg Loss: 5.2305, Avg Regression Loss 1.8588, Avg Classification Loss: 3.3717
2021-05-21 20:15:46 - Epoch: 8, Step: 490/502, Avg Loss: 5.2863, Avg Regression Loss 1.8902, Avg Classification Loss: 3.3961
2021-05-21 20:15:52 - Epoch: 8, Step: 500/502, Avg Loss: 5.5064, Avg Regression Loss 1.9555, Avg Classification Loss: 3.5508
2021-05-21 20:16:53 - Epoch: 8, Validation Loss: 5.2501, Validation Regression Loss 1.8527, Validation Classification Loss: 3.3974
2021-05-21 20:16:53 - Saved model models/smd/mb1-ssd-Epoch-8-Loss-5.250080542260432.pth
2021-05-21 20:16:59 - Epoch: 9, Step: 10/502, Avg Loss: 6.1747, Avg Regression Loss 2.4236, Avg Classification Loss: 3.7511
2021-05-21 20:17:04 - Epoch: 9, Step: 20/502, Avg Loss: 5.4264, Avg Regression Loss 2.0746, Avg Classification Loss: 3.3519
2021-05-21 20:17:10 - Epoch: 9, Step: 30/502, Avg Loss: 6.4390, Avg Regression Loss 2.7633, Avg Classification Loss: 3.6758
2021-05-21 20:17:16 - Epoch: 9, Step: 40/502, Avg Loss: 5.1981, Avg Regression Loss 1.7805, Avg Classification Loss: 3.4176
2021-05-21 20:17:21 - Epoch: 9, Step: 50/502, Avg Loss: 4.9476, Avg Regression Loss 1.5614, Avg Classification Loss: 3.3862
2021-05-21 20:17:27 - Epoch: 9, Step: 60/502, Avg Loss: 5.4657, Avg Regression Loss 1.9782, Avg Classification Loss: 3.4875
2021-05-21 20:17:33 - Epoch: 9, Step: 70/502, Avg Loss: 5.3411, Avg Regression Loss 1.8515, Avg Classification Loss: 3.4896
2021-05-21 20:17:38 - Epoch: 9, Step: 80/502, Avg Loss: 4.9445, Avg Regression Loss 1.6137, Avg Classification Loss: 3.3309
2021-05-21 20:17:52 - Epoch: 9, Step: 90/502, Avg Loss: 6.0413, Avg Regression Loss 2.4100, Avg Classification Loss: 3.6313
2021-05-21 20:17:57 - Epoch: 9, Step: 100/502, Avg Loss: 5.3101, Avg Regression Loss 1.8641, Avg Classification Loss: 3.4460
2021-05-21 20:18:02 - Epoch: 9, Step: 110/502, Avg Loss: 6.0865, Avg Regression Loss 2.5494, Avg Classification Loss: 3.5371
2021-05-21 20:18:16 - Epoch: 9, Step: 120/502, Avg Loss: 5.8548, Avg Regression Loss 2.1992, Avg Classification Loss: 3.6556
2021-05-21 20:18:21 - Epoch: 9, Step: 130/502, Avg Loss: 5.4811, Avg Regression Loss 2.0906, Avg Classification Loss: 3.3905
2021-05-21 20:18:26 - Epoch: 9, Step: 140/502, Avg Loss: 5.5547, Avg Regression Loss 2.0060, Avg Classification Loss: 3.5488
2021-05-21 20:18:31 - Epoch: 9, Step: 150/502, Avg Loss: 5.1477, Avg Regression Loss 1.8243, Avg Classification Loss: 3.3235
2021-05-21 20:18:39 - Epoch: 9, Step: 160/502, Avg Loss: 6.4662, Avg Regression Loss 2.6511, Avg Classification Loss: 3.8151
2021-05-21 20:18:45 - Epoch: 9, Step: 170/502, Avg Loss: 6.8658, Avg Regression Loss 3.4458, Avg Classification Loss: 3.4200
2021-05-21 20:18:49 - Epoch: 9, Step: 180/502, Avg Loss: 5.1372, Avg Regression Loss 1.8095, Avg Classification Loss: 3.3277
2021-05-21 20:18:54 - Epoch: 9, Step: 190/502, Avg Loss: 5.1039, Avg Regression Loss 1.7418, Avg Classification Loss: 3.3621
2021-05-21 20:18:59 - Epoch: 9, Step: 200/502, Avg Loss: 5.8081, Avg Regression Loss 2.2498, Avg Classification Loss: 3.5583
2021-05-21 20:19:05 - Epoch: 9, Step: 210/502, Avg Loss: 4.9761, Avg Regression Loss 1.7701, Avg Classification Loss: 3.2060
2021-05-21 20:19:10 - Epoch: 9, Step: 220/502, Avg Loss: 6.0597, Avg Regression Loss 2.5984, Avg Classification Loss: 3.4613
2021-05-21 20:19:19 - Epoch: 9, Step: 230/502, Avg Loss: 5.6000, Avg Regression Loss 2.2228, Avg Classification Loss: 3.3772
2021-05-21 20:19:26 - Epoch: 9, Step: 240/502, Avg Loss: 5.5170, Avg Regression Loss 2.1985, Avg Classification Loss: 3.3185
2021-05-21 20:19:32 - Epoch: 9, Step: 250/502, Avg Loss: 6.5366, Avg Regression Loss 2.8252, Avg Classification Loss: 3.7114
2021-05-21 20:19:37 - Epoch: 9, Step: 260/502, Avg Loss: 5.2951, Avg Regression Loss 2.0258, Avg Classification Loss: 3.2693
2021-05-21 20:19:42 - Epoch: 9, Step: 270/502, Avg Loss: 5.9185, Avg Regression Loss 2.2700, Avg Classification Loss: 3.6485
2021-05-21 20:19:46 - Epoch: 9, Step: 280/502, Avg Loss: 5.5202, Avg Regression Loss 2.1025, Avg Classification Loss: 3.4177
2021-05-21 20:19:52 - Epoch: 9, Step: 290/502, Avg Loss: 5.9007, Avg Regression Loss 2.4509, Avg Classification Loss: 3.4498
2021-05-21 20:19:58 - Epoch: 9, Step: 300/502, Avg Loss: 5.8005, Avg Regression Loss 2.3559, Avg Classification Loss: 3.4447
2021-05-21 20:20:02 - Epoch: 9, Step: 310/502, Avg Loss: 5.7420, Avg Regression Loss 2.3117, Avg Classification Loss: 3.4303
2021-05-21 20:20:07 - Epoch: 9, Step: 320/502, Avg Loss: 5.4166, Avg Regression Loss 1.8887, Avg Classification Loss: 3.5279
2021-05-21 20:20:12 - Epoch: 9, Step: 330/502, Avg Loss: 6.4486, Avg Regression Loss 2.9989, Avg Classification Loss: 3.4497
2021-05-21 20:20:17 - Epoch: 9, Step: 340/502, Avg Loss: 5.1431, Avg Regression Loss 1.6911, Avg Classification Loss: 3.4520
2021-05-21 20:20:21 - Epoch: 9, Step: 350/502, Avg Loss: 5.2433, Avg Regression Loss 1.8434, Avg Classification Loss: 3.3999
2021-05-21 20:20:27 - Epoch: 9, Step: 360/502, Avg Loss: 5.5153, Avg Regression Loss 2.0672, Avg Classification Loss: 3.4481
2021-05-21 20:20:39 - Epoch: 9, Step: 370/502, Avg Loss: 5.8504, Avg Regression Loss 2.2942, Avg Classification Loss: 3.5562
2021-05-21 20:20:43 - Epoch: 9, Step: 380/502, Avg Loss: 5.5732, Avg Regression Loss 1.9028, Avg Classification Loss: 3.6705
2021-05-21 20:20:48 - Epoch: 9, Step: 390/502, Avg Loss: 5.3165, Avg Regression Loss 1.8421, Avg Classification Loss: 3.4745
2021-05-21 20:20:53 - Epoch: 9, Step: 400/502, Avg Loss: 4.8360, Avg Regression Loss 1.4504, Avg Classification Loss: 3.3856
2021-05-21 20:20:59 - Epoch: 9, Step: 410/502, Avg Loss: 5.5639, Avg Regression Loss 1.8479, Avg Classification Loss: 3.7159
2021-05-21 20:21:04 - Epoch: 9, Step: 420/502, Avg Loss: 5.1490, Avg Regression Loss 1.7052, Avg Classification Loss: 3.4438
2021-05-21 20:21:12 - Epoch: 9, Step: 430/502, Avg Loss: 5.5631, Avg Regression Loss 2.1247, Avg Classification Loss: 3.4384
2021-05-21 20:21:17 - Epoch: 9, Step: 440/502, Avg Loss: 4.8935, Avg Regression Loss 1.5889, Avg Classification Loss: 3.3046
2021-05-21 20:21:22 - Epoch: 9, Step: 450/502, Avg Loss: 5.6785, Avg Regression Loss 2.3507, Avg Classification Loss: 3.3278
2021-05-21 20:21:26 - Epoch: 9, Step: 460/502, Avg Loss: 5.7345, Avg Regression Loss 2.1373, Avg Classification Loss: 3.5972
2021-05-21 20:21:31 - Epoch: 9, Step: 470/502, Avg Loss: 5.4342, Avg Regression Loss 1.9402, Avg Classification Loss: 3.4940
2021-05-21 20:21:36 - Epoch: 9, Step: 480/502, Avg Loss: 5.8929, Avg Regression Loss 2.3371, Avg Classification Loss: 3.5557
2021-05-21 20:21:41 - Epoch: 9, Step: 490/502, Avg Loss: 5.5395, Avg Regression Loss 2.1007, Avg Classification Loss: 3.4388
2021-05-21 20:21:49 - Epoch: 9, Step: 500/502, Avg Loss: 5.1545, Avg Regression Loss 1.9049, Avg Classification Loss: 3.2496
2021-05-21 20:22:51 - Epoch: 9, Validation Loss: 4.6133, Validation Regression Loss 1.2102, Validation Classification Loss: 3.4031
2021-05-21 20:22:51 - Saved model models/smd/mb1-ssd-Epoch-9-Loss-4.613264281436266.pth
2021-05-21 20:22:57 - Epoch: 10, Step: 10/502, Avg Loss: 6.5564, Avg Regression Loss 2.6356, Avg Classification Loss: 3.9208
2021-05-21 20:23:03 - Epoch: 10, Step: 20/502, Avg Loss: 5.2622, Avg Regression Loss 1.6111, Avg Classification Loss: 3.6511
2021-05-21 20:23:10 - Epoch: 10, Step: 30/502, Avg Loss: 6.4120, Avg Regression Loss 2.6747, Avg Classification Loss: 3.7373
2021-05-21 20:23:15 - Epoch: 10, Step: 40/502, Avg Loss: 5.3740, Avg Regression Loss 1.8357, Avg Classification Loss: 3.5383
2021-05-21 20:23:20 - Epoch: 10, Step: 50/502, Avg Loss: 6.0059, Avg Regression Loss 2.4165, Avg Classification Loss: 3.5894
2021-05-21 20:23:35 - Epoch: 10, Step: 60/502, Avg Loss: 5.6900, Avg Regression Loss 2.1483, Avg Classification Loss: 3.5416
2021-05-21 20:23:40 - Epoch: 10, Step: 70/502, Avg Loss: 6.2686, Avg Regression Loss 2.6431, Avg Classification Loss: 3.6256
2021-05-21 20:23:45 - Epoch: 10, Step: 80/502, Avg Loss: 5.3097, Avg Regression Loss 1.7923, Avg Classification Loss: 3.5174
2021-05-21 20:23:53 - Epoch: 10, Step: 90/502, Avg Loss: 5.1114, Avg Regression Loss 1.6899, Avg Classification Loss: 3.4215
2021-05-21 20:23:58 - Epoch: 10, Step: 100/502, Avg Loss: 6.3418, Avg Regression Loss 2.7968, Avg Classification Loss: 3.5450
2021-05-21 20:24:07 - Epoch: 10, Step: 110/502, Avg Loss: 5.8755, Avg Regression Loss 2.1818, Avg Classification Loss: 3.6937
2021-05-21 20:24:11 - Epoch: 10, Step: 120/502, Avg Loss: 5.7352, Avg Regression Loss 2.2870, Avg Classification Loss: 3.4483
2021-05-21 20:24:16 - Epoch: 10, Step: 130/502, Avg Loss: 5.5081, Avg Regression Loss 2.0434, Avg Classification Loss: 3.4647
2021-05-21 20:24:21 - Epoch: 10, Step: 140/502, Avg Loss: 5.6062, Avg Regression Loss 2.2048, Avg Classification Loss: 3.4014
2021-05-21 20:24:30 - Epoch: 10, Step: 150/502, Avg Loss: 5.3668, Avg Regression Loss 2.0480, Avg Classification Loss: 3.3188
2021-05-21 20:24:35 - Epoch: 10, Step: 160/502, Avg Loss: 5.2502, Avg Regression Loss 1.7716, Avg Classification Loss: 3.4786
2021-05-21 20:24:39 - Epoch: 10, Step: 170/502, Avg Loss: 5.3811, Avg Regression Loss 1.7864, Avg Classification Loss: 3.5948
2021-05-21 20:24:44 - Epoch: 10, Step: 180/502, Avg Loss: 6.6732, Avg Regression Loss 2.9715, Avg Classification Loss: 3.7017
2021-05-21 20:24:49 - Epoch: 10, Step: 190/502, Avg Loss: 5.0238, Avg Regression Loss 1.6392, Avg Classification Loss: 3.3845
2021-05-21 20:24:54 - Epoch: 10, Step: 200/502, Avg Loss: 5.9137, Avg Regression Loss 2.5432, Avg Classification Loss: 3.3706
2021-05-21 20:25:02 - Epoch: 10, Step: 210/502, Avg Loss: 6.7348, Avg Regression Loss 3.1534, Avg Classification Loss: 3.5814
2021-05-21 20:25:07 - Epoch: 10, Step: 220/502, Avg Loss: 6.4120, Avg Regression Loss 3.1200, Avg Classification Loss: 3.2919
2021-05-21 20:25:20 - Epoch: 10, Step: 230/502, Avg Loss: 5.9186, Avg Regression Loss 2.3860, Avg Classification Loss: 3.5326
2021-05-21 20:25:26 - Epoch: 10, Step: 240/502, Avg Loss: 6.0947, Avg Regression Loss 2.6060, Avg Classification Loss: 3.4886
2021-05-21 20:25:31 - Epoch: 10, Step: 250/502, Avg Loss: 5.8900, Avg Regression Loss 2.4791, Avg Classification Loss: 3.4108
2021-05-21 20:25:36 - Epoch: 10, Step: 260/502, Avg Loss: 5.0932, Avg Regression Loss 1.6847, Avg Classification Loss: 3.4085
2021-05-21 20:25:40 - Epoch: 10, Step: 270/502, Avg Loss: 5.1749, Avg Regression Loss 1.7217, Avg Classification Loss: 3.4531
2021-05-21 20:25:45 - Epoch: 10, Step: 280/502, Avg Loss: 4.7848, Avg Regression Loss 1.5184, Avg Classification Loss: 3.2663
2021-05-21 20:25:49 - Epoch: 10, Step: 290/502, Avg Loss: 5.1286, Avg Regression Loss 1.7565, Avg Classification Loss: 3.3721
2021-05-21 20:25:55 - Epoch: 10, Step: 300/502, Avg Loss: 4.8290, Avg Regression Loss 1.5951, Avg Classification Loss: 3.2339
2021-05-21 20:25:59 - Epoch: 10, Step: 310/502, Avg Loss: 5.5434, Avg Regression Loss 1.9891, Avg Classification Loss: 3.5543
2021-05-21 20:26:06 - Epoch: 10, Step: 320/502, Avg Loss: 5.2546, Avg Regression Loss 1.9222, Avg Classification Loss: 3.3324
2021-05-21 20:26:11 - Epoch: 10, Step: 330/502, Avg Loss: 5.0070, Avg Regression Loss 1.5791, Avg Classification Loss: 3.4279
2021-05-21 20:26:16 - Epoch: 10, Step: 340/502, Avg Loss: 5.4242, Avg Regression Loss 1.7483, Avg Classification Loss: 3.6759
2021-05-21 20:26:20 - Epoch: 10, Step: 350/502, Avg Loss: 5.8963, Avg Regression Loss 2.4341, Avg Classification Loss: 3.4622
2021-05-21 20:26:26 - Epoch: 10, Step: 360/502, Avg Loss: 5.6949, Avg Regression Loss 2.3705, Avg Classification Loss: 3.3244
2021-05-21 20:26:32 - Epoch: 10, Step: 370/502, Avg Loss: 5.1710, Avg Regression Loss 1.6719, Avg Classification Loss: 3.4991
2021-05-21 20:26:36 - Epoch: 10, Step: 380/502, Avg Loss: 5.2348, Avg Regression Loss 1.9558, Avg Classification Loss: 3.2790
2021-05-21 20:26:43 - Epoch: 10, Step: 390/502, Avg Loss: 6.3994, Avg Regression Loss 2.9723, Avg Classification Loss: 3.4271
2021-05-21 20:26:47 - Epoch: 10, Step: 400/502, Avg Loss: 5.6231, Avg Regression Loss 2.2217, Avg Classification Loss: 3.4014
2021-05-21 20:26:52 - Epoch: 10, Step: 410/502, Avg Loss: 5.3255, Avg Regression Loss 1.4767, Avg Classification Loss: 3.8488
2021-05-21 20:26:57 - Epoch: 10, Step: 420/502, Avg Loss: 5.2648, Avg Regression Loss 1.8823, Avg Classification Loss: 3.3825
2021-05-21 20:27:04 - Epoch: 10, Step: 430/502, Avg Loss: 5.6072, Avg Regression Loss 2.2460, Avg Classification Loss: 3.3612
2021-05-21 20:27:09 - Epoch: 10, Step: 440/502, Avg Loss: 5.7229, Avg Regression Loss 2.1308, Avg Classification Loss: 3.5920
2021-05-21 20:27:14 - Epoch: 10, Step: 450/502, Avg Loss: 5.0206, Avg Regression Loss 1.6416, Avg Classification Loss: 3.3790
2021-05-21 20:27:20 - Epoch: 10, Step: 460/502, Avg Loss: 5.1232, Avg Regression Loss 1.8748, Avg Classification Loss: 3.2484
2021-05-21 20:27:25 - Epoch: 10, Step: 470/502, Avg Loss: 5.4900, Avg Regression Loss 2.2056, Avg Classification Loss: 3.2844
2021-05-21 20:27:30 - Epoch: 10, Step: 480/502, Avg Loss: 6.0217, Avg Regression Loss 2.5565, Avg Classification Loss: 3.4652
2021-05-21 20:27:34 - Epoch: 10, Step: 490/502, Avg Loss: 5.0061, Avg Regression Loss 1.7338, Avg Classification Loss: 3.2723
2021-05-21 20:27:41 - Epoch: 10, Step: 500/502, Avg Loss: 4.8041, Avg Regression Loss 1.5428, Avg Classification Loss: 3.2613
2021-05-21 20:28:42 - Epoch: 10, Validation Loss: 5.3028, Validation Regression Loss 1.5280, Validation Classification Loss: 3.7747
2021-05-21 20:28:42 - Saved model models/smd/mb1-ssd-Epoch-10-Loss-5.302782662836204.pth
2021-05-21 20:28:48 - Epoch: 11, Step: 10/502, Avg Loss: 5.9039, Avg Regression Loss 2.0964, Avg Classification Loss: 3.8075
2021-05-21 20:28:56 - Epoch: 11, Step: 20/502, Avg Loss: 5.4603, Avg Regression Loss 1.8306, Avg Classification Loss: 3.6297
2021-05-21 20:29:05 - Epoch: 11, Step: 30/502, Avg Loss: 5.8417, Avg Regression Loss 2.3443, Avg Classification Loss: 3.4974
2021-05-21 20:29:10 - Epoch: 11, Step: 40/502, Avg Loss: 5.3060, Avg Regression Loss 1.7782, Avg Classification Loss: 3.5278
2021-05-21 20:29:15 - Epoch: 11, Step: 50/502, Avg Loss: 4.9610, Avg Regression Loss 1.6353, Avg Classification Loss: 3.3257
2021-05-21 20:29:20 - Epoch: 11, Step: 60/502, Avg Loss: 5.5188, Avg Regression Loss 1.8377, Avg Classification Loss: 3.6811
2021-05-21 20:29:25 - Epoch: 11, Step: 70/502, Avg Loss: 6.1323, Avg Regression Loss 2.5802, Avg Classification Loss: 3.5521
2021-05-21 20:29:34 - Epoch: 11, Step: 80/502, Avg Loss: 5.5551, Avg Regression Loss 2.0965, Avg Classification Loss: 3.4586
2021-05-21 20:29:39 - Epoch: 11, Step: 90/502, Avg Loss: 5.8818, Avg Regression Loss 2.5348, Avg Classification Loss: 3.3470
2021-05-21 20:29:52 - Epoch: 11, Step: 100/502, Avg Loss: 5.2437, Avg Regression Loss 1.6949, Avg Classification Loss: 3.5487
2021-05-21 20:29:56 - Epoch: 11, Step: 110/502, Avg Loss: 5.0734, Avg Regression Loss 1.7237, Avg Classification Loss: 3.3497
2021-05-21 20:30:01 - Epoch: 11, Step: 120/502, Avg Loss: 5.2051, Avg Regression Loss 1.7726, Avg Classification Loss: 3.4325
2021-05-21 20:30:07 - Epoch: 11, Step: 130/502, Avg Loss: 5.2886, Avg Regression Loss 1.8188, Avg Classification Loss: 3.4698
2021-05-21 20:30:22 - Epoch: 11, Step: 140/502, Avg Loss: 5.9364, Avg Regression Loss 2.5559, Avg Classification Loss: 3.3805
2021-05-21 20:30:27 - Epoch: 11, Step: 150/502, Avg Loss: 5.5547, Avg Regression Loss 2.0241, Avg Classification Loss: 3.5306
2021-05-21 20:30:39 - Epoch: 11, Step: 160/502, Avg Loss: 4.9535, Avg Regression Loss 1.6534, Avg Classification Loss: 3.3001
2021-05-21 20:30:44 - Epoch: 11, Step: 170/502, Avg Loss: 5.1451, Avg Regression Loss 1.6951, Avg Classification Loss: 3.4500
2021-05-21 20:30:49 - Epoch: 11, Step: 180/502, Avg Loss: 5.1060, Avg Regression Loss 1.6521, Avg Classification Loss: 3.4539
2021-05-21 20:30:53 - Epoch: 11, Step: 190/502, Avg Loss: 5.3803, Avg Regression Loss 1.9349, Avg Classification Loss: 3.4454
2021-05-21 20:30:58 - Epoch: 11, Step: 200/502, Avg Loss: 5.3743, Avg Regression Loss 1.9531, Avg Classification Loss: 3.4212
2021-05-21 20:31:07 - Epoch: 11, Step: 210/502, Avg Loss: 5.9985, Avg Regression Loss 2.3339, Avg Classification Loss: 3.6646
2021-05-21 20:31:12 - Epoch: 11, Step: 220/502, Avg Loss: 5.3046, Avg Regression Loss 1.8144, Avg Classification Loss: 3.4902
2021-05-21 20:31:17 - Epoch: 11, Step: 230/502, Avg Loss: 4.9676, Avg Regression Loss 1.6112, Avg Classification Loss: 3.3564
2021-05-21 20:31:21 - Epoch: 11, Step: 240/502, Avg Loss: 5.1524, Avg Regression Loss 1.5352, Avg Classification Loss: 3.6172
2021-05-21 20:31:26 - Epoch: 11, Step: 250/502, Avg Loss: 4.9062, Avg Regression Loss 1.4707, Avg Classification Loss: 3.4355
2021-05-21 20:31:31 - Epoch: 11, Step: 260/502, Avg Loss: 5.8679, Avg Regression Loss 2.5313, Avg Classification Loss: 3.3366
2021-05-21 20:31:36 - Epoch: 11, Step: 270/502, Avg Loss: 5.8243, Avg Regression Loss 2.3778, Avg Classification Loss: 3.4465
2021-05-21 20:31:41 - Epoch: 11, Step: 280/502, Avg Loss: 5.0419, Avg Regression Loss 1.7091, Avg Classification Loss: 3.3328
2021-05-21 20:31:46 - Epoch: 11, Step: 290/502, Avg Loss: 5.6633, Avg Regression Loss 2.0784, Avg Classification Loss: 3.5850
2021-05-21 20:31:51 - Epoch: 11, Step: 300/502, Avg Loss: 5.0284, Avg Regression Loss 1.8020, Avg Classification Loss: 3.2264
2021-05-21 20:31:55 - Epoch: 11, Step: 310/502, Avg Loss: 4.8253, Avg Regression Loss 1.5983, Avg Classification Loss: 3.2270
2021-05-21 20:32:00 - Epoch: 11, Step: 320/502, Avg Loss: 5.7434, Avg Regression Loss 2.2578, Avg Classification Loss: 3.4856
2021-05-21 20:32:06 - Epoch: 11, Step: 330/502, Avg Loss: 5.3137, Avg Regression Loss 1.7467, Avg Classification Loss: 3.5670
2021-05-21 20:32:12 - Epoch: 11, Step: 340/502, Avg Loss: 5.1799, Avg Regression Loss 1.9165, Avg Classification Loss: 3.2634
2021-05-21 20:32:17 - Epoch: 11, Step: 350/502, Avg Loss: 5.4454, Avg Regression Loss 1.9772, Avg Classification Loss: 3.4681
2021-05-21 20:32:22 - Epoch: 11, Step: 360/502, Avg Loss: 5.6067, Avg Regression Loss 2.0410, Avg Classification Loss: 3.5657
2021-05-21 20:32:27 - Epoch: 11, Step: 370/502, Avg Loss: 5.0249, Avg Regression Loss 1.6563, Avg Classification Loss: 3.3686
2021-05-21 20:32:31 - Epoch: 11, Step: 380/502, Avg Loss: 5.8461, Avg Regression Loss 2.4439, Avg Classification Loss: 3.4022
2021-05-21 20:32:37 - Epoch: 11, Step: 390/502, Avg Loss: 6.2771, Avg Regression Loss 2.5199, Avg Classification Loss: 3.7572
2021-05-21 20:32:41 - Epoch: 11, Step: 400/502, Avg Loss: 5.4914, Avg Regression Loss 1.9316, Avg Classification Loss: 3.5598
2021-05-21 20:32:46 - Epoch: 11, Step: 410/502, Avg Loss: 5.1524, Avg Regression Loss 1.7243, Avg Classification Loss: 3.4281
2021-05-21 20:32:52 - Epoch: 11, Step: 420/502, Avg Loss: 5.2343, Avg Regression Loss 1.7356, Avg Classification Loss: 3.4987
2021-05-21 20:32:56 - Epoch: 11, Step: 430/502, Avg Loss: 4.5266, Avg Regression Loss 1.3104, Avg Classification Loss: 3.2162
2021-05-21 20:33:01 - Epoch: 11, Step: 440/502, Avg Loss: 5.3631, Avg Regression Loss 1.8620, Avg Classification Loss: 3.5011
2021-05-21 20:33:06 - Epoch: 11, Step: 450/502, Avg Loss: 5.1074, Avg Regression Loss 1.6905, Avg Classification Loss: 3.4168
2021-05-21 20:33:13 - Epoch: 11, Step: 460/502, Avg Loss: 4.9732, Avg Regression Loss 1.6887, Avg Classification Loss: 3.2845
2021-05-21 20:33:17 - Epoch: 11, Step: 470/502, Avg Loss: 4.8854, Avg Regression Loss 1.5311, Avg Classification Loss: 3.3543
2021-05-21 20:33:22 - Epoch: 11, Step: 480/502, Avg Loss: 5.5069, Avg Regression Loss 1.7747, Avg Classification Loss: 3.7321
2021-05-21 20:33:27 - Epoch: 11, Step: 490/502, Avg Loss: 5.0529, Avg Regression Loss 1.5548, Avg Classification Loss: 3.4981
2021-05-21 20:33:32 - Epoch: 11, Step: 500/502, Avg Loss: 4.9923, Avg Regression Loss 1.8270, Avg Classification Loss: 3.1653
2021-05-21 20:34:34 - Epoch: 11, Validation Loss: 4.5179, Validation Regression Loss 1.1754, Validation Classification Loss: 3.3425
2021-05-21 20:34:34 - Saved model models/smd/mb1-ssd-Epoch-11-Loss-4.517873972060671.pth
2021-05-21 20:34:40 - Epoch: 12, Step: 10/502, Avg Loss: 5.3759, Avg Regression Loss 1.6493, Avg Classification Loss: 3.7266
2021-05-21 20:34:49 - Epoch: 12, Step: 20/502, Avg Loss: 5.7962, Avg Regression Loss 2.2749, Avg Classification Loss: 3.5213
2021-05-21 20:34:55 - Epoch: 12, Step: 30/502, Avg Loss: 5.1565, Avg Regression Loss 1.7095, Avg Classification Loss: 3.4469
2021-05-21 20:35:00 - Epoch: 12, Step: 40/502, Avg Loss: 5.9128, Avg Regression Loss 2.3969, Avg Classification Loss: 3.5159
2021-05-21 20:35:05 - Epoch: 12, Step: 50/502, Avg Loss: 5.0139, Avg Regression Loss 1.7230, Avg Classification Loss: 3.2909
2021-05-21 20:35:09 - Epoch: 12, Step: 60/502, Avg Loss: 5.2977, Avg Regression Loss 1.7583, Avg Classification Loss: 3.5395
2021-05-21 20:35:14 - Epoch: 12, Step: 70/502, Avg Loss: 5.4196, Avg Regression Loss 2.0388, Avg Classification Loss: 3.3809
2021-05-21 20:35:19 - Epoch: 12, Step: 80/502, Avg Loss: 4.9651, Avg Regression Loss 1.7277, Avg Classification Loss: 3.2375
2021-05-21 20:35:24 - Epoch: 12, Step: 90/502, Avg Loss: 5.5361, Avg Regression Loss 2.1117, Avg Classification Loss: 3.4244
2021-05-21 20:35:29 - Epoch: 12, Step: 100/502, Avg Loss: 5.2178, Avg Regression Loss 1.8068, Avg Classification Loss: 3.4111
2021-05-21 20:35:34 - Epoch: 12, Step: 110/502, Avg Loss: 5.3811, Avg Regression Loss 1.8486, Avg Classification Loss: 3.5325
2021-05-21 20:35:39 - Epoch: 12, Step: 120/502, Avg Loss: 5.7791, Avg Regression Loss 2.0602, Avg Classification Loss: 3.7189
2021-05-21 20:35:44 - Epoch: 12, Step: 130/502, Avg Loss: 5.8045, Avg Regression Loss 2.4069, Avg Classification Loss: 3.3976
2021-05-21 20:35:49 - Epoch: 12, Step: 140/502, Avg Loss: 5.8280, Avg Regression Loss 2.3836, Avg Classification Loss: 3.4444
2021-05-21 20:36:07 - Epoch: 12, Step: 150/502, Avg Loss: 5.9088, Avg Regression Loss 2.5224, Avg Classification Loss: 3.3864
2021-05-21 20:36:12 - Epoch: 12, Step: 160/502, Avg Loss: 5.4047, Avg Regression Loss 1.8390, Avg Classification Loss: 3.5656
2021-05-21 20:36:17 - Epoch: 12, Step: 170/502, Avg Loss: 5.0256, Avg Regression Loss 1.7039, Avg Classification Loss: 3.3217
2021-05-21 20:36:22 - Epoch: 12, Step: 180/502, Avg Loss: 4.7522, Avg Regression Loss 1.3256, Avg Classification Loss: 3.4266
2021-05-21 20:36:26 - Epoch: 12, Step: 190/502, Avg Loss: 4.9908, Avg Regression Loss 1.6645, Avg Classification Loss: 3.3263
2021-05-21 20:36:31 - Epoch: 12, Step: 200/502, Avg Loss: 5.1337, Avg Regression Loss 1.6599, Avg Classification Loss: 3.4738
2021-05-21 20:36:36 - Epoch: 12, Step: 210/502, Avg Loss: 5.2924, Avg Regression Loss 1.9518, Avg Classification Loss: 3.3405
2021-05-21 20:36:43 - Epoch: 12, Step: 220/502, Avg Loss: 5.1535, Avg Regression Loss 1.6680, Avg Classification Loss: 3.4854
2021-05-21 20:36:49 - Epoch: 12, Step: 230/502, Avg Loss: 6.1670, Avg Regression Loss 2.5120, Avg Classification Loss: 3.6550
2021-05-21 20:36:54 - Epoch: 12, Step: 240/502, Avg Loss: 5.2186, Avg Regression Loss 1.7876, Avg Classification Loss: 3.4309
2021-05-21 20:37:00 - Epoch: 12, Step: 250/502, Avg Loss: 5.8503, Avg Regression Loss 2.4766, Avg Classification Loss: 3.3737
2021-05-21 20:37:05 - Epoch: 12, Step: 260/502, Avg Loss: 5.2653, Avg Regression Loss 1.8219, Avg Classification Loss: 3.4435
2021-05-21 20:37:09 - Epoch: 12, Step: 270/502, Avg Loss: 5.9300, Avg Regression Loss 2.4555, Avg Classification Loss: 3.4746
2021-05-21 20:37:14 - Epoch: 12, Step: 280/502, Avg Loss: 5.0644, Avg Regression Loss 1.7435, Avg Classification Loss: 3.3209
2021-05-21 20:37:19 - Epoch: 12, Step: 290/502, Avg Loss: 4.5699, Avg Regression Loss 1.0643, Avg Classification Loss: 3.5056
2021-05-21 20:37:24 - Epoch: 12, Step: 300/502, Avg Loss: 5.1510, Avg Regression Loss 1.8333, Avg Classification Loss: 3.3177
2021-05-21 20:37:28 - Epoch: 12, Step: 310/502, Avg Loss: 5.6505, Avg Regression Loss 2.3002, Avg Classification Loss: 3.3503
2021-05-21 20:37:33 - Epoch: 12, Step: 320/502, Avg Loss: 4.4082, Avg Regression Loss 1.2445, Avg Classification Loss: 3.1637
2021-05-21 20:37:41 - Epoch: 12, Step: 330/502, Avg Loss: 5.4850, Avg Regression Loss 1.9455, Avg Classification Loss: 3.5395
2021-05-21 20:37:46 - Epoch: 12, Step: 340/502, Avg Loss: 4.6600, Avg Regression Loss 1.3667, Avg Classification Loss: 3.2933
2021-05-21 20:37:51 - Epoch: 12, Step: 350/502, Avg Loss: 5.6229, Avg Regression Loss 2.2103, Avg Classification Loss: 3.4126
2021-05-21 20:37:57 - Epoch: 12, Step: 360/502, Avg Loss: 5.0819, Avg Regression Loss 1.7685, Avg Classification Loss: 3.3134
2021-05-21 20:38:02 - Epoch: 12, Step: 370/502, Avg Loss: 6.0877, Avg Regression Loss 2.6357, Avg Classification Loss: 3.4520
2021-05-21 20:38:06 - Epoch: 12, Step: 380/502, Avg Loss: 4.9784, Avg Regression Loss 1.5105, Avg Classification Loss: 3.4679
2021-05-21 20:38:11 - Epoch: 12, Step: 390/502, Avg Loss: 5.1197, Avg Regression Loss 1.7773, Avg Classification Loss: 3.3424
2021-05-21 20:38:16 - Epoch: 12, Step: 400/502, Avg Loss: 4.9608, Avg Regression Loss 1.6930, Avg Classification Loss: 3.2678
2021-05-21 20:38:21 - Epoch: 12, Step: 410/502, Avg Loss: 5.2383, Avg Regression Loss 1.8253, Avg Classification Loss: 3.4130
2021-05-21 20:38:26 - Epoch: 12, Step: 420/502, Avg Loss: 6.1992, Avg Regression Loss 2.7335, Avg Classification Loss: 3.4657
2021-05-21 20:38:32 - Epoch: 12, Step: 430/502, Avg Loss: 6.1872, Avg Regression Loss 2.6147, Avg Classification Loss: 3.5725
2021-05-21 20:38:36 - Epoch: 12, Step: 440/502, Avg Loss: 4.7216, Avg Regression Loss 1.1611, Avg Classification Loss: 3.5605
2021-05-21 20:38:41 - Epoch: 12, Step: 450/502, Avg Loss: 4.8227, Avg Regression Loss 1.4149, Avg Classification Loss: 3.4078
2021-05-21 20:38:48 - Epoch: 12, Step: 460/502, Avg Loss: 5.5492, Avg Regression Loss 2.1736, Avg Classification Loss: 3.3756
2021-05-21 20:38:58 - Epoch: 12, Step: 470/502, Avg Loss: 5.0710, Avg Regression Loss 1.6208, Avg Classification Loss: 3.4501
2021-05-21 20:39:03 - Epoch: 12, Step: 480/502, Avg Loss: 5.8899, Avg Regression Loss 2.3740, Avg Classification Loss: 3.5159
2021-05-21 20:39:07 - Epoch: 12, Step: 490/502, Avg Loss: 5.4617, Avg Regression Loss 1.9951, Avg Classification Loss: 3.4665
2021-05-21 20:39:12 - Epoch: 12, Step: 500/502, Avg Loss: 5.8826, Avg Regression Loss 2.4786, Avg Classification Loss: 3.4040
2021-05-21 20:40:13 - Epoch: 12, Validation Loss: 4.8726, Validation Regression Loss 1.5755, Validation Classification Loss: 3.2971
2021-05-21 20:40:13 - Saved model models/smd/mb1-ssd-Epoch-12-Loss-4.872572588730618.pth
2021-05-21 20:40:22 - Epoch: 13, Step: 10/502, Avg Loss: 5.8768, Avg Regression Loss 2.0985, Avg Classification Loss: 3.7784
2021-05-21 20:40:27 - Epoch: 13, Step: 20/502, Avg Loss: 5.2258, Avg Regression Loss 1.8509, Avg Classification Loss: 3.3749
2021-05-21 20:40:33 - Epoch: 13, Step: 30/502, Avg Loss: 5.1337, Avg Regression Loss 1.5767, Avg Classification Loss: 3.5571
2021-05-21 20:40:38 - Epoch: 13, Step: 40/502, Avg Loss: 5.5354, Avg Regression Loss 2.0947, Avg Classification Loss: 3.4407
2021-05-21 20:40:43 - Epoch: 13, Step: 50/502, Avg Loss: 4.7395, Avg Regression Loss 1.5061, Avg Classification Loss: 3.2334
2021-05-21 20:40:47 - Epoch: 13, Step: 60/502, Avg Loss: 4.9425, Avg Regression Loss 1.6556, Avg Classification Loss: 3.2870
2021-05-21 20:40:52 - Epoch: 13, Step: 70/502, Avg Loss: 5.3180, Avg Regression Loss 1.8331, Avg Classification Loss: 3.4849
2021-05-21 20:40:57 - Epoch: 13, Step: 80/502, Avg Loss: 5.0117, Avg Regression Loss 1.6639, Avg Classification Loss: 3.3477
2021-05-21 20:41:03 - Epoch: 13, Step: 90/502, Avg Loss: 5.5584, Avg Regression Loss 2.2007, Avg Classification Loss: 3.3577
2021-05-21 20:41:08 - Epoch: 13, Step: 100/502, Avg Loss: 4.9527, Avg Regression Loss 1.7700, Avg Classification Loss: 3.1826
2021-05-21 20:41:29 - Epoch: 13, Step: 110/502, Avg Loss: 5.5629, Avg Regression Loss 2.1684, Avg Classification Loss: 3.3945
2021-05-21 20:41:34 - Epoch: 13, Step: 120/502, Avg Loss: 4.9290, Avg Regression Loss 1.5212, Avg Classification Loss: 3.4078
2021-05-21 20:41:39 - Epoch: 13, Step: 130/502, Avg Loss: 4.9870, Avg Regression Loss 1.6243, Avg Classification Loss: 3.3627
2021-05-21 20:41:43 - Epoch: 13, Step: 140/502, Avg Loss: 5.5627, Avg Regression Loss 1.9855, Avg Classification Loss: 3.5773
2021-05-21 20:41:48 - Epoch: 13, Step: 150/502, Avg Loss: 5.4813, Avg Regression Loss 2.1400, Avg Classification Loss: 3.3413
2021-05-21 20:42:00 - Epoch: 13, Step: 160/502, Avg Loss: 5.0480, Avg Regression Loss 1.6050, Avg Classification Loss: 3.4431
2021-05-21 20:42:05 - Epoch: 13, Step: 170/502, Avg Loss: 5.3793, Avg Regression Loss 2.0161, Avg Classification Loss: 3.3632
2021-05-21 20:42:10 - Epoch: 13, Step: 180/502, Avg Loss: 5.4124, Avg Regression Loss 2.0811, Avg Classification Loss: 3.3313
2021-05-21 20:42:15 - Epoch: 13, Step: 190/502, Avg Loss: 5.3952, Avg Regression Loss 1.9813, Avg Classification Loss: 3.4139
2021-05-21 20:42:19 - Epoch: 13, Step: 200/502, Avg Loss: 5.0676, Avg Regression Loss 1.6947, Avg Classification Loss: 3.3728
2021-05-21 20:42:24 - Epoch: 13, Step: 210/502, Avg Loss: 4.8383, Avg Regression Loss 1.4846, Avg Classification Loss: 3.3537
2021-05-21 20:42:29 - Epoch: 13, Step: 220/502, Avg Loss: 5.3865, Avg Regression Loss 1.8991, Avg Classification Loss: 3.4874
2021-05-21 20:42:35 - Epoch: 13, Step: 230/502, Avg Loss: 5.3098, Avg Regression Loss 1.9048, Avg Classification Loss: 3.4050
2021-05-21 20:42:40 - Epoch: 13, Step: 240/502, Avg Loss: 4.9150, Avg Regression Loss 1.5238, Avg Classification Loss: 3.3912
2021-05-21 20:42:48 - Epoch: 13, Step: 250/502, Avg Loss: 4.6915, Avg Regression Loss 1.2498, Avg Classification Loss: 3.4417
2021-05-21 20:42:53 - Epoch: 13, Step: 260/502, Avg Loss: 4.9119, Avg Regression Loss 1.4928, Avg Classification Loss: 3.4191
2021-05-21 20:42:58 - Epoch: 13, Step: 270/502, Avg Loss: 4.8887, Avg Regression Loss 1.5201, Avg Classification Loss: 3.3686
2021-05-21 20:43:04 - Epoch: 13, Step: 280/502, Avg Loss: 5.9364, Avg Regression Loss 2.6665, Avg Classification Loss: 3.2699
2021-05-21 20:43:08 - Epoch: 13, Step: 290/502, Avg Loss: 4.8349, Avg Regression Loss 1.4776, Avg Classification Loss: 3.3574
2021-05-21 20:43:15 - Epoch: 13, Step: 300/502, Avg Loss: 5.5122, Avg Regression Loss 1.9462, Avg Classification Loss: 3.5660
2021-05-21 20:43:20 - Epoch: 13, Step: 310/502, Avg Loss: 4.2118, Avg Regression Loss 1.0789, Avg Classification Loss: 3.1329
2021-05-21 20:43:24 - Epoch: 13, Step: 320/502, Avg Loss: 4.4044, Avg Regression Loss 1.1757, Avg Classification Loss: 3.2287
2021-05-21 20:43:29 - Epoch: 13, Step: 330/502, Avg Loss: 5.5101, Avg Regression Loss 2.0517, Avg Classification Loss: 3.4584
2021-05-21 20:43:34 - Epoch: 13, Step: 340/502, Avg Loss: 5.0193, Avg Regression Loss 1.5603, Avg Classification Loss: 3.4590
2021-05-21 20:43:38 - Epoch: 13, Step: 350/502, Avg Loss: 4.7659, Avg Regression Loss 1.4961, Avg Classification Loss: 3.2698
2021-05-21 20:43:43 - Epoch: 13, Step: 360/502, Avg Loss: 5.2603, Avg Regression Loss 1.6514, Avg Classification Loss: 3.6089
2021-05-21 20:43:49 - Epoch: 13, Step: 370/502, Avg Loss: 5.5686, Avg Regression Loss 1.9941, Avg Classification Loss: 3.5745
2021-05-21 20:44:00 - Epoch: 13, Step: 380/502, Avg Loss: 6.0528, Avg Regression Loss 2.6760, Avg Classification Loss: 3.3767
2021-05-21 20:44:04 - Epoch: 13, Step: 390/502, Avg Loss: 5.1919, Avg Regression Loss 1.8547, Avg Classification Loss: 3.3372
2021-05-21 20:44:10 - Epoch: 13, Step: 400/502, Avg Loss: 5.5865, Avg Regression Loss 2.3392, Avg Classification Loss: 3.2473
2021-05-21 20:44:15 - Epoch: 13, Step: 410/502, Avg Loss: 5.3218, Avg Regression Loss 1.8371, Avg Classification Loss: 3.4847
2021-05-21 20:44:21 - Epoch: 13, Step: 420/502, Avg Loss: 5.4683, Avg Regression Loss 1.9410, Avg Classification Loss: 3.5273
2021-05-21 20:44:25 - Epoch: 13, Step: 430/502, Avg Loss: 5.3149, Avg Regression Loss 1.9125, Avg Classification Loss: 3.4024
2021-05-21 20:44:30 - Epoch: 13, Step: 440/502, Avg Loss: 5.4058, Avg Regression Loss 2.0770, Avg Classification Loss: 3.3288
2021-05-21 20:44:36 - Epoch: 13, Step: 450/502, Avg Loss: 5.4485, Avg Regression Loss 2.1570, Avg Classification Loss: 3.2916
2021-05-21 20:44:41 - Epoch: 13, Step: 460/502, Avg Loss: 5.1061, Avg Regression Loss 1.8439, Avg Classification Loss: 3.2622
2021-05-21 20:44:46 - Epoch: 13, Step: 470/502, Avg Loss: 5.0316, Avg Regression Loss 1.8722, Avg Classification Loss: 3.1593
2021-05-21 20:44:51 - Epoch: 13, Step: 480/502, Avg Loss: 5.4443, Avg Regression Loss 2.0177, Avg Classification Loss: 3.4266
2021-05-21 20:44:56 - Epoch: 13, Step: 490/502, Avg Loss: 5.1817, Avg Regression Loss 1.7732, Avg Classification Loss: 3.4085
2021-05-21 20:45:01 - Epoch: 13, Step: 500/502, Avg Loss: 5.7922, Avg Regression Loss 2.3723, Avg Classification Loss: 3.4199
2021-05-21 20:46:01 - Epoch: 13, Validation Loss: 4.3681, Validation Regression Loss 1.0776, Validation Classification Loss: 3.2905
2021-05-21 20:46:02 - Saved model models/smd/mb1-ssd-Epoch-13-Loss-4.368092726901233.pth
2021-05-21 20:46:08 - Epoch: 14, Step: 10/502, Avg Loss: 6.1600, Avg Regression Loss 2.4309, Avg Classification Loss: 3.7291
2021-05-21 20:46:14 - Epoch: 14, Step: 20/502, Avg Loss: 5.3621, Avg Regression Loss 1.8357, Avg Classification Loss: 3.5263
2021-05-21 20:46:19 - Epoch: 14, Step: 30/502, Avg Loss: 4.9917, Avg Regression Loss 1.4616, Avg Classification Loss: 3.5302
2021-05-21 20:46:24 - Epoch: 14, Step: 40/502, Avg Loss: 4.7862, Avg Regression Loss 1.3574, Avg Classification Loss: 3.4288
2021-05-21 20:46:30 - Epoch: 14, Step: 50/502, Avg Loss: 5.6797, Avg Regression Loss 2.1001, Avg Classification Loss: 3.5796
2021-05-21 20:46:35 - Epoch: 14, Step: 60/502, Avg Loss: 5.5768, Avg Regression Loss 2.2256, Avg Classification Loss: 3.3512
2021-05-21 20:46:41 - Epoch: 14, Step: 70/502, Avg Loss: 5.2890, Avg Regression Loss 1.8745, Avg Classification Loss: 3.4145
2021-05-21 20:46:48 - Epoch: 14, Step: 80/502, Avg Loss: 5.3617, Avg Regression Loss 1.9480, Avg Classification Loss: 3.4137
2021-05-21 20:46:53 - Epoch: 14, Step: 90/502, Avg Loss: 5.2708, Avg Regression Loss 1.9224, Avg Classification Loss: 3.3484
2021-05-21 20:46:57 - Epoch: 14, Step: 100/502, Avg Loss: 5.2597, Avg Regression Loss 1.9496, Avg Classification Loss: 3.3101
2021-05-21 20:47:08 - Epoch: 14, Step: 110/502, Avg Loss: 4.4720, Avg Regression Loss 1.3074, Avg Classification Loss: 3.1646
2021-05-21 20:47:13 - Epoch: 14, Step: 120/502, Avg Loss: 4.9777, Avg Regression Loss 1.7357, Avg Classification Loss: 3.2420
2021-05-21 20:47:18 - Epoch: 14, Step: 130/502, Avg Loss: 5.2544, Avg Regression Loss 1.8707, Avg Classification Loss: 3.3837
2021-05-21 20:47:27 - Epoch: 14, Step: 140/502, Avg Loss: 5.1900, Avg Regression Loss 1.6838, Avg Classification Loss: 3.5062
2021-05-21 20:47:36 - Epoch: 14, Step: 150/502, Avg Loss: 4.6973, Avg Regression Loss 1.3394, Avg Classification Loss: 3.3579
2021-05-21 20:47:42 - Epoch: 14, Step: 160/502, Avg Loss: 5.2632, Avg Regression Loss 2.0476, Avg Classification Loss: 3.2156
2021-05-21 20:47:46 - Epoch: 14, Step: 170/502, Avg Loss: 5.3930, Avg Regression Loss 1.9471, Avg Classification Loss: 3.4458
2021-05-21 20:47:51 - Epoch: 14, Step: 180/502, Avg Loss: 4.7857, Avg Regression Loss 1.4362, Avg Classification Loss: 3.3494
2021-05-21 20:47:56 - Epoch: 14, Step: 190/502, Avg Loss: 5.8400, Avg Regression Loss 2.4746, Avg Classification Loss: 3.3654
2021-05-21 20:48:00 - Epoch: 14, Step: 200/502, Avg Loss: 4.5481, Avg Regression Loss 1.1605, Avg Classification Loss: 3.3876
2021-05-21 20:48:06 - Epoch: 14, Step: 210/502, Avg Loss: 5.7347, Avg Regression Loss 2.1612, Avg Classification Loss: 3.5734
2021-05-21 20:48:17 - Epoch: 14, Step: 220/502, Avg Loss: 5.3462, Avg Regression Loss 2.1112, Avg Classification Loss: 3.2350
2021-05-21 20:48:22 - Epoch: 14, Step: 230/502, Avg Loss: 4.8009, Avg Regression Loss 1.6849, Avg Classification Loss: 3.1160
2021-05-21 20:48:27 - Epoch: 14, Step: 240/502, Avg Loss: 5.0800, Avg Regression Loss 1.7142, Avg Classification Loss: 3.3657
2021-05-21 20:48:33 - Epoch: 14, Step: 250/502, Avg Loss: 4.9864, Avg Regression Loss 1.5914, Avg Classification Loss: 3.3950
2021-05-21 20:48:38 - Epoch: 14, Step: 260/502, Avg Loss: 5.1011, Avg Regression Loss 1.5540, Avg Classification Loss: 3.5470
2021-05-21 20:48:48 - Epoch: 14, Step: 270/502, Avg Loss: 4.5881, Avg Regression Loss 1.3423, Avg Classification Loss: 3.2458
2021-05-21 20:48:53 - Epoch: 14, Step: 280/502, Avg Loss: 4.6844, Avg Regression Loss 1.4641, Avg Classification Loss: 3.2204
2021-05-21 20:48:58 - Epoch: 14, Step: 290/502, Avg Loss: 5.1515, Avg Regression Loss 1.7002, Avg Classification Loss: 3.4513
2021-05-21 20:49:03 - Epoch: 14, Step: 300/502, Avg Loss: 5.0182, Avg Regression Loss 1.7647, Avg Classification Loss: 3.2535
2021-05-21 20:49:07 - Epoch: 14, Step: 310/502, Avg Loss: 4.3561, Avg Regression Loss 1.1025, Avg Classification Loss: 3.2536
2021-05-21 20:49:12 - Epoch: 14, Step: 320/502, Avg Loss: 4.9934, Avg Regression Loss 1.8681, Avg Classification Loss: 3.1253
2021-05-21 20:49:17 - Epoch: 14, Step: 330/502, Avg Loss: 5.4967, Avg Regression Loss 1.9715, Avg Classification Loss: 3.5253
2021-05-21 20:49:23 - Epoch: 14, Step: 340/502, Avg Loss: 4.9954, Avg Regression Loss 1.6308, Avg Classification Loss: 3.3646
2021-05-21 20:49:28 - Epoch: 14, Step: 350/502, Avg Loss: 4.9296, Avg Regression Loss 1.6701, Avg Classification Loss: 3.2596
2021-05-21 20:49:38 - Epoch: 14, Step: 360/502, Avg Loss: 4.8983, Avg Regression Loss 1.5086, Avg Classification Loss: 3.3897
2021-05-21 20:49:43 - Epoch: 14, Step: 370/502, Avg Loss: 5.1148, Avg Regression Loss 1.7178, Avg Classification Loss: 3.3970
2021-05-21 20:49:48 - Epoch: 14, Step: 380/502, Avg Loss: 4.9301, Avg Regression Loss 1.6084, Avg Classification Loss: 3.3217
2021-05-21 20:49:52 - Epoch: 14, Step: 390/502, Avg Loss: 5.1014, Avg Regression Loss 1.7076, Avg Classification Loss: 3.3938
2021-05-21 20:49:57 - Epoch: 14, Step: 400/502, Avg Loss: 5.2603, Avg Regression Loss 1.9469, Avg Classification Loss: 3.3133
2021-05-21 20:50:02 - Epoch: 14, Step: 410/502, Avg Loss: 5.3372, Avg Regression Loss 1.8029, Avg Classification Loss: 3.5344
2021-05-21 20:50:08 - Epoch: 14, Step: 420/502, Avg Loss: 4.4317, Avg Regression Loss 1.2735, Avg Classification Loss: 3.1582
2021-05-21 20:50:13 - Epoch: 14, Step: 430/502, Avg Loss: 4.9038, Avg Regression Loss 1.5309, Avg Classification Loss: 3.3729
2021-05-21 20:50:18 - Epoch: 14, Step: 440/502, Avg Loss: 5.0327, Avg Regression Loss 1.5990, Avg Classification Loss: 3.4337
2021-05-21 20:50:23 - Epoch: 14, Step: 450/502, Avg Loss: 5.4487, Avg Regression Loss 2.0981, Avg Classification Loss: 3.3506
2021-05-21 20:50:27 - Epoch: 14, Step: 460/502, Avg Loss: 4.9102, Avg Regression Loss 1.6859, Avg Classification Loss: 3.2244
2021-05-21 20:50:32 - Epoch: 14, Step: 470/502, Avg Loss: 4.7283, Avg Regression Loss 1.4420, Avg Classification Loss: 3.2863
2021-05-21 20:50:42 - Epoch: 14, Step: 480/502, Avg Loss: 4.8405, Avg Regression Loss 1.5426, Avg Classification Loss: 3.2979
2021-05-21 20:50:47 - Epoch: 14, Step: 490/502, Avg Loss: 5.3617, Avg Regression Loss 2.1029, Avg Classification Loss: 3.2588
2021-05-21 20:50:52 - Epoch: 14, Step: 500/502, Avg Loss: 5.2717, Avg Regression Loss 1.8916, Avg Classification Loss: 3.3801
2021-05-21 20:51:54 - Epoch: 14, Validation Loss: 4.5121, Validation Regression Loss 1.2920, Validation Classification Loss: 3.2202
2021-05-21 20:51:54 - Saved model models/smd/mb1-ssd-Epoch-14-Loss-4.512124897474312.pth
2021-05-21 20:52:00 - Epoch: 15, Step: 10/502, Avg Loss: 5.6123, Avg Regression Loss 1.8317, Avg Classification Loss: 3.7806
2021-05-21 20:52:05 - Epoch: 15, Step: 20/502, Avg Loss: 5.3119, Avg Regression Loss 1.9570, Avg Classification Loss: 3.3549
2021-05-21 20:52:10 - Epoch: 15, Step: 30/502, Avg Loss: 5.6008, Avg Regression Loss 2.0955, Avg Classification Loss: 3.5053
2021-05-21 20:52:15 - Epoch: 15, Step: 40/502, Avg Loss: 5.2907, Avg Regression Loss 2.0037, Avg Classification Loss: 3.2870
2021-05-21 20:52:19 - Epoch: 15, Step: 50/502, Avg Loss: 5.2795, Avg Regression Loss 1.7073, Avg Classification Loss: 3.5722
2021-05-21 20:52:25 - Epoch: 15, Step: 60/502, Avg Loss: 5.1785, Avg Regression Loss 1.8509, Avg Classification Loss: 3.3275
2021-05-21 20:52:32 - Epoch: 15, Step: 70/502, Avg Loss: 5.8927, Avg Regression Loss 2.4765, Avg Classification Loss: 3.4163
2021-05-21 20:52:36 - Epoch: 15, Step: 80/502, Avg Loss: 5.3163, Avg Regression Loss 1.9994, Avg Classification Loss: 3.3169
2021-05-21 20:52:41 - Epoch: 15, Step: 90/502, Avg Loss: 5.0077, Avg Regression Loss 1.6435, Avg Classification Loss: 3.3641
2021-05-21 20:52:47 - Epoch: 15, Step: 100/502, Avg Loss: 4.9756, Avg Regression Loss 1.6041, Avg Classification Loss: 3.3715
2021-05-21 20:52:53 - Epoch: 15, Step: 110/502, Avg Loss: 5.1287, Avg Regression Loss 1.6578, Avg Classification Loss: 3.4709
2021-05-21 20:52:58 - Epoch: 15, Step: 120/502, Avg Loss: 5.2795, Avg Regression Loss 1.8419, Avg Classification Loss: 3.4376
2021-05-21 20:53:02 - Epoch: 15, Step: 130/502, Avg Loss: 4.8779, Avg Regression Loss 1.6587, Avg Classification Loss: 3.2192
2021-05-21 20:53:07 - Epoch: 15, Step: 140/502, Avg Loss: 5.9392, Avg Regression Loss 2.4341, Avg Classification Loss: 3.5051
2021-05-21 20:53:12 - Epoch: 15, Step: 150/502, Avg Loss: 5.4026, Avg Regression Loss 1.9055, Avg Classification Loss: 3.4971
2021-05-21 20:53:18 - Epoch: 15, Step: 160/502, Avg Loss: 5.1555, Avg Regression Loss 1.8190, Avg Classification Loss: 3.3365
2021-05-21 20:53:22 - Epoch: 15, Step: 170/502, Avg Loss: 4.5051, Avg Regression Loss 1.1178, Avg Classification Loss: 3.3873
2021-05-21 20:53:27 - Epoch: 15, Step: 180/502, Avg Loss: 4.5741, Avg Regression Loss 1.2916, Avg Classification Loss: 3.2825
2021-05-21 20:53:36 - Epoch: 15, Step: 190/502, Avg Loss: 5.4777, Avg Regression Loss 1.8678, Avg Classification Loss: 3.6099
2021-05-21 20:53:41 - Epoch: 15, Step: 200/502, Avg Loss: 5.2903, Avg Regression Loss 1.7920, Avg Classification Loss: 3.4982
2021-05-21 20:53:45 - Epoch: 15, Step: 210/502, Avg Loss: 4.9480, Avg Regression Loss 1.6487, Avg Classification Loss: 3.2993
2021-05-21 20:54:01 - Epoch: 15, Step: 220/502, Avg Loss: 5.2077, Avg Regression Loss 1.8168, Avg Classification Loss: 3.3909
2021-05-21 20:54:07 - Epoch: 15, Step: 230/502, Avg Loss: 4.5339, Avg Regression Loss 1.2864, Avg Classification Loss: 3.2475
2021-05-21 20:54:11 - Epoch: 15, Step: 240/502, Avg Loss: 5.3219, Avg Regression Loss 2.1652, Avg Classification Loss: 3.1568
2021-05-21 20:54:17 - Epoch: 15, Step: 250/502, Avg Loss: 5.0967, Avg Regression Loss 1.8684, Avg Classification Loss: 3.2283
2021-05-21 20:54:22 - Epoch: 15, Step: 260/502, Avg Loss: 5.0306, Avg Regression Loss 1.7662, Avg Classification Loss: 3.2644
2021-05-21 20:54:26 - Epoch: 15, Step: 270/502, Avg Loss: 5.2847, Avg Regression Loss 1.9674, Avg Classification Loss: 3.3173
2021-05-21 20:54:31 - Epoch: 15, Step: 280/502, Avg Loss: 4.3732, Avg Regression Loss 1.2944, Avg Classification Loss: 3.0787
2021-05-21 20:54:42 - Epoch: 15, Step: 290/502, Avg Loss: 5.6272, Avg Regression Loss 2.2390, Avg Classification Loss: 3.3882
2021-05-21 20:54:47 - Epoch: 15, Step: 300/502, Avg Loss: 5.2131, Avg Regression Loss 1.9426, Avg Classification Loss: 3.2705
2021-05-21 20:54:52 - Epoch: 15, Step: 310/502, Avg Loss: 5.2682, Avg Regression Loss 1.8810, Avg Classification Loss: 3.3871
2021-05-21 20:54:57 - Epoch: 15, Step: 320/502, Avg Loss: 5.3782, Avg Regression Loss 1.9697, Avg Classification Loss: 3.4086
2021-05-21 20:55:03 - Epoch: 15, Step: 330/502, Avg Loss: 6.4276, Avg Regression Loss 2.9107, Avg Classification Loss: 3.5169
2021-05-21 20:55:08 - Epoch: 15, Step: 340/502, Avg Loss: 5.3560, Avg Regression Loss 2.1012, Avg Classification Loss: 3.2548
2021-05-21 20:55:13 - Epoch: 15, Step: 350/502, Avg Loss: 5.4843, Avg Regression Loss 2.1245, Avg Classification Loss: 3.3598
2021-05-21 20:55:23 - Epoch: 15, Step: 360/502, Avg Loss: 5.5747, Avg Regression Loss 2.1889, Avg Classification Loss: 3.3858
2021-05-21 20:55:27 - Epoch: 15, Step: 370/502, Avg Loss: 5.2685, Avg Regression Loss 1.8413, Avg Classification Loss: 3.4272
2021-05-21 20:55:32 - Epoch: 15, Step: 380/502, Avg Loss: 6.2828, Avg Regression Loss 2.8610, Avg Classification Loss: 3.4218
2021-05-21 20:55:37 - Epoch: 15, Step: 390/502, Avg Loss: 5.2575, Avg Regression Loss 1.9281, Avg Classification Loss: 3.3294
2021-05-21 20:55:42 - Epoch: 15, Step: 400/502, Avg Loss: 5.2704, Avg Regression Loss 1.8878, Avg Classification Loss: 3.3827
2021-05-21 20:55:47 - Epoch: 15, Step: 410/502, Avg Loss: 4.9452, Avg Regression Loss 1.5448, Avg Classification Loss: 3.4004
2021-05-21 20:55:52 - Epoch: 15, Step: 420/502, Avg Loss: 4.8342, Avg Regression Loss 1.7210, Avg Classification Loss: 3.1132
2021-05-21 20:55:57 - Epoch: 15, Step: 430/502, Avg Loss: 4.8485, Avg Regression Loss 1.5406, Avg Classification Loss: 3.3079
2021-05-21 20:56:02 - Epoch: 15, Step: 440/502, Avg Loss: 4.7502, Avg Regression Loss 1.5140, Avg Classification Loss: 3.2363
2021-05-21 20:56:06 - Epoch: 15, Step: 450/502, Avg Loss: 4.6416, Avg Regression Loss 1.5346, Avg Classification Loss: 3.1070
2021-05-21 20:56:15 - Epoch: 15, Step: 460/502, Avg Loss: 5.0913, Avg Regression Loss 1.7649, Avg Classification Loss: 3.3265
2021-05-21 20:56:21 - Epoch: 15, Step: 470/502, Avg Loss: 5.3507, Avg Regression Loss 1.9089, Avg Classification Loss: 3.4418
2021-05-21 20:56:25 - Epoch: 15, Step: 480/502, Avg Loss: 4.9914, Avg Regression Loss 1.6087, Avg Classification Loss: 3.3827
2021-05-21 20:56:31 - Epoch: 15, Step: 490/502, Avg Loss: 4.6873, Avg Regression Loss 1.4341, Avg Classification Loss: 3.2532
2021-05-21 20:56:36 - Epoch: 15, Step: 500/502, Avg Loss: 5.0870, Avg Regression Loss 1.6555, Avg Classification Loss: 3.4315
2021-05-21 20:57:38 - Epoch: 15, Validation Loss: 4.5149, Validation Regression Loss 1.1544, Validation Classification Loss: 3.3605
2021-05-21 20:57:38 - Saved model models/smd/mb1-ssd-Epoch-15-Loss-4.514851388228367.pth
2021-05-21 20:57:44 - Epoch: 16, Step: 10/502, Avg Loss: 5.1303, Avg Regression Loss 1.5763, Avg Classification Loss: 3.5539
2021-05-21 20:57:52 - Epoch: 16, Step: 20/502, Avg Loss: 5.2474, Avg Regression Loss 1.8393, Avg Classification Loss: 3.4082
2021-05-21 20:57:57 - Epoch: 16, Step: 30/502, Avg Loss: 5.2683, Avg Regression Loss 2.1141, Avg Classification Loss: 3.1543
2021-05-21 20:58:02 - Epoch: 16, Step: 40/502, Avg Loss: 5.4844, Avg Regression Loss 2.0163, Avg Classification Loss: 3.4681
2021-05-21 20:58:06 - Epoch: 16, Step: 50/502, Avg Loss: 5.5229, Avg Regression Loss 2.1338, Avg Classification Loss: 3.3892
2021-05-21 20:58:11 - Epoch: 16, Step: 60/502, Avg Loss: 4.9287, Avg Regression Loss 1.4378, Avg Classification Loss: 3.4909
2021-05-21 20:58:16 - Epoch: 16, Step: 70/502, Avg Loss: 5.3827, Avg Regression Loss 1.8806, Avg Classification Loss: 3.5021
2021-05-21 20:58:21 - Epoch: 16, Step: 80/502, Avg Loss: 5.5117, Avg Regression Loss 2.0065, Avg Classification Loss: 3.5052
2021-05-21 20:58:27 - Epoch: 16, Step: 90/502, Avg Loss: 5.4436, Avg Regression Loss 1.8569, Avg Classification Loss: 3.5867
2021-05-21 20:58:32 - Epoch: 16, Step: 100/502, Avg Loss: 4.3245, Avg Regression Loss 1.2628, Avg Classification Loss: 3.0617
2021-05-21 20:58:37 - Epoch: 16, Step: 110/502, Avg Loss: 4.4293, Avg Regression Loss 1.2666, Avg Classification Loss: 3.1627
2021-05-21 20:58:41 - Epoch: 16, Step: 120/502, Avg Loss: 5.0872, Avg Regression Loss 1.6341, Avg Classification Loss: 3.4531
2021-05-21 20:58:46 - Epoch: 16, Step: 130/502, Avg Loss: 4.5446, Avg Regression Loss 1.2164, Avg Classification Loss: 3.3282
2021-05-21 20:58:51 - Epoch: 16, Step: 140/502, Avg Loss: 4.8927, Avg Regression Loss 1.5817, Avg Classification Loss: 3.3110
2021-05-21 20:58:56 - Epoch: 16, Step: 150/502, Avg Loss: 4.8900, Avg Regression Loss 1.3787, Avg Classification Loss: 3.5113
2021-05-21 20:59:17 - Epoch: 16, Step: 160/502, Avg Loss: 5.4916, Avg Regression Loss 2.2786, Avg Classification Loss: 3.2129
2021-05-21 20:59:22 - Epoch: 16, Step: 170/502, Avg Loss: 5.1327, Avg Regression Loss 1.6708, Avg Classification Loss: 3.4619
2021-05-21 20:59:26 - Epoch: 16, Step: 180/502, Avg Loss: 5.0937, Avg Regression Loss 1.6831, Avg Classification Loss: 3.4107
2021-05-21 20:59:31 - Epoch: 16, Step: 190/502, Avg Loss: 5.7040, Avg Regression Loss 2.1189, Avg Classification Loss: 3.5850
2021-05-21 20:59:43 - Epoch: 16, Step: 200/502, Avg Loss: 6.8278, Avg Regression Loss 3.2578, Avg Classification Loss: 3.5700
2021-05-21 20:59:48 - Epoch: 16, Step: 210/502, Avg Loss: 5.0572, Avg Regression Loss 1.7225, Avg Classification Loss: 3.3347
2021-05-21 20:59:56 - Epoch: 16, Step: 220/502, Avg Loss: 5.0342, Avg Regression Loss 1.7261, Avg Classification Loss: 3.3081
2021-05-21 21:00:01 - Epoch: 16, Step: 230/502, Avg Loss: 4.9433, Avg Regression Loss 1.4195, Avg Classification Loss: 3.5238
2021-05-21 21:00:06 - Epoch: 16, Step: 240/502, Avg Loss: 5.2907, Avg Regression Loss 1.9136, Avg Classification Loss: 3.3770
2021-05-21 21:00:11 - Epoch: 16, Step: 250/502, Avg Loss: 4.9790, Avg Regression Loss 1.6790, Avg Classification Loss: 3.3001
2021-05-21 21:00:16 - Epoch: 16, Step: 260/502, Avg Loss: 5.1509, Avg Regression Loss 1.7801, Avg Classification Loss: 3.3708
2021-05-21 21:00:21 - Epoch: 16, Step: 270/502, Avg Loss: 5.0193, Avg Regression Loss 1.7284, Avg Classification Loss: 3.2909
2021-05-21 21:00:25 - Epoch: 16, Step: 280/502, Avg Loss: 4.4793, Avg Regression Loss 1.2016, Avg Classification Loss: 3.2777
2021-05-21 21:00:34 - Epoch: 16, Step: 290/502, Avg Loss: 4.5976, Avg Regression Loss 1.4593, Avg Classification Loss: 3.1383
2021-05-21 21:00:39 - Epoch: 16, Step: 300/502, Avg Loss: 4.5586, Avg Regression Loss 1.2525, Avg Classification Loss: 3.3062
2021-05-21 21:00:44 - Epoch: 16, Step: 310/502, Avg Loss: 5.4244, Avg Regression Loss 2.0254, Avg Classification Loss: 3.3989
2021-05-21 21:00:49 - Epoch: 16, Step: 320/502, Avg Loss: 4.1278, Avg Regression Loss 0.8473, Avg Classification Loss: 3.2806
2021-05-21 21:00:53 - Epoch: 16, Step: 330/502, Avg Loss: 4.4468, Avg Regression Loss 1.3740, Avg Classification Loss: 3.0728
2021-05-21 21:00:58 - Epoch: 16, Step: 340/502, Avg Loss: 4.4585, Avg Regression Loss 1.2249, Avg Classification Loss: 3.2336
2021-05-21 21:01:03 - Epoch: 16, Step: 350/502, Avg Loss: 4.6039, Avg Regression Loss 1.2014, Avg Classification Loss: 3.4025
2021-05-21 21:01:08 - Epoch: 16, Step: 360/502, Avg Loss: 4.8225, Avg Regression Loss 1.5642, Avg Classification Loss: 3.2582
2021-05-21 21:01:13 - Epoch: 16, Step: 370/502, Avg Loss: 5.3605, Avg Regression Loss 2.0376, Avg Classification Loss: 3.3229
2021-05-21 21:01:19 - Epoch: 16, Step: 380/502, Avg Loss: 5.8283, Avg Regression Loss 2.3375, Avg Classification Loss: 3.4907
2021-05-21 21:01:24 - Epoch: 16, Step: 390/502, Avg Loss: 4.9806, Avg Regression Loss 1.5802, Avg Classification Loss: 3.4003
2021-05-21 21:01:29 - Epoch: 16, Step: 400/502, Avg Loss: 4.7340, Avg Regression Loss 1.3225, Avg Classification Loss: 3.4115
2021-05-21 21:01:35 - Epoch: 16, Step: 410/502, Avg Loss: 5.3461, Avg Regression Loss 1.9057, Avg Classification Loss: 3.4403
2021-05-21 21:01:40 - Epoch: 16, Step: 420/502, Avg Loss: 4.5260, Avg Regression Loss 1.2635, Avg Classification Loss: 3.2625
2021-05-21 21:01:45 - Epoch: 16, Step: 430/502, Avg Loss: 5.9475, Avg Regression Loss 2.3349, Avg Classification Loss: 3.6126
2021-05-21 21:01:50 - Epoch: 16, Step: 440/502, Avg Loss: 5.2094, Avg Regression Loss 1.5277, Avg Classification Loss: 3.6817
2021-05-21 21:01:55 - Epoch: 16, Step: 450/502, Avg Loss: 5.6382, Avg Regression Loss 2.1498, Avg Classification Loss: 3.4884
2021-05-21 21:02:02 - Epoch: 16, Step: 460/502, Avg Loss: 5.1132, Avg Regression Loss 1.8043, Avg Classification Loss: 3.3089
2021-05-21 21:02:07 - Epoch: 16, Step: 470/502, Avg Loss: 5.1119, Avg Regression Loss 1.7077, Avg Classification Loss: 3.4042
2021-05-21 21:02:18 - Epoch: 16, Step: 480/502, Avg Loss: 5.2535, Avg Regression Loss 2.1288, Avg Classification Loss: 3.1246
2021-05-21 21:02:22 - Epoch: 16, Step: 490/502, Avg Loss: 4.7406, Avg Regression Loss 1.5635, Avg Classification Loss: 3.1772
2021-05-21 21:02:27 - Epoch: 16, Step: 500/502, Avg Loss: 4.9458, Avg Regression Loss 1.4767, Avg Classification Loss: 3.4691
2021-05-21 21:03:28 - Epoch: 16, Validation Loss: 4.5450, Validation Regression Loss 1.2819, Validation Classification Loss: 3.2631
2021-05-21 21:03:29 - Saved model models/smd/mb1-ssd-Epoch-16-Loss-4.544968772219471.pth
2021-05-21 21:03:34 - Epoch: 17, Step: 10/502, Avg Loss: 5.0191, Avg Regression Loss 1.4005, Avg Classification Loss: 3.6186
2021-05-21 21:03:42 - Epoch: 17, Step: 20/502, Avg Loss: 4.3670, Avg Regression Loss 1.1155, Avg Classification Loss: 3.2515
2021-05-21 21:03:47 - Epoch: 17, Step: 30/502, Avg Loss: 5.1413, Avg Regression Loss 1.8113, Avg Classification Loss: 3.3300
2021-05-21 21:03:52 - Epoch: 17, Step: 40/502, Avg Loss: 5.4246, Avg Regression Loss 1.9342, Avg Classification Loss: 3.4904
2021-05-21 21:03:57 - Epoch: 17, Step: 50/502, Avg Loss: 5.7678, Avg Regression Loss 2.4266, Avg Classification Loss: 3.3411
2021-05-21 21:04:03 - Epoch: 17, Step: 60/502, Avg Loss: 4.9907, Avg Regression Loss 1.7032, Avg Classification Loss: 3.2875
2021-05-21 21:04:07 - Epoch: 17, Step: 70/502, Avg Loss: 4.4779, Avg Regression Loss 1.2120, Avg Classification Loss: 3.2659
2021-05-21 21:04:12 - Epoch: 17, Step: 80/502, Avg Loss: 5.0911, Avg Regression Loss 1.8899, Avg Classification Loss: 3.2012
2021-05-21 21:04:18 - Epoch: 17, Step: 90/502, Avg Loss: 5.2238, Avg Regression Loss 1.7310, Avg Classification Loss: 3.4928
2021-05-21 21:04:23 - Epoch: 17, Step: 100/502, Avg Loss: 4.9598, Avg Regression Loss 1.6453, Avg Classification Loss: 3.3145
2021-05-21 21:04:27 - Epoch: 17, Step: 110/502, Avg Loss: 4.9140, Avg Regression Loss 1.6909, Avg Classification Loss: 3.2231
2021-05-21 21:04:32 - Epoch: 17, Step: 120/502, Avg Loss: 5.8114, Avg Regression Loss 2.5714, Avg Classification Loss: 3.2400
2021-05-21 21:04:38 - Epoch: 17, Step: 130/502, Avg Loss: 5.1376, Avg Regression Loss 1.7610, Avg Classification Loss: 3.3767
2021-05-21 21:04:43 - Epoch: 17, Step: 140/502, Avg Loss: 5.1134, Avg Regression Loss 1.7397, Avg Classification Loss: 3.3737
2021-05-21 21:04:48 - Epoch: 17, Step: 150/502, Avg Loss: 4.7479, Avg Regression Loss 1.5681, Avg Classification Loss: 3.1798
2021-05-21 21:05:04 - Epoch: 17, Step: 160/502, Avg Loss: 5.2211, Avg Regression Loss 1.8958, Avg Classification Loss: 3.3252
2021-05-21 21:05:09 - Epoch: 17, Step: 170/502, Avg Loss: 5.3145, Avg Regression Loss 2.0938, Avg Classification Loss: 3.2207
2021-05-21 21:05:14 - Epoch: 17, Step: 180/502, Avg Loss: 4.6223, Avg Regression Loss 1.2825, Avg Classification Loss: 3.3399
2021-05-21 21:05:19 - Epoch: 17, Step: 190/502, Avg Loss: 5.3525, Avg Regression Loss 2.0439, Avg Classification Loss: 3.3086
2021-05-21 21:05:23 - Epoch: 17, Step: 200/502, Avg Loss: 4.6068, Avg Regression Loss 1.4900, Avg Classification Loss: 3.1168
2021-05-21 21:05:28 - Epoch: 17, Step: 210/502, Avg Loss: 4.7161, Avg Regression Loss 1.3922, Avg Classification Loss: 3.3239
2021-05-21 21:05:32 - Epoch: 17, Step: 220/502, Avg Loss: 5.0163, Avg Regression Loss 1.7901, Avg Classification Loss: 3.2263
2021-05-21 21:05:40 - Epoch: 17, Step: 230/502, Avg Loss: 5.0798, Avg Regression Loss 1.8023, Avg Classification Loss: 3.2775
2021-05-21 21:05:45 - Epoch: 17, Step: 240/502, Avg Loss: 4.9621, Avg Regression Loss 1.5121, Avg Classification Loss: 3.4500
2021-05-21 21:05:50 - Epoch: 17, Step: 250/502, Avg Loss: 4.5013, Avg Regression Loss 1.2568, Avg Classification Loss: 3.2445
2021-05-21 21:05:55 - Epoch: 17, Step: 260/502, Avg Loss: 4.8536, Avg Regression Loss 1.4083, Avg Classification Loss: 3.4453
2021-05-21 21:06:00 - Epoch: 17, Step: 270/502, Avg Loss: 4.6874, Avg Regression Loss 1.4551, Avg Classification Loss: 3.2324
2021-05-21 21:06:05 - Epoch: 17, Step: 280/502, Avg Loss: 4.8351, Avg Regression Loss 1.4698, Avg Classification Loss: 3.3654
2021-05-21 21:06:09 - Epoch: 17, Step: 290/502, Avg Loss: 5.2023, Avg Regression Loss 1.8127, Avg Classification Loss: 3.3896
2021-05-21 21:06:14 - Epoch: 17, Step: 300/502, Avg Loss: 5.0446, Avg Regression Loss 1.5522, Avg Classification Loss: 3.4925
2021-05-21 21:06:19 - Epoch: 17, Step: 310/502, Avg Loss: 4.4458, Avg Regression Loss 1.4234, Avg Classification Loss: 3.0224
2021-05-21 21:06:24 - Epoch: 17, Step: 320/502, Avg Loss: 4.8795, Avg Regression Loss 1.5733, Avg Classification Loss: 3.3062
2021-05-21 21:06:35 - Epoch: 17, Step: 330/502, Avg Loss: 5.2767, Avg Regression Loss 1.9006, Avg Classification Loss: 3.3760
2021-05-21 21:06:42 - Epoch: 17, Step: 340/502, Avg Loss: 5.5554, Avg Regression Loss 2.1928, Avg Classification Loss: 3.3626
2021-05-21 21:06:46 - Epoch: 17, Step: 350/502, Avg Loss: 4.3426, Avg Regression Loss 1.1065, Avg Classification Loss: 3.2361
2021-05-21 21:06:51 - Epoch: 17, Step: 360/502, Avg Loss: 4.8505, Avg Regression Loss 1.6873, Avg Classification Loss: 3.1632
2021-05-21 21:06:56 - Epoch: 17, Step: 370/502, Avg Loss: 4.7301, Avg Regression Loss 1.4827, Avg Classification Loss: 3.2474
2021-05-21 21:07:01 - Epoch: 17, Step: 380/502, Avg Loss: 4.6373, Avg Regression Loss 1.5585, Avg Classification Loss: 3.0788
2021-05-21 21:07:07 - Epoch: 17, Step: 390/502, Avg Loss: 6.1545, Avg Regression Loss 2.5510, Avg Classification Loss: 3.6034
2021-05-21 21:07:14 - Epoch: 17, Step: 400/502, Avg Loss: 5.2054, Avg Regression Loss 2.1701, Avg Classification Loss: 3.0353
2021-05-21 21:07:19 - Epoch: 17, Step: 410/502, Avg Loss: 4.6027, Avg Regression Loss 1.2966, Avg Classification Loss: 3.3062
2021-05-21 21:07:23 - Epoch: 17, Step: 420/502, Avg Loss: 5.0633, Avg Regression Loss 1.7718, Avg Classification Loss: 3.2915
2021-05-21 21:07:29 - Epoch: 17, Step: 430/502, Avg Loss: 5.2934, Avg Regression Loss 1.9967, Avg Classification Loss: 3.2967
2021-05-21 21:07:34 - Epoch: 17, Step: 440/502, Avg Loss: 4.9153, Avg Regression Loss 1.7483, Avg Classification Loss: 3.1669
2021-05-21 21:07:40 - Epoch: 17, Step: 450/502, Avg Loss: 4.6078, Avg Regression Loss 1.5939, Avg Classification Loss: 3.0139
2021-05-21 21:07:45 - Epoch: 17, Step: 460/502, Avg Loss: 4.7131, Avg Regression Loss 1.4862, Avg Classification Loss: 3.2269
2021-05-21 21:07:50 - Epoch: 17, Step: 470/502, Avg Loss: 5.4150, Avg Regression Loss 2.2555, Avg Classification Loss: 3.1595
2021-05-21 21:07:54 - Epoch: 17, Step: 480/502, Avg Loss: 4.4457, Avg Regression Loss 1.2548, Avg Classification Loss: 3.1909
2021-05-21 21:07:59 - Epoch: 17, Step: 490/502, Avg Loss: 5.3469, Avg Regression Loss 2.0131, Avg Classification Loss: 3.3338
2021-05-21 21:08:04 - Epoch: 17, Step: 500/502, Avg Loss: 5.1810, Avg Regression Loss 1.6784, Avg Classification Loss: 3.5026
2021-05-21 21:09:04 - Epoch: 17, Validation Loss: 4.1346, Validation Regression Loss 1.0014, Validation Classification Loss: 3.1332
2021-05-21 21:09:05 - Saved model models/smd/mb1-ssd-Epoch-17-Loss-4.134613862550591.pth
2021-05-21 21:09:11 - Epoch: 18, Step: 10/502, Avg Loss: 5.2303, Avg Regression Loss 1.4600, Avg Classification Loss: 3.7703
2021-05-21 21:09:23 - Epoch: 18, Step: 20/502, Avg Loss: 4.6679, Avg Regression Loss 1.3952, Avg Classification Loss: 3.2727
2021-05-21 21:09:29 - Epoch: 18, Step: 30/502, Avg Loss: 5.1276, Avg Regression Loss 1.8148, Avg Classification Loss: 3.3128
2021-05-21 21:09:34 - Epoch: 18, Step: 40/502, Avg Loss: 5.0288, Avg Regression Loss 1.7780, Avg Classification Loss: 3.2508
2021-05-21 21:09:38 - Epoch: 18, Step: 50/502, Avg Loss: 4.6418, Avg Regression Loss 1.2696, Avg Classification Loss: 3.3722
2021-05-21 21:09:50 - Epoch: 18, Step: 60/502, Avg Loss: 4.7514, Avg Regression Loss 1.5636, Avg Classification Loss: 3.1878
2021-05-21 21:09:55 - Epoch: 18, Step: 70/502, Avg Loss: 4.3965, Avg Regression Loss 1.1365, Avg Classification Loss: 3.2600
2021-05-21 21:09:59 - Epoch: 18, Step: 80/502, Avg Loss: 5.2047, Avg Regression Loss 1.7969, Avg Classification Loss: 3.4078
2021-05-21 21:10:05 - Epoch: 18, Step: 90/502, Avg Loss: 4.7936, Avg Regression Loss 1.4911, Avg Classification Loss: 3.3025
2021-05-21 21:10:10 - Epoch: 18, Step: 100/502, Avg Loss: 4.9808, Avg Regression Loss 1.4354, Avg Classification Loss: 3.5454
2021-05-21 21:10:15 - Epoch: 18, Step: 110/502, Avg Loss: 4.9957, Avg Regression Loss 1.6642, Avg Classification Loss: 3.3315
2021-05-21 21:10:27 - Epoch: 18, Step: 120/502, Avg Loss: 4.8003, Avg Regression Loss 1.5124, Avg Classification Loss: 3.2879
2021-05-21 21:10:32 - Epoch: 18, Step: 130/502, Avg Loss: 4.8474, Avg Regression Loss 1.5759, Avg Classification Loss: 3.2716
2021-05-21 21:10:42 - Epoch: 18, Step: 140/502, Avg Loss: 4.9737, Avg Regression Loss 1.7025, Avg Classification Loss: 3.2712
2021-05-21 21:10:48 - Epoch: 18, Step: 150/502, Avg Loss: 4.6170, Avg Regression Loss 1.6544, Avg Classification Loss: 2.9626
2021-05-21 21:10:52 - Epoch: 18, Step: 160/502, Avg Loss: 4.5824, Avg Regression Loss 1.3972, Avg Classification Loss: 3.1852
2021-05-21 21:10:57 - Epoch: 18, Step: 170/502, Avg Loss: 5.3142, Avg Regression Loss 1.8212, Avg Classification Loss: 3.4930
2021-05-21 21:11:02 - Epoch: 18, Step: 180/502, Avg Loss: 4.9345, Avg Regression Loss 1.4162, Avg Classification Loss: 3.5183
2021-05-21 21:11:07 - Epoch: 18, Step: 190/502, Avg Loss: 5.0691, Avg Regression Loss 1.8060, Avg Classification Loss: 3.2631
2021-05-21 21:11:21 - Epoch: 18, Step: 200/502, Avg Loss: 5.5516, Avg Regression Loss 1.9823, Avg Classification Loss: 3.5693
2021-05-21 21:11:26 - Epoch: 18, Step: 210/502, Avg Loss: 4.6697, Avg Regression Loss 1.3842, Avg Classification Loss: 3.2855
2021-05-21 21:11:31 - Epoch: 18, Step: 220/502, Avg Loss: 4.6688, Avg Regression Loss 1.3868, Avg Classification Loss: 3.2820
2021-05-21 21:11:36 - Epoch: 18, Step: 230/502, Avg Loss: 5.2851, Avg Regression Loss 2.0811, Avg Classification Loss: 3.2040
2021-05-21 21:11:44 - Epoch: 18, Step: 240/502, Avg Loss: 4.5527, Avg Regression Loss 1.3595, Avg Classification Loss: 3.1933
2021-05-21 21:11:50 - Epoch: 18, Step: 250/502, Avg Loss: 5.2065, Avg Regression Loss 1.8753, Avg Classification Loss: 3.3312
2021-05-21 21:11:54 - Epoch: 18, Step: 260/502, Avg Loss: 5.1403, Avg Regression Loss 1.8244, Avg Classification Loss: 3.3158
2021-05-21 21:11:59 - Epoch: 18, Step: 270/502, Avg Loss: 5.2261, Avg Regression Loss 1.8559, Avg Classification Loss: 3.3702
2021-05-21 21:12:04 - Epoch: 18, Step: 280/502, Avg Loss: 4.4079, Avg Regression Loss 1.2870, Avg Classification Loss: 3.1208
2021-05-21 21:12:11 - Epoch: 18, Step: 290/502, Avg Loss: 5.0842, Avg Regression Loss 1.6860, Avg Classification Loss: 3.3982
2021-05-21 21:12:16 - Epoch: 18, Step: 300/502, Avg Loss: 5.0124, Avg Regression Loss 2.0045, Avg Classification Loss: 3.0079
2021-05-21 21:12:21 - Epoch: 18, Step: 310/502, Avg Loss: 4.8476, Avg Regression Loss 1.6648, Avg Classification Loss: 3.1828
2021-05-21 21:12:26 - Epoch: 18, Step: 320/502, Avg Loss: 5.5563, Avg Regression Loss 2.0238, Avg Classification Loss: 3.5325
2021-05-21 21:12:32 - Epoch: 18, Step: 330/502, Avg Loss: 5.0893, Avg Regression Loss 1.9266, Avg Classification Loss: 3.1627
2021-05-21 21:12:37 - Epoch: 18, Step: 340/502, Avg Loss: 4.7253, Avg Regression Loss 1.5053, Avg Classification Loss: 3.2200
2021-05-21 21:12:42 - Epoch: 18, Step: 350/502, Avg Loss: 5.0727, Avg Regression Loss 1.7939, Avg Classification Loss: 3.2788
2021-05-21 21:12:47 - Epoch: 18, Step: 360/502, Avg Loss: 4.5188, Avg Regression Loss 1.4808, Avg Classification Loss: 3.0381
2021-05-21 21:12:52 - Epoch: 18, Step: 370/502, Avg Loss: 5.3230, Avg Regression Loss 1.9199, Avg Classification Loss: 3.4031
2021-05-21 21:12:59 - Epoch: 18, Step: 380/502, Avg Loss: 5.5741, Avg Regression Loss 2.0206, Avg Classification Loss: 3.5535
2021-05-21 21:13:03 - Epoch: 18, Step: 390/502, Avg Loss: 4.9499, Avg Regression Loss 1.6041, Avg Classification Loss: 3.3459
2021-05-21 21:13:08 - Epoch: 18, Step: 400/502, Avg Loss: 4.9376, Avg Regression Loss 1.7509, Avg Classification Loss: 3.1867
2021-05-21 21:13:13 - Epoch: 18, Step: 410/502, Avg Loss: 4.6701, Avg Regression Loss 1.4949, Avg Classification Loss: 3.1752
2021-05-21 21:13:19 - Epoch: 18, Step: 420/502, Avg Loss: 5.1558, Avg Regression Loss 1.9065, Avg Classification Loss: 3.2493
2021-05-21 21:13:24 - Epoch: 18, Step: 430/502, Avg Loss: 5.6535, Avg Regression Loss 2.3658, Avg Classification Loss: 3.2877
2021-05-21 21:13:29 - Epoch: 18, Step: 440/502, Avg Loss: 4.9692, Avg Regression Loss 1.4830, Avg Classification Loss: 3.4862
2021-05-21 21:13:33 - Epoch: 18, Step: 450/502, Avg Loss: 5.2440, Avg Regression Loss 1.7940, Avg Classification Loss: 3.4500
2021-05-21 21:13:39 - Epoch: 18, Step: 460/502, Avg Loss: 5.0036, Avg Regression Loss 1.8171, Avg Classification Loss: 3.1865
2021-05-21 21:13:44 - Epoch: 18, Step: 470/502, Avg Loss: 5.3517, Avg Regression Loss 2.1163, Avg Classification Loss: 3.2354
2021-05-21 21:13:49 - Epoch: 18, Step: 480/502, Avg Loss: 4.8733, Avg Regression Loss 1.6385, Avg Classification Loss: 3.2348
2021-05-21 21:13:55 - Epoch: 18, Step: 490/502, Avg Loss: 5.1501, Avg Regression Loss 1.9481, Avg Classification Loss: 3.2020
2021-05-21 21:14:00 - Epoch: 18, Step: 500/502, Avg Loss: 4.8602, Avg Regression Loss 1.4783, Avg Classification Loss: 3.3819
2021-05-21 21:15:02 - Epoch: 18, Validation Loss: 4.2156, Validation Regression Loss 1.1059, Validation Classification Loss: 3.1097
2021-05-21 21:15:03 - Saved model models/smd/mb1-ssd-Epoch-18-Loss-4.215637993527599.pth
2021-05-21 21:15:11 - Epoch: 19, Step: 10/502, Avg Loss: 5.2462, Avg Regression Loss 1.6900, Avg Classification Loss: 3.5562
2021-05-21 21:15:18 - Epoch: 19, Step: 20/502, Avg Loss: 5.0127, Avg Regression Loss 1.6819, Avg Classification Loss: 3.3308
2021-05-21 21:15:24 - Epoch: 19, Step: 30/502, Avg Loss: 4.7851, Avg Regression Loss 1.5359, Avg Classification Loss: 3.2492
2021-05-21 21:15:29 - Epoch: 19, Step: 40/502, Avg Loss: 4.3787, Avg Regression Loss 1.3214, Avg Classification Loss: 3.0573
2021-05-21 21:15:33 - Epoch: 19, Step: 50/502, Avg Loss: 4.8891, Avg Regression Loss 1.6538, Avg Classification Loss: 3.2353
2021-05-21 21:15:38 - Epoch: 19, Step: 60/502, Avg Loss: 4.6843, Avg Regression Loss 1.5342, Avg Classification Loss: 3.1500
2021-05-21 21:15:43 - Epoch: 19, Step: 70/502, Avg Loss: 4.1994, Avg Regression Loss 1.0366, Avg Classification Loss: 3.1628
2021-05-21 21:15:49 - Epoch: 19, Step: 80/502, Avg Loss: 5.1523, Avg Regression Loss 1.8281, Avg Classification Loss: 3.3243
2021-05-21 21:15:54 - Epoch: 19, Step: 90/502, Avg Loss: 5.1185, Avg Regression Loss 1.7536, Avg Classification Loss: 3.3649
2021-05-21 21:15:59 - Epoch: 19, Step: 100/502, Avg Loss: 4.1854, Avg Regression Loss 1.0526, Avg Classification Loss: 3.1328
2021-05-21 21:16:09 - Epoch: 19, Step: 110/502, Avg Loss: 5.0436, Avg Regression Loss 1.9321, Avg Classification Loss: 3.1115
2021-05-21 21:16:21 - Epoch: 19, Step: 120/502, Avg Loss: 5.2266, Avg Regression Loss 1.8351, Avg Classification Loss: 3.3915
2021-05-21 21:16:25 - Epoch: 19, Step: 130/502, Avg Loss: 4.4154, Avg Regression Loss 1.2218, Avg Classification Loss: 3.1935
2021-05-21 21:16:30 - Epoch: 19, Step: 140/502, Avg Loss: 5.1614, Avg Regression Loss 1.9614, Avg Classification Loss: 3.2000
2021-05-21 21:16:36 - Epoch: 19, Step: 150/502, Avg Loss: 5.2079, Avg Regression Loss 1.9127, Avg Classification Loss: 3.2953
2021-05-21 21:16:42 - Epoch: 19, Step: 160/502, Avg Loss: 4.9567, Avg Regression Loss 1.8878, Avg Classification Loss: 3.0689
2021-05-21 21:16:47 - Epoch: 19, Step: 170/502, Avg Loss: 4.7812, Avg Regression Loss 1.3602, Avg Classification Loss: 3.4210
2021-05-21 21:16:52 - Epoch: 19, Step: 180/502, Avg Loss: 4.7478, Avg Regression Loss 1.6209, Avg Classification Loss: 3.1269
2021-05-21 21:16:57 - Epoch: 19, Step: 190/502, Avg Loss: 4.8187, Avg Regression Loss 1.4923, Avg Classification Loss: 3.3265
2021-05-21 21:17:01 - Epoch: 19, Step: 200/502, Avg Loss: 4.8562, Avg Regression Loss 1.7213, Avg Classification Loss: 3.1349
2021-05-21 21:17:07 - Epoch: 19, Step: 210/502, Avg Loss: 5.4101, Avg Regression Loss 2.0801, Avg Classification Loss: 3.3300
2021-05-21 21:17:13 - Epoch: 19, Step: 220/502, Avg Loss: 5.0828, Avg Regression Loss 1.8018, Avg Classification Loss: 3.2810
2021-05-21 21:17:19 - Epoch: 19, Step: 230/502, Avg Loss: 4.9649, Avg Regression Loss 1.5603, Avg Classification Loss: 3.4045
2021-05-21 21:17:24 - Epoch: 19, Step: 240/502, Avg Loss: 5.3902, Avg Regression Loss 2.0286, Avg Classification Loss: 3.3615
2021-05-21 21:17:30 - Epoch: 19, Step: 250/502, Avg Loss: 5.3424, Avg Regression Loss 2.0071, Avg Classification Loss: 3.3353
2021-05-21 21:17:34 - Epoch: 19, Step: 260/502, Avg Loss: 5.0762, Avg Regression Loss 1.6138, Avg Classification Loss: 3.4624
2021-05-21 21:17:39 - Epoch: 19, Step: 270/502, Avg Loss: 4.4433, Avg Regression Loss 1.3332, Avg Classification Loss: 3.1101
2021-05-21 21:17:44 - Epoch: 19, Step: 280/502, Avg Loss: 4.2358, Avg Regression Loss 1.2122, Avg Classification Loss: 3.0236
2021-05-21 21:17:48 - Epoch: 19, Step: 290/502, Avg Loss: 5.1853, Avg Regression Loss 1.8478, Avg Classification Loss: 3.3375
2021-05-21 21:17:53 - Epoch: 19, Step: 300/502, Avg Loss: 4.6686, Avg Regression Loss 1.3828, Avg Classification Loss: 3.2857
2021-05-21 21:17:58 - Epoch: 19, Step: 310/502, Avg Loss: 5.3650, Avg Regression Loss 1.9817, Avg Classification Loss: 3.3834
2021-05-21 21:18:04 - Epoch: 19, Step: 320/502, Avg Loss: 4.3136, Avg Regression Loss 1.2643, Avg Classification Loss: 3.0492
2021-05-21 21:18:08 - Epoch: 19, Step: 330/502, Avg Loss: 4.5243, Avg Regression Loss 1.2888, Avg Classification Loss: 3.2356
2021-05-21 21:18:13 - Epoch: 19, Step: 340/502, Avg Loss: 4.9045, Avg Regression Loss 1.7675, Avg Classification Loss: 3.1370
2021-05-21 21:18:19 - Epoch: 19, Step: 350/502, Avg Loss: 4.8353, Avg Regression Loss 1.5396, Avg Classification Loss: 3.2957
2021-05-21 21:18:32 - Epoch: 19, Step: 360/502, Avg Loss: 4.8990, Avg Regression Loss 1.4813, Avg Classification Loss: 3.4176
2021-05-21 21:18:36 - Epoch: 19, Step: 370/502, Avg Loss: 4.8735, Avg Regression Loss 1.5016, Avg Classification Loss: 3.3719
2021-05-21 21:18:41 - Epoch: 19, Step: 380/502, Avg Loss: 5.6375, Avg Regression Loss 2.3821, Avg Classification Loss: 3.2553
2021-05-21 21:18:47 - Epoch: 19, Step: 390/502, Avg Loss: 5.6834, Avg Regression Loss 2.2372, Avg Classification Loss: 3.4462
2021-05-21 21:18:52 - Epoch: 19, Step: 400/502, Avg Loss: 4.5030, Avg Regression Loss 1.2815, Avg Classification Loss: 3.2215
2021-05-21 21:18:57 - Epoch: 19, Step: 410/502, Avg Loss: 4.6542, Avg Regression Loss 1.5266, Avg Classification Loss: 3.1276
2021-05-21 21:19:04 - Epoch: 19, Step: 420/502, Avg Loss: 5.3767, Avg Regression Loss 2.1490, Avg Classification Loss: 3.2278
2021-05-21 21:19:10 - Epoch: 19, Step: 430/502, Avg Loss: 4.9944, Avg Regression Loss 1.6571, Avg Classification Loss: 3.3372
2021-05-21 21:19:14 - Epoch: 19, Step: 440/502, Avg Loss: 5.0098, Avg Regression Loss 1.8815, Avg Classification Loss: 3.1283
2021-05-21 21:19:20 - Epoch: 19, Step: 450/502, Avg Loss: 5.2256, Avg Regression Loss 1.7962, Avg Classification Loss: 3.4294
2021-05-21 21:19:24 - Epoch: 19, Step: 460/502, Avg Loss: 4.8938, Avg Regression Loss 1.6325, Avg Classification Loss: 3.2613
2021-05-21 21:19:29 - Epoch: 19, Step: 470/502, Avg Loss: 4.5015, Avg Regression Loss 1.4500, Avg Classification Loss: 3.0515
2021-05-21 21:19:34 - Epoch: 19, Step: 480/502, Avg Loss: 4.2070, Avg Regression Loss 1.0857, Avg Classification Loss: 3.1213
2021-05-21 21:19:41 - Epoch: 19, Step: 490/502, Avg Loss: 5.0383, Avg Regression Loss 1.7565, Avg Classification Loss: 3.2818
2021-05-21 21:19:46 - Epoch: 19, Step: 500/502, Avg Loss: 4.6524, Avg Regression Loss 1.4427, Avg Classification Loss: 3.2097
2021-05-21 21:20:48 - Epoch: 19, Validation Loss: 4.4449, Validation Regression Loss 1.3424, Validation Classification Loss: 3.1025
2021-05-21 21:20:48 - Saved model models/smd/mb1-ssd-Epoch-19-Loss-4.444941280372589.pth
2021-05-21 21:20:54 - Epoch: 20, Step: 10/502, Avg Loss: 5.2631, Avg Regression Loss 1.6824, Avg Classification Loss: 3.5807
2021-05-21 21:21:00 - Epoch: 20, Step: 20/502, Avg Loss: 4.6609, Avg Regression Loss 1.5810, Avg Classification Loss: 3.0799
2021-05-21 21:21:05 - Epoch: 20, Step: 30/502, Avg Loss: 4.9432, Avg Regression Loss 1.6955, Avg Classification Loss: 3.2478
2021-05-21 21:21:11 - Epoch: 20, Step: 40/502, Avg Loss: 4.7960, Avg Regression Loss 1.5316, Avg Classification Loss: 3.2645
2021-05-21 21:21:16 - Epoch: 20, Step: 50/502, Avg Loss: 4.8269, Avg Regression Loss 1.4120, Avg Classification Loss: 3.4150
2021-05-21 21:21:21 - Epoch: 20, Step: 60/502, Avg Loss: 4.8530, Avg Regression Loss 1.7992, Avg Classification Loss: 3.0538
2021-05-21 21:21:26 - Epoch: 20, Step: 70/502, Avg Loss: 4.5947, Avg Regression Loss 1.3021, Avg Classification Loss: 3.2925
2021-05-21 21:21:31 - Epoch: 20, Step: 80/502, Avg Loss: 4.9993, Avg Regression Loss 1.7136, Avg Classification Loss: 3.2857
2021-05-21 21:21:37 - Epoch: 20, Step: 90/502, Avg Loss: 5.1196, Avg Regression Loss 1.6884, Avg Classification Loss: 3.4312
2021-05-21 21:21:42 - Epoch: 20, Step: 100/502, Avg Loss: 5.0395, Avg Regression Loss 2.0485, Avg Classification Loss: 2.9911
2021-05-21 21:21:46 - Epoch: 20, Step: 110/502, Avg Loss: 4.7974, Avg Regression Loss 1.4439, Avg Classification Loss: 3.3535
2021-05-21 21:21:51 - Epoch: 20, Step: 120/502, Avg Loss: 4.2880, Avg Regression Loss 1.0608, Avg Classification Loss: 3.2272
2021-05-21 21:21:56 - Epoch: 20, Step: 130/502, Avg Loss: 4.7968, Avg Regression Loss 1.6975, Avg Classification Loss: 3.0993
2021-05-21 21:22:16 - Epoch: 20, Step: 140/502, Avg Loss: 4.6172, Avg Regression Loss 1.4861, Avg Classification Loss: 3.1311
2021-05-21 21:22:28 - Epoch: 20, Step: 150/502, Avg Loss: 5.2527, Avg Regression Loss 1.8861, Avg Classification Loss: 3.3666
2021-05-21 21:22:32 - Epoch: 20, Step: 160/502, Avg Loss: 4.6897, Avg Regression Loss 1.5636, Avg Classification Loss: 3.1261
2021-05-21 21:22:38 - Epoch: 20, Step: 170/502, Avg Loss: 4.5736, Avg Regression Loss 1.3390, Avg Classification Loss: 3.2346
2021-05-21 21:22:42 - Epoch: 20, Step: 180/502, Avg Loss: 4.2268, Avg Regression Loss 1.0986, Avg Classification Loss: 3.1283
2021-05-21 21:22:47 - Epoch: 20, Step: 190/502, Avg Loss: 4.6095, Avg Regression Loss 1.4989, Avg Classification Loss: 3.1106
2021-05-21 21:22:51 - Epoch: 20, Step: 200/502, Avg Loss: 5.5196, Avg Regression Loss 2.2131, Avg Classification Loss: 3.3065
2021-05-21 21:22:56 - Epoch: 20, Step: 210/502, Avg Loss: 4.5926, Avg Regression Loss 1.3603, Avg Classification Loss: 3.2323
2021-05-21 21:23:01 - Epoch: 20, Step: 220/502, Avg Loss: 5.1924, Avg Regression Loss 1.9468, Avg Classification Loss: 3.2456
2021-05-21 21:23:07 - Epoch: 20, Step: 230/502, Avg Loss: 5.2984, Avg Regression Loss 2.0689, Avg Classification Loss: 3.2295
2021-05-21 21:23:11 - Epoch: 20, Step: 240/502, Avg Loss: 4.9310, Avg Regression Loss 1.7517, Avg Classification Loss: 3.1793
2021-05-21 21:23:16 - Epoch: 20, Step: 250/502, Avg Loss: 4.8061, Avg Regression Loss 1.6016, Avg Classification Loss: 3.2046
2021-05-21 21:23:25 - Epoch: 20, Step: 260/502, Avg Loss: 5.1725, Avg Regression Loss 1.9383, Avg Classification Loss: 3.2342
2021-05-21 21:23:30 - Epoch: 20, Step: 270/502, Avg Loss: 5.2576, Avg Regression Loss 1.8687, Avg Classification Loss: 3.3889
2021-05-21 21:23:35 - Epoch: 20, Step: 280/502, Avg Loss: 4.5459, Avg Regression Loss 1.3953, Avg Classification Loss: 3.1505
2021-05-21 21:23:40 - Epoch: 20, Step: 290/502, Avg Loss: 4.7253, Avg Regression Loss 1.3730, Avg Classification Loss: 3.3523
2021-05-21 21:23:45 - Epoch: 20, Step: 300/502, Avg Loss: 4.3480, Avg Regression Loss 1.2447, Avg Classification Loss: 3.1033
2021-05-21 21:23:50 - Epoch: 20, Step: 310/502, Avg Loss: 4.8359, Avg Regression Loss 1.5240, Avg Classification Loss: 3.3119
2021-05-21 21:23:54 - Epoch: 20, Step: 320/502, Avg Loss: 4.5655, Avg Regression Loss 1.2248, Avg Classification Loss: 3.3407
2021-05-21 21:24:00 - Epoch: 20, Step: 330/502, Avg Loss: 4.5255, Avg Regression Loss 1.2326, Avg Classification Loss: 3.2929
2021-05-21 21:24:05 - Epoch: 20, Step: 340/502, Avg Loss: 4.5873, Avg Regression Loss 1.3892, Avg Classification Loss: 3.1981
2021-05-21 21:24:10 - Epoch: 20, Step: 350/502, Avg Loss: 4.8731, Avg Regression Loss 1.7819, Avg Classification Loss: 3.0911
2021-05-21 21:24:17 - Epoch: 20, Step: 360/502, Avg Loss: 4.8869, Avg Regression Loss 1.4715, Avg Classification Loss: 3.4154
2021-05-21 21:24:22 - Epoch: 20, Step: 370/502, Avg Loss: 5.3792, Avg Regression Loss 1.8844, Avg Classification Loss: 3.4948
2021-05-21 21:24:27 - Epoch: 20, Step: 380/502, Avg Loss: 4.4503, Avg Regression Loss 1.2276, Avg Classification Loss: 3.2227
2021-05-21 21:24:31 - Epoch: 20, Step: 390/502, Avg Loss: 4.5590, Avg Regression Loss 1.4424, Avg Classification Loss: 3.1166
2021-05-21 21:24:37 - Epoch: 20, Step: 400/502, Avg Loss: 4.6386, Avg Regression Loss 1.4503, Avg Classification Loss: 3.1883
2021-05-21 21:24:42 - Epoch: 20, Step: 410/502, Avg Loss: 4.9725, Avg Regression Loss 1.9427, Avg Classification Loss: 3.0299
2021-05-21 21:24:46 - Epoch: 20, Step: 420/502, Avg Loss: 4.9077, Avg Regression Loss 1.5964, Avg Classification Loss: 3.3113
2021-05-21 21:24:51 - Epoch: 20, Step: 430/502, Avg Loss: 4.5888, Avg Regression Loss 1.4820, Avg Classification Loss: 3.1068
2021-05-21 21:24:56 - Epoch: 20, Step: 440/502, Avg Loss: 5.2809, Avg Regression Loss 1.9734, Avg Classification Loss: 3.3075
2021-05-21 21:25:01 - Epoch: 20, Step: 450/502, Avg Loss: 5.0862, Avg Regression Loss 1.8291, Avg Classification Loss: 3.2571
2021-05-21 21:25:05 - Epoch: 20, Step: 460/502, Avg Loss: 4.4114, Avg Regression Loss 1.3048, Avg Classification Loss: 3.1066
2021-05-21 21:25:17 - Epoch: 20, Step: 470/502, Avg Loss: 4.3491, Avg Regression Loss 1.3295, Avg Classification Loss: 3.0196
2021-05-21 21:25:22 - Epoch: 20, Step: 480/502, Avg Loss: 4.5433, Avg Regression Loss 1.3484, Avg Classification Loss: 3.1949
2021-05-21 21:25:27 - Epoch: 20, Step: 490/502, Avg Loss: 5.0034, Avg Regression Loss 1.7468, Avg Classification Loss: 3.2566
2021-05-21 21:25:32 - Epoch: 20, Step: 500/502, Avg Loss: 4.4931, Avg Regression Loss 1.5396, Avg Classification Loss: 2.9534
2021-05-21 21:26:33 - Epoch: 20, Validation Loss: 4.1741, Validation Regression Loss 1.0836, Validation Classification Loss: 3.0905
2021-05-21 21:26:34 - Saved model models/smd/mb1-ssd-Epoch-20-Loss-4.174056052686684.pth
2021-05-21 21:26:40 - Epoch: 21, Step: 10/502, Avg Loss: 5.2382, Avg Regression Loss 1.8344, Avg Classification Loss: 3.4037
2021-05-21 21:26:45 - Epoch: 21, Step: 20/502, Avg Loss: 5.2550, Avg Regression Loss 1.9208, Avg Classification Loss: 3.3342
2021-05-21 21:26:50 - Epoch: 21, Step: 30/502, Avg Loss: 5.5002, Avg Regression Loss 2.2235, Avg Classification Loss: 3.2766
2021-05-21 21:26:55 - Epoch: 21, Step: 40/502, Avg Loss: 4.8582, Avg Regression Loss 1.6778, Avg Classification Loss: 3.1804
2021-05-21 21:27:00 - Epoch: 21, Step: 50/502, Avg Loss: 4.5038, Avg Regression Loss 1.4539, Avg Classification Loss: 3.0499
2021-05-21 21:27:04 - Epoch: 21, Step: 60/502, Avg Loss: 4.3540, Avg Regression Loss 1.5368, Avg Classification Loss: 2.8172
2021-05-21 21:27:10 - Epoch: 21, Step: 70/502, Avg Loss: 5.2441, Avg Regression Loss 1.9540, Avg Classification Loss: 3.2901
2021-05-21 21:27:15 - Epoch: 21, Step: 80/502, Avg Loss: 4.5941, Avg Regression Loss 1.4570, Avg Classification Loss: 3.1371
2021-05-21 21:27:22 - Epoch: 21, Step: 90/502, Avg Loss: 4.8963, Avg Regression Loss 1.6673, Avg Classification Loss: 3.2290
2021-05-21 21:27:26 - Epoch: 21, Step: 100/502, Avg Loss: 4.2937, Avg Regression Loss 1.1928, Avg Classification Loss: 3.1009
2021-05-21 21:27:32 - Epoch: 21, Step: 110/502, Avg Loss: 4.5303, Avg Regression Loss 1.4616, Avg Classification Loss: 3.0688
2021-05-21 21:27:48 - Epoch: 21, Step: 120/502, Avg Loss: 4.4325, Avg Regression Loss 1.1179, Avg Classification Loss: 3.3146
2021-05-21 21:27:53 - Epoch: 21, Step: 130/502, Avg Loss: 5.0822, Avg Regression Loss 2.0175, Avg Classification Loss: 3.0647
2021-05-21 21:27:58 - Epoch: 21, Step: 140/502, Avg Loss: 5.4230, Avg Regression Loss 2.1850, Avg Classification Loss: 3.2380
2021-05-21 21:28:03 - Epoch: 21, Step: 150/502, Avg Loss: 4.7431, Avg Regression Loss 1.5586, Avg Classification Loss: 3.1844
2021-05-21 21:28:09 - Epoch: 21, Step: 160/502, Avg Loss: 5.2961, Avg Regression Loss 1.8323, Avg Classification Loss: 3.4638
2021-05-21 21:28:14 - Epoch: 21, Step: 170/502, Avg Loss: 5.4238, Avg Regression Loss 1.9892, Avg Classification Loss: 3.4345
2021-05-21 21:28:19 - Epoch: 21, Step: 180/502, Avg Loss: 4.6266, Avg Regression Loss 1.4383, Avg Classification Loss: 3.1883
2021-05-21 21:28:24 - Epoch: 21, Step: 190/502, Avg Loss: 4.9831, Avg Regression Loss 1.7184, Avg Classification Loss: 3.2647
2021-05-21 21:28:29 - Epoch: 21, Step: 200/502, Avg Loss: 4.9805, Avg Regression Loss 1.8504, Avg Classification Loss: 3.1302
2021-05-21 21:28:34 - Epoch: 21, Step: 210/502, Avg Loss: 5.4542, Avg Regression Loss 2.2293, Avg Classification Loss: 3.2249
2021-05-21 21:28:42 - Epoch: 21, Step: 220/502, Avg Loss: 5.5997, Avg Regression Loss 2.2442, Avg Classification Loss: 3.3556
2021-05-21 21:28:47 - Epoch: 21, Step: 230/502, Avg Loss: 4.9420, Avg Regression Loss 1.6296, Avg Classification Loss: 3.3124
2021-05-21 21:28:53 - Epoch: 21, Step: 240/502, Avg Loss: 5.3146, Avg Regression Loss 1.8754, Avg Classification Loss: 3.4392
2021-05-21 21:28:59 - Epoch: 21, Step: 250/502, Avg Loss: 4.3300, Avg Regression Loss 1.4152, Avg Classification Loss: 2.9148
2021-05-21 21:29:04 - Epoch: 21, Step: 260/502, Avg Loss: 4.3761, Avg Regression Loss 1.3190, Avg Classification Loss: 3.0571
2021-05-21 21:29:09 - Epoch: 21, Step: 270/502, Avg Loss: 5.1089, Avg Regression Loss 2.0882, Avg Classification Loss: 3.0207
2021-05-21 21:29:13 - Epoch: 21, Step: 280/502, Avg Loss: 4.9603, Avg Regression Loss 1.3966, Avg Classification Loss: 3.5636
2021-05-21 21:29:18 - Epoch: 21, Step: 290/502, Avg Loss: 4.5331, Avg Regression Loss 1.3748, Avg Classification Loss: 3.1583
2021-05-21 21:29:23 - Epoch: 21, Step: 300/502, Avg Loss: 4.6925, Avg Regression Loss 1.5782, Avg Classification Loss: 3.1142
2021-05-21 21:29:28 - Epoch: 21, Step: 310/502, Avg Loss: 4.3098, Avg Regression Loss 1.2214, Avg Classification Loss: 3.0884
2021-05-21 21:29:35 - Epoch: 21, Step: 320/502, Avg Loss: 4.3586, Avg Regression Loss 1.1674, Avg Classification Loss: 3.1911
2021-05-21 21:29:39 - Epoch: 21, Step: 330/502, Avg Loss: 4.4056, Avg Regression Loss 1.2118, Avg Classification Loss: 3.1937
2021-05-21 21:29:45 - Epoch: 21, Step: 340/502, Avg Loss: 5.0395, Avg Regression Loss 1.9383, Avg Classification Loss: 3.1012
2021-05-21 21:29:50 - Epoch: 21, Step: 350/502, Avg Loss: 4.2718, Avg Regression Loss 1.2673, Avg Classification Loss: 3.0045
2021-05-21 21:29:59 - Epoch: 21, Step: 360/502, Avg Loss: 4.3870, Avg Regression Loss 1.3152, Avg Classification Loss: 3.0718
2021-05-21 21:30:04 - Epoch: 21, Step: 370/502, Avg Loss: 5.1838, Avg Regression Loss 1.8414, Avg Classification Loss: 3.3424
2021-05-21 21:30:08 - Epoch: 21, Step: 380/502, Avg Loss: 4.1256, Avg Regression Loss 0.9494, Avg Classification Loss: 3.1761
2021-05-21 21:30:20 - Epoch: 21, Step: 390/502, Avg Loss: 4.7655, Avg Regression Loss 1.5617, Avg Classification Loss: 3.2038
2021-05-21 21:30:25 - Epoch: 21, Step: 400/502, Avg Loss: 5.0745, Avg Regression Loss 1.8506, Avg Classification Loss: 3.2239
2021-05-21 21:30:30 - Epoch: 21, Step: 410/502, Avg Loss: 4.7140, Avg Regression Loss 1.6510, Avg Classification Loss: 3.0630
2021-05-21 21:30:36 - Epoch: 21, Step: 420/502, Avg Loss: 4.8836, Avg Regression Loss 1.6685, Avg Classification Loss: 3.2152
2021-05-21 21:30:40 - Epoch: 21, Step: 430/502, Avg Loss: 4.5984, Avg Regression Loss 1.4545, Avg Classification Loss: 3.1439
2021-05-21 21:30:45 - Epoch: 21, Step: 440/502, Avg Loss: 4.8492, Avg Regression Loss 1.6795, Avg Classification Loss: 3.1697
2021-05-21 21:30:50 - Epoch: 21, Step: 450/502, Avg Loss: 3.9556, Avg Regression Loss 0.9608, Avg Classification Loss: 2.9949
2021-05-21 21:30:55 - Epoch: 21, Step: 460/502, Avg Loss: 5.3184, Avg Regression Loss 2.1693, Avg Classification Loss: 3.1490
2021-05-21 21:31:00 - Epoch: 21, Step: 470/502, Avg Loss: 5.3145, Avg Regression Loss 1.9396, Avg Classification Loss: 3.3749
2021-05-21 21:31:11 - Epoch: 21, Step: 480/502, Avg Loss: 4.1728, Avg Regression Loss 1.2055, Avg Classification Loss: 2.9673
2021-05-21 21:31:16 - Epoch: 21, Step: 490/502, Avg Loss: 4.6089, Avg Regression Loss 1.4896, Avg Classification Loss: 3.1193
2021-05-21 21:31:21 - Epoch: 21, Step: 500/502, Avg Loss: 4.5752, Avg Regression Loss 1.5024, Avg Classification Loss: 3.0729
2021-05-21 21:32:22 - Epoch: 21, Validation Loss: 4.0307, Validation Regression Loss 1.0419, Validation Classification Loss: 2.9888
2021-05-21 21:32:22 - Saved model models/smd/mb1-ssd-Epoch-21-Loss-4.030674990904759.pth
2021-05-21 21:32:28 - Epoch: 22, Step: 10/502, Avg Loss: 5.5179, Avg Regression Loss 1.5649, Avg Classification Loss: 3.9530
2021-05-21 21:32:37 - Epoch: 22, Step: 20/502, Avg Loss: 5.3765, Avg Regression Loss 2.1780, Avg Classification Loss: 3.1985
2021-05-21 21:32:41 - Epoch: 22, Step: 30/502, Avg Loss: 4.3630, Avg Regression Loss 1.4815, Avg Classification Loss: 2.8815
2021-05-21 21:32:46 - Epoch: 22, Step: 40/502, Avg Loss: 4.6130, Avg Regression Loss 1.5499, Avg Classification Loss: 3.0631
2021-05-21 21:32:51 - Epoch: 22, Step: 50/502, Avg Loss: 3.8026, Avg Regression Loss 0.7575, Avg Classification Loss: 3.0451
2021-05-21 21:32:55 - Epoch: 22, Step: 60/502, Avg Loss: 4.7351, Avg Regression Loss 1.2409, Avg Classification Loss: 3.4942
2021-05-21 21:33:04 - Epoch: 22, Step: 70/502, Avg Loss: 4.8613, Avg Regression Loss 1.5771, Avg Classification Loss: 3.2842
2021-05-21 21:33:09 - Epoch: 22, Step: 80/502, Avg Loss: 4.5189, Avg Regression Loss 1.4571, Avg Classification Loss: 3.0618
2021-05-21 21:33:15 - Epoch: 22, Step: 90/502, Avg Loss: 5.1630, Avg Regression Loss 1.8488, Avg Classification Loss: 3.3142
2021-05-21 21:33:19 - Epoch: 22, Step: 100/502, Avg Loss: 5.0004, Avg Regression Loss 1.8647, Avg Classification Loss: 3.1357
2021-05-21 21:33:24 - Epoch: 22, Step: 110/502, Avg Loss: 4.8535, Avg Regression Loss 1.4528, Avg Classification Loss: 3.4007
2021-05-21 21:33:29 - Epoch: 22, Step: 120/502, Avg Loss: 4.5577, Avg Regression Loss 1.5628, Avg Classification Loss: 2.9949
2021-05-21 21:33:33 - Epoch: 22, Step: 130/502, Avg Loss: 4.7774, Avg Regression Loss 1.6955, Avg Classification Loss: 3.0820
2021-05-21 21:33:38 - Epoch: 22, Step: 140/502, Avg Loss: 5.1947, Avg Regression Loss 1.9115, Avg Classification Loss: 3.2832
2021-05-21 21:33:44 - Epoch: 22, Step: 150/502, Avg Loss: 5.3106, Avg Regression Loss 2.0939, Avg Classification Loss: 3.2167
2021-05-21 21:34:01 - Epoch: 22, Step: 160/502, Avg Loss: 4.7872, Avg Regression Loss 1.5421, Avg Classification Loss: 3.2451
2021-05-21 21:34:08 - Epoch: 22, Step: 170/502, Avg Loss: 4.6979, Avg Regression Loss 1.5373, Avg Classification Loss: 3.1606
2021-05-21 21:34:13 - Epoch: 22, Step: 180/502, Avg Loss: 4.7904, Avg Regression Loss 1.3113, Avg Classification Loss: 3.4790
2021-05-21 21:34:18 - Epoch: 22, Step: 190/502, Avg Loss: 4.9460, Avg Regression Loss 1.9308, Avg Classification Loss: 3.0152
2021-05-21 21:34:22 - Epoch: 22, Step: 200/502, Avg Loss: 4.5284, Avg Regression Loss 1.3977, Avg Classification Loss: 3.1307
2021-05-21 21:34:27 - Epoch: 22, Step: 210/502, Avg Loss: 5.4087, Avg Regression Loss 2.0566, Avg Classification Loss: 3.3521
2021-05-21 21:34:33 - Epoch: 22, Step: 220/502, Avg Loss: 4.8462, Avg Regression Loss 1.7464, Avg Classification Loss: 3.0998
2021-05-21 21:34:38 - Epoch: 22, Step: 230/502, Avg Loss: 4.4094, Avg Regression Loss 1.4867, Avg Classification Loss: 2.9227
2021-05-21 21:34:43 - Epoch: 22, Step: 240/502, Avg Loss: 4.7333, Avg Regression Loss 1.6481, Avg Classification Loss: 3.0852
2021-05-21 21:34:48 - Epoch: 22, Step: 250/502, Avg Loss: 4.5284, Avg Regression Loss 1.4155, Avg Classification Loss: 3.1130
2021-05-21 21:34:53 - Epoch: 22, Step: 260/502, Avg Loss: 4.4927, Avg Regression Loss 1.3930, Avg Classification Loss: 3.0997
2021-05-21 21:34:59 - Epoch: 22, Step: 270/502, Avg Loss: 5.0292, Avg Regression Loss 1.9205, Avg Classification Loss: 3.1087
2021-05-21 21:35:04 - Epoch: 22, Step: 280/502, Avg Loss: 4.6698, Avg Regression Loss 1.6642, Avg Classification Loss: 3.0057
2021-05-21 21:35:09 - Epoch: 22, Step: 290/502, Avg Loss: 4.7414, Avg Regression Loss 1.6611, Avg Classification Loss: 3.0803
2021-05-21 21:35:16 - Epoch: 22, Step: 300/502, Avg Loss: 4.9538, Avg Regression Loss 1.6593, Avg Classification Loss: 3.2945
2021-05-21 21:35:21 - Epoch: 22, Step: 310/502, Avg Loss: 4.5521, Avg Regression Loss 1.5032, Avg Classification Loss: 3.0489
2021-05-21 21:35:26 - Epoch: 22, Step: 320/502, Avg Loss: 4.7561, Avg Regression Loss 1.6926, Avg Classification Loss: 3.0635
2021-05-21 21:35:31 - Epoch: 22, Step: 330/502, Avg Loss: 4.3527, Avg Regression Loss 1.2340, Avg Classification Loss: 3.1187
2021-05-21 21:35:36 - Epoch: 22, Step: 340/502, Avg Loss: 4.7568, Avg Regression Loss 1.5817, Avg Classification Loss: 3.1752
2021-05-21 21:35:41 - Epoch: 22, Step: 350/502, Avg Loss: 4.5278, Avg Regression Loss 1.5178, Avg Classification Loss: 3.0100
2021-05-21 21:35:45 - Epoch: 22, Step: 360/502, Avg Loss: 4.8617, Avg Regression Loss 1.5799, Avg Classification Loss: 3.2818
2021-05-21 21:35:50 - Epoch: 22, Step: 370/502, Avg Loss: 4.5220, Avg Regression Loss 1.4260, Avg Classification Loss: 3.0960
2021-05-21 21:35:55 - Epoch: 22, Step: 380/502, Avg Loss: 4.7477, Avg Regression Loss 1.6315, Avg Classification Loss: 3.1163
2021-05-21 21:36:00 - Epoch: 22, Step: 390/502, Avg Loss: 5.0088, Avg Regression Loss 1.8949, Avg Classification Loss: 3.1139
2021-05-21 21:36:05 - Epoch: 22, Step: 400/502, Avg Loss: 4.5442, Avg Regression Loss 1.4211, Avg Classification Loss: 3.1231
2021-05-21 21:36:10 - Epoch: 22, Step: 410/502, Avg Loss: 4.6616, Avg Regression Loss 1.6095, Avg Classification Loss: 3.0521
2021-05-21 21:36:15 - Epoch: 22, Step: 420/502, Avg Loss: 4.9391, Avg Regression Loss 1.9568, Avg Classification Loss: 2.9822
2021-05-21 21:36:20 - Epoch: 22, Step: 430/502, Avg Loss: 4.9944, Avg Regression Loss 1.8014, Avg Classification Loss: 3.1930
2021-05-21 21:36:26 - Epoch: 22, Step: 440/502, Avg Loss: 4.7444, Avg Regression Loss 1.6080, Avg Classification Loss: 3.1364
2021-05-21 21:36:31 - Epoch: 22, Step: 450/502, Avg Loss: 4.8550, Avg Regression Loss 1.7281, Avg Classification Loss: 3.1269
2021-05-21 21:36:35 - Epoch: 22, Step: 460/502, Avg Loss: 5.5570, Avg Regression Loss 2.1669, Avg Classification Loss: 3.3900
2021-05-21 21:36:40 - Epoch: 22, Step: 470/502, Avg Loss: 4.9025, Avg Regression Loss 1.6478, Avg Classification Loss: 3.2547
2021-05-21 21:36:45 - Epoch: 22, Step: 480/502, Avg Loss: 4.9609, Avg Regression Loss 1.9050, Avg Classification Loss: 3.0560
2021-05-21 21:36:50 - Epoch: 22, Step: 490/502, Avg Loss: 5.3168, Avg Regression Loss 2.2099, Avg Classification Loss: 3.1069
2021-05-21 21:36:55 - Epoch: 22, Step: 500/502, Avg Loss: 4.7188, Avg Regression Loss 1.7401, Avg Classification Loss: 2.9787
2021-05-21 21:37:55 - Epoch: 22, Validation Loss: 3.9320, Validation Regression Loss 1.0281, Validation Classification Loss: 2.9039
2021-05-21 21:37:55 - Saved model models/smd/mb1-ssd-Epoch-22-Loss-3.9319941885917786.pth
2021-05-21 21:38:07 - Epoch: 23, Step: 10/502, Avg Loss: 4.9240, Avg Regression Loss 1.6425, Avg Classification Loss: 3.2814
2021-05-21 21:38:12 - Epoch: 23, Step: 20/502, Avg Loss: 5.4220, Avg Regression Loss 2.2093, Avg Classification Loss: 3.2127
2021-05-21 21:38:17 - Epoch: 23, Step: 30/502, Avg Loss: 4.8424, Avg Regression Loss 1.5506, Avg Classification Loss: 3.2918
2021-05-21 21:38:21 - Epoch: 23, Step: 40/502, Avg Loss: 4.6535, Avg Regression Loss 1.2087, Avg Classification Loss: 3.4448
2021-05-21 21:38:26 - Epoch: 23, Step: 50/502, Avg Loss: 4.8018, Avg Regression Loss 1.7416, Avg Classification Loss: 3.0601
2021-05-21 21:38:31 - Epoch: 23, Step: 60/502, Avg Loss: 4.8155, Avg Regression Loss 1.5507, Avg Classification Loss: 3.2648
2021-05-21 21:38:36 - Epoch: 23, Step: 70/502, Avg Loss: 5.4397, Avg Regression Loss 2.0627, Avg Classification Loss: 3.3770
2021-05-21 21:38:44 - Epoch: 23, Step: 80/502, Avg Loss: 5.4350, Avg Regression Loss 1.9551, Avg Classification Loss: 3.4798
2021-05-21 21:38:49 - Epoch: 23, Step: 90/502, Avg Loss: 5.1285, Avg Regression Loss 1.9085, Avg Classification Loss: 3.2200
2021-05-21 21:39:03 - Epoch: 23, Step: 100/502, Avg Loss: 5.0235, Avg Regression Loss 1.8500, Avg Classification Loss: 3.1735
2021-05-21 21:39:08 - Epoch: 23, Step: 110/502, Avg Loss: 4.3727, Avg Regression Loss 1.4401, Avg Classification Loss: 2.9327
2021-05-21 21:39:12 - Epoch: 23, Step: 120/502, Avg Loss: 5.0727, Avg Regression Loss 1.6851, Avg Classification Loss: 3.3876
2021-05-21 21:39:17 - Epoch: 23, Step: 130/502, Avg Loss: 5.1636, Avg Regression Loss 1.9450, Avg Classification Loss: 3.2186
2021-05-21 21:39:23 - Epoch: 23, Step: 140/502, Avg Loss: 4.9657, Avg Regression Loss 1.8565, Avg Classification Loss: 3.1092
2021-05-21 21:39:28 - Epoch: 23, Step: 150/502, Avg Loss: 5.4119, Avg Regression Loss 2.1577, Avg Classification Loss: 3.2542
2021-05-21 21:39:33 - Epoch: 23, Step: 160/502, Avg Loss: 4.4939, Avg Regression Loss 1.3640, Avg Classification Loss: 3.1299
2021-05-21 21:39:37 - Epoch: 23, Step: 170/502, Avg Loss: 4.8687, Avg Regression Loss 1.6207, Avg Classification Loss: 3.2479
2021-05-21 21:39:42 - Epoch: 23, Step: 180/502, Avg Loss: 4.9826, Avg Regression Loss 1.8900, Avg Classification Loss: 3.0926
2021-05-21 21:39:47 - Epoch: 23, Step: 190/502, Avg Loss: 4.1880, Avg Regression Loss 1.0917, Avg Classification Loss: 3.0963
2021-05-21 21:39:52 - Epoch: 23, Step: 200/502, Avg Loss: 3.9256, Avg Regression Loss 0.9437, Avg Classification Loss: 2.9820
2021-05-21 21:39:56 - Epoch: 23, Step: 210/502, Avg Loss: 4.8488, Avg Regression Loss 1.8756, Avg Classification Loss: 2.9732
2021-05-21 21:40:02 - Epoch: 23, Step: 220/502, Avg Loss: 5.5614, Avg Regression Loss 2.2422, Avg Classification Loss: 3.3192
2021-05-21 21:40:08 - Epoch: 23, Step: 230/502, Avg Loss: 4.6677, Avg Regression Loss 1.4699, Avg Classification Loss: 3.1978
2021-05-21 21:40:14 - Epoch: 23, Step: 240/502, Avg Loss: 4.8036, Avg Regression Loss 1.7746, Avg Classification Loss: 3.0290
2021-05-21 21:40:20 - Epoch: 23, Step: 250/502, Avg Loss: 4.8917, Avg Regression Loss 1.7345, Avg Classification Loss: 3.1572
2021-05-21 21:40:25 - Epoch: 23, Step: 260/502, Avg Loss: 5.4041, Avg Regression Loss 2.2422, Avg Classification Loss: 3.1618
2021-05-21 21:40:30 - Epoch: 23, Step: 270/502, Avg Loss: 4.8422, Avg Regression Loss 1.6934, Avg Classification Loss: 3.1489
2021-05-21 21:40:35 - Epoch: 23, Step: 280/502, Avg Loss: 4.4171, Avg Regression Loss 1.3341, Avg Classification Loss: 3.0829
2021-05-21 21:40:48 - Epoch: 23, Step: 290/502, Avg Loss: 4.6841, Avg Regression Loss 1.4357, Avg Classification Loss: 3.2484
2021-05-21 21:40:53 - Epoch: 23, Step: 300/502, Avg Loss: 4.5519, Avg Regression Loss 1.5858, Avg Classification Loss: 2.9661
2021-05-21 21:40:58 - Epoch: 23, Step: 310/502, Avg Loss: 4.4170, Avg Regression Loss 1.5110, Avg Classification Loss: 2.9060
2021-05-21 21:41:02 - Epoch: 23, Step: 320/502, Avg Loss: 5.0345, Avg Regression Loss 1.7514, Avg Classification Loss: 3.2831
2021-05-21 21:41:07 - Epoch: 23, Step: 330/502, Avg Loss: 5.0076, Avg Regression Loss 1.8005, Avg Classification Loss: 3.2072
2021-05-21 21:41:13 - Epoch: 23, Step: 340/502, Avg Loss: 5.2828, Avg Regression Loss 1.8945, Avg Classification Loss: 3.3883
2021-05-21 21:41:17 - Epoch: 23, Step: 350/502, Avg Loss: 5.1371, Avg Regression Loss 1.9331, Avg Classification Loss: 3.2040
2021-05-21 21:41:29 - Epoch: 23, Step: 360/502, Avg Loss: 5.8825, Avg Regression Loss 2.5162, Avg Classification Loss: 3.3664
2021-05-21 21:41:34 - Epoch: 23, Step: 370/502, Avg Loss: 4.1364, Avg Regression Loss 1.2582, Avg Classification Loss: 2.8782
2021-05-21 21:41:40 - Epoch: 23, Step: 380/502, Avg Loss: 5.4685, Avg Regression Loss 2.1820, Avg Classification Loss: 3.2864
2021-05-21 21:41:45 - Epoch: 23, Step: 390/502, Avg Loss: 5.0987, Avg Regression Loss 1.7697, Avg Classification Loss: 3.3291
2021-05-21 21:41:50 - Epoch: 23, Step: 400/502, Avg Loss: 4.7289, Avg Regression Loss 1.8404, Avg Classification Loss: 2.8885
2021-05-21 21:41:55 - Epoch: 23, Step: 410/502, Avg Loss: 4.2066, Avg Regression Loss 1.2721, Avg Classification Loss: 2.9345
2021-05-21 21:41:59 - Epoch: 23, Step: 420/502, Avg Loss: 5.2434, Avg Regression Loss 2.0470, Avg Classification Loss: 3.1965
2021-05-21 21:42:04 - Epoch: 23, Step: 430/502, Avg Loss: 4.0642, Avg Regression Loss 1.2079, Avg Classification Loss: 2.8563
2021-05-21 21:42:09 - Epoch: 23, Step: 440/502, Avg Loss: 4.9512, Avg Regression Loss 1.6882, Avg Classification Loss: 3.2630
2021-05-21 21:42:14 - Epoch: 23, Step: 450/502, Avg Loss: 4.8522, Avg Regression Loss 1.6175, Avg Classification Loss: 3.2347
2021-05-21 21:42:19 - Epoch: 23, Step: 460/502, Avg Loss: 5.1850, Avg Regression Loss 1.7783, Avg Classification Loss: 3.4068
2021-05-21 21:42:25 - Epoch: 23, Step: 470/502, Avg Loss: 5.4166, Avg Regression Loss 2.1354, Avg Classification Loss: 3.2812
2021-05-21 21:42:30 - Epoch: 23, Step: 480/502, Avg Loss: 5.0330, Avg Regression Loss 1.7247, Avg Classification Loss: 3.3083
2021-05-21 21:42:35 - Epoch: 23, Step: 490/502, Avg Loss: 4.4806, Avg Regression Loss 1.4655, Avg Classification Loss: 3.0150
2021-05-21 21:42:41 - Epoch: 23, Step: 500/502, Avg Loss: 4.5815, Avg Regression Loss 1.3800, Avg Classification Loss: 3.2015
2021-05-21 21:43:42 - Epoch: 23, Validation Loss: 4.0557, Validation Regression Loss 1.0609, Validation Classification Loss: 2.9947
2021-05-21 21:43:43 - Saved model models/smd/mb1-ssd-Epoch-23-Loss-4.055684765496577.pth
2021-05-21 21:43:49 - Epoch: 24, Step: 10/502, Avg Loss: 4.7196, Avg Regression Loss 1.4786, Avg Classification Loss: 3.2410
2021-05-21 21:43:56 - Epoch: 24, Step: 20/502, Avg Loss: 5.0914, Avg Regression Loss 1.7600, Avg Classification Loss: 3.3313
2021-05-21 21:44:02 - Epoch: 24, Step: 30/502, Avg Loss: 4.6669, Avg Regression Loss 1.5682, Avg Classification Loss: 3.0986
2021-05-21 21:44:07 - Epoch: 24, Step: 40/502, Avg Loss: 4.5076, Avg Regression Loss 1.3461, Avg Classification Loss: 3.1615
2021-05-21 21:44:11 - Epoch: 24, Step: 50/502, Avg Loss: 4.2464, Avg Regression Loss 1.0965, Avg Classification Loss: 3.1499
2021-05-21 21:44:16 - Epoch: 24, Step: 60/502, Avg Loss: 3.9008, Avg Regression Loss 1.0421, Avg Classification Loss: 2.8587
2021-05-21 21:44:21 - Epoch: 24, Step: 70/502, Avg Loss: 5.1873, Avg Regression Loss 2.0579, Avg Classification Loss: 3.1294
2021-05-21 21:44:25 - Epoch: 24, Step: 80/502, Avg Loss: 4.9857, Avg Regression Loss 1.7255, Avg Classification Loss: 3.2602
2021-05-21 21:44:32 - Epoch: 24, Step: 90/502, Avg Loss: 4.8062, Avg Regression Loss 1.7845, Avg Classification Loss: 3.0217
2021-05-21 21:44:36 - Epoch: 24, Step: 100/502, Avg Loss: 4.4312, Avg Regression Loss 1.4219, Avg Classification Loss: 3.0093
2021-05-21 21:44:41 - Epoch: 24, Step: 110/502, Avg Loss: 4.4162, Avg Regression Loss 1.6304, Avg Classification Loss: 2.7858
2021-05-21 21:44:47 - Epoch: 24, Step: 120/502, Avg Loss: 5.7065, Avg Regression Loss 2.1905, Avg Classification Loss: 3.5160
2021-05-21 21:44:52 - Epoch: 24, Step: 130/502, Avg Loss: 3.9947, Avg Regression Loss 1.1022, Avg Classification Loss: 2.8925
2021-05-21 21:44:56 - Epoch: 24, Step: 140/502, Avg Loss: 5.2180, Avg Regression Loss 2.1814, Avg Classification Loss: 3.0366
2021-05-21 21:45:01 - Epoch: 24, Step: 150/502, Avg Loss: 5.1921, Avg Regression Loss 2.1880, Avg Classification Loss: 3.0040
2021-05-21 21:45:14 - Epoch: 24, Step: 160/502, Avg Loss: 5.5775, Avg Regression Loss 2.3539, Avg Classification Loss: 3.2236
2021-05-21 21:45:18 - Epoch: 24, Step: 170/502, Avg Loss: 4.6346, Avg Regression Loss 1.3546, Avg Classification Loss: 3.2800
2021-05-21 21:45:23 - Epoch: 24, Step: 180/502, Avg Loss: 4.3040, Avg Regression Loss 1.0241, Avg Classification Loss: 3.2798
2021-05-21 21:45:28 - Epoch: 24, Step: 190/502, Avg Loss: 4.5438, Avg Regression Loss 1.4195, Avg Classification Loss: 3.1242
2021-05-21 21:45:32 - Epoch: 24, Step: 200/502, Avg Loss: 4.4065, Avg Regression Loss 1.2768, Avg Classification Loss: 3.1297
2021-05-21 21:45:37 - Epoch: 24, Step: 210/502, Avg Loss: 4.1125, Avg Regression Loss 1.2158, Avg Classification Loss: 2.8967
2021-05-21 21:45:42 - Epoch: 24, Step: 220/502, Avg Loss: 5.2598, Avg Regression Loss 2.0498, Avg Classification Loss: 3.2100
2021-05-21 21:45:53 - Epoch: 24, Step: 230/502, Avg Loss: 5.0924, Avg Regression Loss 1.8225, Avg Classification Loss: 3.2699
2021-05-21 21:45:58 - Epoch: 24, Step: 240/502, Avg Loss: 4.8298, Avg Regression Loss 1.6515, Avg Classification Loss: 3.1783
2021-05-21 21:46:04 - Epoch: 24, Step: 250/502, Avg Loss: 4.2500, Avg Regression Loss 1.1085, Avg Classification Loss: 3.1415
2021-05-21 21:46:09 - Epoch: 24, Step: 260/502, Avg Loss: 4.7795, Avg Regression Loss 1.6417, Avg Classification Loss: 3.1377
2021-05-21 21:46:14 - Epoch: 24, Step: 270/502, Avg Loss: 4.2641, Avg Regression Loss 1.2710, Avg Classification Loss: 2.9930
2021-05-21 21:46:22 - Epoch: 24, Step: 280/502, Avg Loss: 4.9111, Avg Regression Loss 1.7784, Avg Classification Loss: 3.1328
2021-05-21 21:46:26 - Epoch: 24, Step: 290/502, Avg Loss: 4.2651, Avg Regression Loss 1.2390, Avg Classification Loss: 3.0261
2021-05-21 21:46:32 - Epoch: 24, Step: 300/502, Avg Loss: 4.5356, Avg Regression Loss 1.3509, Avg Classification Loss: 3.1848
2021-05-21 21:46:37 - Epoch: 24, Step: 310/502, Avg Loss: 4.7905, Avg Regression Loss 1.7823, Avg Classification Loss: 3.0082
2021-05-21 21:46:42 - Epoch: 24, Step: 320/502, Avg Loss: 4.5408, Avg Regression Loss 1.2663, Avg Classification Loss: 3.2745
2021-05-21 21:46:46 - Epoch: 24, Step: 330/502, Avg Loss: 4.4815, Avg Regression Loss 1.5428, Avg Classification Loss: 2.9387
2021-05-21 21:46:52 - Epoch: 24, Step: 340/502, Avg Loss: 3.7734, Avg Regression Loss 0.9059, Avg Classification Loss: 2.8675
2021-05-21 21:46:57 - Epoch: 24, Step: 350/502, Avg Loss: 4.7117, Avg Regression Loss 1.4500, Avg Classification Loss: 3.2617
2021-05-21 21:47:02 - Epoch: 24, Step: 360/502, Avg Loss: 5.3407, Avg Regression Loss 2.2341, Avg Classification Loss: 3.1066
2021-05-21 21:47:09 - Epoch: 24, Step: 370/502, Avg Loss: 4.5175, Avg Regression Loss 1.6334, Avg Classification Loss: 2.8841
2021-05-21 21:47:14 - Epoch: 24, Step: 380/502, Avg Loss: 5.2792, Avg Regression Loss 2.0929, Avg Classification Loss: 3.1863
2021-05-21 21:47:18 - Epoch: 24, Step: 390/502, Avg Loss: 4.5701, Avg Regression Loss 1.6683, Avg Classification Loss: 2.9018
2021-05-21 21:47:23 - Epoch: 24, Step: 400/502, Avg Loss: 4.4983, Avg Regression Loss 1.4742, Avg Classification Loss: 3.0242
2021-05-21 21:47:28 - Epoch: 24, Step: 410/502, Avg Loss: 4.4366, Avg Regression Loss 1.5322, Avg Classification Loss: 2.9044
2021-05-21 21:47:33 - Epoch: 24, Step: 420/502, Avg Loss: 4.6255, Avg Regression Loss 1.5877, Avg Classification Loss: 3.0377
2021-05-21 21:47:38 - Epoch: 24, Step: 430/502, Avg Loss: 4.4855, Avg Regression Loss 1.5826, Avg Classification Loss: 2.9029
2021-05-21 21:47:44 - Epoch: 24, Step: 440/502, Avg Loss: 4.9024, Avg Regression Loss 1.6137, Avg Classification Loss: 3.2887
2021-05-21 21:47:49 - Epoch: 24, Step: 450/502, Avg Loss: 4.5258, Avg Regression Loss 1.1870, Avg Classification Loss: 3.3388
2021-05-21 21:47:53 - Epoch: 24, Step: 460/502, Avg Loss: 4.1352, Avg Regression Loss 1.2098, Avg Classification Loss: 2.9254
2021-05-21 21:47:58 - Epoch: 24, Step: 470/502, Avg Loss: 4.0734, Avg Regression Loss 1.1738, Avg Classification Loss: 2.8996
2021-05-21 21:48:03 - Epoch: 24, Step: 480/502, Avg Loss: 4.4565, Avg Regression Loss 1.5635, Avg Classification Loss: 2.8930
2021-05-21 21:48:07 - Epoch: 24, Step: 490/502, Avg Loss: 4.5711, Avg Regression Loss 1.4656, Avg Classification Loss: 3.1055
2021-05-21 21:48:12 - Epoch: 24, Step: 500/502, Avg Loss: 4.0476, Avg Regression Loss 1.1215, Avg Classification Loss: 2.9261
2021-05-21 21:49:12 - Epoch: 24, Validation Loss: 3.6986, Validation Regression Loss 0.8883, Validation Classification Loss: 2.8103
2021-05-21 21:49:12 - Saved model models/smd/mb1-ssd-Epoch-24-Loss-3.6985708427619173.pth
2021-05-21 21:49:20 - Epoch: 25, Step: 10/502, Avg Loss: 5.3274, Avg Regression Loss 2.0262, Avg Classification Loss: 3.3012
2021-05-21 21:49:28 - Epoch: 25, Step: 20/502, Avg Loss: 4.5992, Avg Regression Loss 1.6072, Avg Classification Loss: 2.9920
2021-05-21 21:49:34 - Epoch: 25, Step: 30/502, Avg Loss: 4.0171, Avg Regression Loss 1.1763, Avg Classification Loss: 2.8408
2021-05-21 21:49:38 - Epoch: 25, Step: 40/502, Avg Loss: 4.5535, Avg Regression Loss 1.4914, Avg Classification Loss: 3.0620
2021-05-21 21:49:43 - Epoch: 25, Step: 50/502, Avg Loss: 3.8531, Avg Regression Loss 1.1413, Avg Classification Loss: 2.7117
2021-05-21 21:49:48 - Epoch: 25, Step: 60/502, Avg Loss: 4.4020, Avg Regression Loss 1.2651, Avg Classification Loss: 3.1368
2021-05-21 21:49:53 - Epoch: 25, Step: 70/502, Avg Loss: 4.0215, Avg Regression Loss 1.3332, Avg Classification Loss: 2.6882
2021-05-21 21:50:00 - Epoch: 25, Step: 80/502, Avg Loss: 5.2559, Avg Regression Loss 2.0545, Avg Classification Loss: 3.2014
2021-05-21 21:50:04 - Epoch: 25, Step: 90/502, Avg Loss: 3.9613, Avg Regression Loss 1.2549, Avg Classification Loss: 2.7064
2021-05-21 21:50:18 - Epoch: 25, Step: 100/502, Avg Loss: 4.0695, Avg Regression Loss 1.1590, Avg Classification Loss: 2.9105
2021-05-21 21:50:23 - Epoch: 25, Step: 110/502, Avg Loss: 4.7516, Avg Regression Loss 1.7071, Avg Classification Loss: 3.0445
2021-05-21 21:50:28 - Epoch: 25, Step: 120/502, Avg Loss: 4.3787, Avg Regression Loss 1.3521, Avg Classification Loss: 3.0266
2021-05-21 21:50:33 - Epoch: 25, Step: 130/502, Avg Loss: 4.9731, Avg Regression Loss 1.6486, Avg Classification Loss: 3.3246
2021-05-21 21:50:39 - Epoch: 25, Step: 140/502, Avg Loss: 4.5316, Avg Regression Loss 1.2938, Avg Classification Loss: 3.2378
2021-05-21 21:50:44 - Epoch: 25, Step: 150/502, Avg Loss: 4.2062, Avg Regression Loss 1.1983, Avg Classification Loss: 3.0078
2021-05-21 21:50:48 - Epoch: 25, Step: 160/502, Avg Loss: 5.0810, Avg Regression Loss 1.6878, Avg Classification Loss: 3.3932
2021-05-21 21:50:54 - Epoch: 25, Step: 170/502, Avg Loss: 4.7642, Avg Regression Loss 1.5938, Avg Classification Loss: 3.1705
2021-05-21 21:50:59 - Epoch: 25, Step: 180/502, Avg Loss: 3.9643, Avg Regression Loss 1.0961, Avg Classification Loss: 2.8682
2021-05-21 21:51:04 - Epoch: 25, Step: 190/502, Avg Loss: 4.9883, Avg Regression Loss 1.9544, Avg Classification Loss: 3.0339
2021-05-21 21:51:08 - Epoch: 25, Step: 200/502, Avg Loss: 3.5866, Avg Regression Loss 0.7982, Avg Classification Loss: 2.7884
2021-05-21 21:51:13 - Epoch: 25, Step: 210/502, Avg Loss: 4.4867, Avg Regression Loss 1.4195, Avg Classification Loss: 3.0672
2021-05-21 21:51:18 - Epoch: 25, Step: 220/502, Avg Loss: 4.3136, Avg Regression Loss 1.3038, Avg Classification Loss: 3.0098
2021-05-21 21:51:23 - Epoch: 25, Step: 230/502, Avg Loss: 5.6862, Avg Regression Loss 2.0092, Avg Classification Loss: 3.6770
2021-05-21 21:51:28 - Epoch: 25, Step: 240/502, Avg Loss: 4.7905, Avg Regression Loss 1.7429, Avg Classification Loss: 3.0476
2021-05-21 21:51:33 - Epoch: 25, Step: 250/502, Avg Loss: 4.9548, Avg Regression Loss 1.7235, Avg Classification Loss: 3.2313
2021-05-21 21:51:38 - Epoch: 25, Step: 260/502, Avg Loss: 4.1551, Avg Regression Loss 1.2417, Avg Classification Loss: 2.9134
2021-05-21 21:51:42 - Epoch: 25, Step: 270/502, Avg Loss: 4.4282, Avg Regression Loss 1.3075, Avg Classification Loss: 3.1208
2021-05-21 21:51:47 - Epoch: 25, Step: 280/502, Avg Loss: 4.3666, Avg Regression Loss 1.2031, Avg Classification Loss: 3.1635
2021-05-21 21:51:56 - Epoch: 25, Step: 290/502, Avg Loss: 4.6128, Avg Regression Loss 1.2828, Avg Classification Loss: 3.3300
2021-05-21 21:52:01 - Epoch: 25, Step: 300/502, Avg Loss: 4.2709, Avg Regression Loss 1.2418, Avg Classification Loss: 3.0290
2021-05-21 21:52:06 - Epoch: 25, Step: 310/502, Avg Loss: 3.9867, Avg Regression Loss 1.0761, Avg Classification Loss: 2.9106
2021-05-21 21:52:11 - Epoch: 25, Step: 320/502, Avg Loss: 4.2239, Avg Regression Loss 1.0926, Avg Classification Loss: 3.1313
2021-05-21 21:52:16 - Epoch: 25, Step: 330/502, Avg Loss: 4.5999, Avg Regression Loss 1.2351, Avg Classification Loss: 3.3648
2021-05-21 21:52:21 - Epoch: 25, Step: 340/502, Avg Loss: 4.3344, Avg Regression Loss 1.3015, Avg Classification Loss: 3.0328
2021-05-21 21:52:27 - Epoch: 25, Step: 350/502, Avg Loss: 4.4382, Avg Regression Loss 1.3724, Avg Classification Loss: 3.0658
2021-05-21 21:52:37 - Epoch: 25, Step: 360/502, Avg Loss: 4.2869, Avg Regression Loss 1.1114, Avg Classification Loss: 3.1755
2021-05-21 21:52:41 - Epoch: 25, Step: 370/502, Avg Loss: 4.6967, Avg Regression Loss 1.5883, Avg Classification Loss: 3.1085
2021-05-21 21:52:48 - Epoch: 25, Step: 380/502, Avg Loss: 5.4016, Avg Regression Loss 2.0249, Avg Classification Loss: 3.3767
2021-05-21 21:52:53 - Epoch: 25, Step: 390/502, Avg Loss: 5.4922, Avg Regression Loss 2.1775, Avg Classification Loss: 3.3147
2021-05-21 21:52:58 - Epoch: 25, Step: 400/502, Avg Loss: 4.4452, Avg Regression Loss 1.3311, Avg Classification Loss: 3.1142
2021-05-21 21:53:04 - Epoch: 25, Step: 410/502, Avg Loss: 4.8589, Avg Regression Loss 1.6681, Avg Classification Loss: 3.1909
2021-05-21 21:53:09 - Epoch: 25, Step: 420/502, Avg Loss: 4.7587, Avg Regression Loss 1.6099, Avg Classification Loss: 3.1488
2021-05-21 21:53:15 - Epoch: 25, Step: 430/502, Avg Loss: 5.4010, Avg Regression Loss 2.0442, Avg Classification Loss: 3.3568
2021-05-21 21:53:19 - Epoch: 25, Step: 440/502, Avg Loss: 4.1557, Avg Regression Loss 1.3717, Avg Classification Loss: 2.7839
2021-05-21 21:53:25 - Epoch: 25, Step: 450/502, Avg Loss: 4.9526, Avg Regression Loss 2.0441, Avg Classification Loss: 2.9085
2021-05-21 21:53:30 - Epoch: 25, Step: 460/502, Avg Loss: 4.4685, Avg Regression Loss 1.5360, Avg Classification Loss: 2.9325
2021-05-21 21:53:34 - Epoch: 25, Step: 470/502, Avg Loss: 4.8915, Avg Regression Loss 1.8743, Avg Classification Loss: 3.0171
2021-05-21 21:53:39 - Epoch: 25, Step: 480/502, Avg Loss: 3.8127, Avg Regression Loss 0.9972, Avg Classification Loss: 2.8155
2021-05-21 21:53:44 - Epoch: 25, Step: 490/502, Avg Loss: 4.5544, Avg Regression Loss 1.4735, Avg Classification Loss: 3.0809
2021-05-21 21:53:49 - Epoch: 25, Step: 500/502, Avg Loss: 4.4149, Avg Regression Loss 1.3193, Avg Classification Loss: 3.0957
2021-05-21 21:54:51 - Epoch: 25, Validation Loss: 3.8353, Validation Regression Loss 1.0159, Validation Classification Loss: 2.8194
2021-05-21 21:54:51 - Saved model models/smd/mb1-ssd-Epoch-25-Loss-3.835306785496108.pth
2021-05-21 21:54:57 - Epoch: 26, Step: 10/502, Avg Loss: 4.4858, Avg Regression Loss 1.3334, Avg Classification Loss: 3.1525
2021-05-21 21:55:01 - Epoch: 26, Step: 20/502, Avg Loss: 4.6462, Avg Regression Loss 1.7323, Avg Classification Loss: 2.9139
2021-05-21 21:55:07 - Epoch: 26, Step: 30/502, Avg Loss: 4.3882, Avg Regression Loss 1.4615, Avg Classification Loss: 2.9267
2021-05-21 21:55:12 - Epoch: 26, Step: 40/502, Avg Loss: 4.7641, Avg Regression Loss 1.5725, Avg Classification Loss: 3.1916
2021-05-21 21:55:16 - Epoch: 26, Step: 50/502, Avg Loss: 4.5438, Avg Regression Loss 1.3520, Avg Classification Loss: 3.1918
2021-05-21 21:55:21 - Epoch: 26, Step: 60/502, Avg Loss: 4.6386, Avg Regression Loss 1.6785, Avg Classification Loss: 2.9601
2021-05-21 21:55:26 - Epoch: 26, Step: 70/502, Avg Loss: 4.2725, Avg Regression Loss 1.2109, Avg Classification Loss: 3.0615
2021-05-21 21:55:32 - Epoch: 26, Step: 80/502, Avg Loss: 4.6810, Avg Regression Loss 1.7057, Avg Classification Loss: 2.9753
2021-05-21 21:55:37 - Epoch: 26, Step: 90/502, Avg Loss: 5.2929, Avg Regression Loss 2.0802, Avg Classification Loss: 3.2127
2021-05-21 21:55:45 - Epoch: 26, Step: 100/502, Avg Loss: 4.9734, Avg Regression Loss 1.6425, Avg Classification Loss: 3.3309
2021-05-21 21:55:49 - Epoch: 26, Step: 110/502, Avg Loss: 4.1251, Avg Regression Loss 1.2817, Avg Classification Loss: 2.8435
2021-05-21 21:55:55 - Epoch: 26, Step: 120/502, Avg Loss: 4.5278, Avg Regression Loss 1.4682, Avg Classification Loss: 3.0596
2021-05-21 21:55:59 - Epoch: 26, Step: 130/502, Avg Loss: 4.6316, Avg Regression Loss 1.4934, Avg Classification Loss: 3.1382
2021-05-21 21:56:04 - Epoch: 26, Step: 140/502, Avg Loss: 4.8620, Avg Regression Loss 1.7062, Avg Classification Loss: 3.1557
2021-05-21 21:56:18 - Epoch: 26, Step: 150/502, Avg Loss: 4.9588, Avg Regression Loss 1.8979, Avg Classification Loss: 3.0608
2021-05-21 21:56:23 - Epoch: 26, Step: 160/502, Avg Loss: 4.6314, Avg Regression Loss 1.7026, Avg Classification Loss: 2.9288
2021-05-21 21:56:28 - Epoch: 26, Step: 170/502, Avg Loss: 4.3006, Avg Regression Loss 1.3599, Avg Classification Loss: 2.9407
2021-05-21 21:56:33 - Epoch: 26, Step: 180/502, Avg Loss: 4.4168, Avg Regression Loss 1.2060, Avg Classification Loss: 3.2108
2021-05-21 21:56:37 - Epoch: 26, Step: 190/502, Avg Loss: 4.4292, Avg Regression Loss 1.2569, Avg Classification Loss: 3.1723
2021-05-21 21:56:43 - Epoch: 26, Step: 200/502, Avg Loss: 3.9612, Avg Regression Loss 1.0118, Avg Classification Loss: 2.9495
2021-05-21 21:56:47 - Epoch: 26, Step: 210/502, Avg Loss: 4.0783, Avg Regression Loss 1.3724, Avg Classification Loss: 2.7059
2021-05-21 21:56:53 - Epoch: 26, Step: 220/502, Avg Loss: 4.3804, Avg Regression Loss 1.4213, Avg Classification Loss: 2.9591
2021-05-21 21:56:58 - Epoch: 26, Step: 230/502, Avg Loss: 5.0395, Avg Regression Loss 1.8609, Avg Classification Loss: 3.1786
2021-05-21 21:57:03 - Epoch: 26, Step: 240/502, Avg Loss: 4.6617, Avg Regression Loss 1.4937, Avg Classification Loss: 3.1680
2021-05-21 21:57:08 - Epoch: 26, Step: 250/502, Avg Loss: 4.0525, Avg Regression Loss 1.1621, Avg Classification Loss: 2.8903
2021-05-21 21:57:13 - Epoch: 26, Step: 260/502, Avg Loss: 4.5697, Avg Regression Loss 1.6490, Avg Classification Loss: 2.9207
2021-05-21 21:57:17 - Epoch: 26, Step: 270/502, Avg Loss: 4.6185, Avg Regression Loss 1.5414, Avg Classification Loss: 3.0771
2021-05-21 21:57:22 - Epoch: 26, Step: 280/502, Avg Loss: 4.3391, Avg Regression Loss 1.3937, Avg Classification Loss: 2.9455
2021-05-21 21:57:30 - Epoch: 26, Step: 290/502, Avg Loss: 4.0463, Avg Regression Loss 1.1655, Avg Classification Loss: 2.8808
2021-05-21 21:57:35 - Epoch: 26, Step: 300/502, Avg Loss: 4.2439, Avg Regression Loss 1.2711, Avg Classification Loss: 2.9728
2021-05-21 21:57:39 - Epoch: 26, Step: 310/502, Avg Loss: 4.2802, Avg Regression Loss 1.4611, Avg Classification Loss: 2.8191
2021-05-21 21:57:44 - Epoch: 26, Step: 320/502, Avg Loss: 5.1186, Avg Regression Loss 1.9365, Avg Classification Loss: 3.1821
2021-05-21 21:57:49 - Epoch: 26, Step: 330/502, Avg Loss: 3.9573, Avg Regression Loss 1.0091, Avg Classification Loss: 2.9481
2021-05-21 21:57:53 - Epoch: 26, Step: 340/502, Avg Loss: 4.6139, Avg Regression Loss 1.7088, Avg Classification Loss: 2.9051
2021-05-21 21:58:00 - Epoch: 26, Step: 350/502, Avg Loss: 4.8702, Avg Regression Loss 1.7102, Avg Classification Loss: 3.1600
2021-05-21 21:58:09 - Epoch: 26, Step: 360/502, Avg Loss: 4.3499, Avg Regression Loss 1.3055, Avg Classification Loss: 3.0444
2021-05-21 21:58:15 - Epoch: 26, Step: 370/502, Avg Loss: 4.3006, Avg Regression Loss 1.5157, Avg Classification Loss: 2.7848
2021-05-21 21:58:20 - Epoch: 26, Step: 380/502, Avg Loss: 4.8167, Avg Regression Loss 1.6548, Avg Classification Loss: 3.1619
2021-05-21 21:58:25 - Epoch: 26, Step: 390/502, Avg Loss: 3.7987, Avg Regression Loss 1.1507, Avg Classification Loss: 2.6479
2021-05-21 21:58:30 - Epoch: 26, Step: 400/502, Avg Loss: 4.7030, Avg Regression Loss 1.6147, Avg Classification Loss: 3.0883
2021-05-21 21:58:34 - Epoch: 26, Step: 410/502, Avg Loss: 4.5630, Avg Regression Loss 1.5840, Avg Classification Loss: 2.9790
2021-05-21 21:58:39 - Epoch: 26, Step: 420/502, Avg Loss: 4.6426, Avg Regression Loss 1.8566, Avg Classification Loss: 2.7860
2021-05-21 21:58:45 - Epoch: 26, Step: 430/502, Avg Loss: 4.5128, Avg Regression Loss 1.5783, Avg Classification Loss: 2.9345
2021-05-21 21:58:50 - Epoch: 26, Step: 440/502, Avg Loss: 4.3122, Avg Regression Loss 1.2955, Avg Classification Loss: 3.0166
2021-05-21 21:58:55 - Epoch: 26, Step: 450/502, Avg Loss: 5.2087, Avg Regression Loss 2.0183, Avg Classification Loss: 3.1904
2021-05-21 21:59:00 - Epoch: 26, Step: 460/502, Avg Loss: 4.6115, Avg Regression Loss 1.6628, Avg Classification Loss: 2.9487
2021-05-21 21:59:13 - Epoch: 26, Step: 470/502, Avg Loss: 4.6828, Avg Regression Loss 1.7713, Avg Classification Loss: 2.9115
2021-05-21 21:59:18 - Epoch: 26, Step: 480/502, Avg Loss: 4.6519, Avg Regression Loss 1.4000, Avg Classification Loss: 3.2518
2021-05-21 21:59:24 - Epoch: 26, Step: 490/502, Avg Loss: 4.4281, Avg Regression Loss 1.3854, Avg Classification Loss: 3.0428
2021-05-21 21:59:29 - Epoch: 26, Step: 500/502, Avg Loss: 4.2785, Avg Regression Loss 1.2535, Avg Classification Loss: 3.0250
2021-05-21 22:00:29 - Epoch: 26, Validation Loss: 4.0656, Validation Regression Loss 1.3228, Validation Classification Loss: 2.7429
2021-05-21 22:00:29 - Saved model models/smd/mb1-ssd-Epoch-26-Loss-4.065649043991272.pth
2021-05-21 22:00:36 - Epoch: 27, Step: 10/502, Avg Loss: 4.9915, Avg Regression Loss 1.7502, Avg Classification Loss: 3.2413
2021-05-21 22:00:41 - Epoch: 27, Step: 20/502, Avg Loss: 4.4087, Avg Regression Loss 1.4324, Avg Classification Loss: 2.9763
2021-05-21 22:00:47 - Epoch: 27, Step: 30/502, Avg Loss: 4.5379, Avg Regression Loss 1.5553, Avg Classification Loss: 2.9826
2021-05-21 22:00:52 - Epoch: 27, Step: 40/502, Avg Loss: 4.2037, Avg Regression Loss 1.2224, Avg Classification Loss: 2.9813
2021-05-21 22:00:57 - Epoch: 27, Step: 50/502, Avg Loss: 3.9143, Avg Regression Loss 1.1280, Avg Classification Loss: 2.7863
2021-05-21 22:01:01 - Epoch: 27, Step: 60/502, Avg Loss: 4.4193, Avg Regression Loss 1.4161, Avg Classification Loss: 3.0032
2021-05-21 22:01:07 - Epoch: 27, Step: 70/502, Avg Loss: 4.2286, Avg Regression Loss 1.4261, Avg Classification Loss: 2.8025
2021-05-21 22:01:11 - Epoch: 27, Step: 80/502, Avg Loss: 4.0255, Avg Regression Loss 1.1513, Avg Classification Loss: 2.8742
2021-05-21 22:01:18 - Epoch: 27, Step: 90/502, Avg Loss: 5.1168, Avg Regression Loss 1.7740, Avg Classification Loss: 3.3428
2021-05-21 22:01:23 - Epoch: 27, Step: 100/502, Avg Loss: 4.0847, Avg Regression Loss 0.8703, Avg Classification Loss: 3.2144
2021-05-21 22:01:29 - Epoch: 27, Step: 110/502, Avg Loss: 4.2183, Avg Regression Loss 1.0224, Avg Classification Loss: 3.1959
2021-05-21 22:01:34 - Epoch: 27, Step: 120/502, Avg Loss: 4.4678, Avg Regression Loss 1.2172, Avg Classification Loss: 3.2506
2021-05-21 22:01:39 - Epoch: 27, Step: 130/502, Avg Loss: 4.6355, Avg Regression Loss 1.5408, Avg Classification Loss: 3.0947
2021-05-21 22:01:43 - Epoch: 27, Step: 140/502, Avg Loss: 4.5790, Avg Regression Loss 1.4540, Avg Classification Loss: 3.1250
2021-05-21 22:01:48 - Epoch: 27, Step: 150/502, Avg Loss: 4.9616, Avg Regression Loss 1.6988, Avg Classification Loss: 3.2628
2021-05-21 22:01:54 - Epoch: 27, Step: 160/502, Avg Loss: 4.6904, Avg Regression Loss 1.7125, Avg Classification Loss: 2.9779
2021-05-21 22:02:02 - Epoch: 27, Step: 170/502, Avg Loss: 4.1317, Avg Regression Loss 1.1249, Avg Classification Loss: 3.0068
2021-05-21 22:02:06 - Epoch: 27, Step: 180/502, Avg Loss: 4.2202, Avg Regression Loss 1.4288, Avg Classification Loss: 2.7915
2021-05-21 22:02:12 - Epoch: 27, Step: 190/502, Avg Loss: 4.4716, Avg Regression Loss 1.3962, Avg Classification Loss: 3.0754
2021-05-21 22:02:17 - Epoch: 27, Step: 200/502, Avg Loss: 4.6892, Avg Regression Loss 1.4111, Avg Classification Loss: 3.2781
2021-05-21 22:02:22 - Epoch: 27, Step: 210/502, Avg Loss: 4.7415, Avg Regression Loss 1.4102, Avg Classification Loss: 3.3313
2021-05-21 22:02:28 - Epoch: 27, Step: 220/502, Avg Loss: 4.8968, Avg Regression Loss 1.9434, Avg Classification Loss: 2.9534
2021-05-21 22:02:37 - Epoch: 27, Step: 230/502, Avg Loss: 4.7209, Avg Regression Loss 1.6891, Avg Classification Loss: 3.0318
2021-05-21 22:02:42 - Epoch: 27, Step: 240/502, Avg Loss: 4.7046, Avg Regression Loss 1.6539, Avg Classification Loss: 3.0506
2021-05-21 22:02:51 - Epoch: 27, Step: 250/502, Avg Loss: 4.2837, Avg Regression Loss 1.3465, Avg Classification Loss: 2.9372
2021-05-21 22:02:56 - Epoch: 27, Step: 260/502, Avg Loss: 4.2298, Avg Regression Loss 1.1844, Avg Classification Loss: 3.0454
2021-05-21 22:03:01 - Epoch: 27, Step: 270/502, Avg Loss: 4.7007, Avg Regression Loss 1.8264, Avg Classification Loss: 2.8743
2021-05-21 22:03:06 - Epoch: 27, Step: 280/502, Avg Loss: 4.8095, Avg Regression Loss 1.7706, Avg Classification Loss: 3.0389
2021-05-21 22:03:11 - Epoch: 27, Step: 290/502, Avg Loss: 4.9975, Avg Regression Loss 1.9712, Avg Classification Loss: 3.0262
2021-05-21 22:03:16 - Epoch: 27, Step: 300/502, Avg Loss: 4.7852, Avg Regression Loss 1.6909, Avg Classification Loss: 3.0943
2021-05-21 22:03:21 - Epoch: 27, Step: 310/502, Avg Loss: 4.2815, Avg Regression Loss 1.3402, Avg Classification Loss: 2.9413
2021-05-21 22:03:26 - Epoch: 27, Step: 320/502, Avg Loss: 4.8017, Avg Regression Loss 1.5992, Avg Classification Loss: 3.2025
2021-05-21 22:03:32 - Epoch: 27, Step: 330/502, Avg Loss: 4.4571, Avg Regression Loss 1.3315, Avg Classification Loss: 3.1256
2021-05-21 22:03:37 - Epoch: 27, Step: 340/502, Avg Loss: 4.0750, Avg Regression Loss 1.0942, Avg Classification Loss: 2.9808
2021-05-21 22:03:42 - Epoch: 27, Step: 350/502, Avg Loss: 4.4676, Avg Regression Loss 1.5398, Avg Classification Loss: 2.9278
2021-05-21 22:03:48 - Epoch: 27, Step: 360/502, Avg Loss: 4.4126, Avg Regression Loss 1.5598, Avg Classification Loss: 2.8529
2021-05-21 22:03:53 - Epoch: 27, Step: 370/502, Avg Loss: 4.3307, Avg Regression Loss 1.4358, Avg Classification Loss: 2.8950
2021-05-21 22:03:58 - Epoch: 27, Step: 380/502, Avg Loss: 4.0014, Avg Regression Loss 1.0742, Avg Classification Loss: 2.9272
2021-05-21 22:04:04 - Epoch: 27, Step: 390/502, Avg Loss: 4.7415, Avg Regression Loss 1.5721, Avg Classification Loss: 3.1693
2021-05-21 22:04:09 - Epoch: 27, Step: 400/502, Avg Loss: 3.8783, Avg Regression Loss 0.9255, Avg Classification Loss: 2.9529
2021-05-21 22:04:14 - Epoch: 27, Step: 410/502, Avg Loss: 4.3745, Avg Regression Loss 1.1265, Avg Classification Loss: 3.2480
2021-05-21 22:04:18 - Epoch: 27, Step: 420/502, Avg Loss: 4.3321, Avg Regression Loss 1.2524, Avg Classification Loss: 3.0797
2021-05-21 22:04:24 - Epoch: 27, Step: 430/502, Avg Loss: 4.3957, Avg Regression Loss 1.5096, Avg Classification Loss: 2.8861
2021-05-21 22:04:30 - Epoch: 27, Step: 440/502, Avg Loss: 4.6302, Avg Regression Loss 1.5904, Avg Classification Loss: 3.0398
2021-05-21 22:04:34 - Epoch: 27, Step: 450/502, Avg Loss: 4.3029, Avg Regression Loss 1.4455, Avg Classification Loss: 2.8574
2021-05-21 22:04:40 - Epoch: 27, Step: 460/502, Avg Loss: 4.4620, Avg Regression Loss 1.4129, Avg Classification Loss: 3.0491
2021-05-21 22:04:45 - Epoch: 27, Step: 470/502, Avg Loss: 3.9773, Avg Regression Loss 1.3553, Avg Classification Loss: 2.6220
2021-05-21 22:04:50 - Epoch: 27, Step: 480/502, Avg Loss: 5.3127, Avg Regression Loss 2.1361, Avg Classification Loss: 3.1765
2021-05-21 22:04:55 - Epoch: 27, Step: 490/502, Avg Loss: 4.7943, Avg Regression Loss 1.6888, Avg Classification Loss: 3.1055
2021-05-21 22:04:59 - Epoch: 27, Step: 500/502, Avg Loss: 4.1107, Avg Regression Loss 1.2232, Avg Classification Loss: 2.8874
2021-05-21 22:05:59 - Epoch: 27, Validation Loss: 3.8079, Validation Regression Loss 1.0155, Validation Classification Loss: 2.7923
2021-05-21 22:06:00 - Saved model models/smd/mb1-ssd-Epoch-27-Loss-3.807881443386534.pth
2021-05-21 22:06:06 - Epoch: 28, Step: 10/502, Avg Loss: 5.0166, Avg Regression Loss 1.8391, Avg Classification Loss: 3.1775
2021-05-21 22:06:16 - Epoch: 28, Step: 20/502, Avg Loss: 4.6656, Avg Regression Loss 1.7120, Avg Classification Loss: 2.9536
2021-05-21 22:06:21 - Epoch: 28, Step: 30/502, Avg Loss: 4.7184, Avg Regression Loss 1.5393, Avg Classification Loss: 3.1791
2021-05-21 22:06:26 - Epoch: 28, Step: 40/502, Avg Loss: 4.2878, Avg Regression Loss 1.2950, Avg Classification Loss: 2.9928
2021-05-21 22:06:31 - Epoch: 28, Step: 50/502, Avg Loss: 4.1090, Avg Regression Loss 1.1678, Avg Classification Loss: 2.9411
2021-05-21 22:06:36 - Epoch: 28, Step: 60/502, Avg Loss: 4.5564, Avg Regression Loss 1.7243, Avg Classification Loss: 2.8321
2021-05-21 22:06:40 - Epoch: 28, Step: 70/502, Avg Loss: 5.3730, Avg Regression Loss 1.6217, Avg Classification Loss: 3.7513
2021-05-21 22:06:48 - Epoch: 28, Step: 80/502, Avg Loss: 5.2144, Avg Regression Loss 1.8075, Avg Classification Loss: 3.4069
2021-05-21 22:06:53 - Epoch: 28, Step: 90/502, Avg Loss: 5.8641, Avg Regression Loss 2.1851, Avg Classification Loss: 3.6791
2021-05-21 22:07:07 - Epoch: 28, Step: 100/502, Avg Loss: 5.9911, Avg Regression Loss 2.8043, Avg Classification Loss: 3.1868
2021-05-21 22:07:11 - Epoch: 28, Step: 110/502, Avg Loss: 5.5144, Avg Regression Loss 2.1126, Avg Classification Loss: 3.4019
2021-05-21 22:07:16 - Epoch: 28, Step: 120/502, Avg Loss: 6.0679, Avg Regression Loss 2.6851, Avg Classification Loss: 3.3829
2021-05-21 22:07:20 - Epoch: 28, Step: 130/502, Avg Loss: 5.7233, Avg Regression Loss 2.2905, Avg Classification Loss: 3.4328
2021-05-21 22:07:26 - Epoch: 28, Step: 140/502, Avg Loss: 5.7000, Avg Regression Loss 2.1280, Avg Classification Loss: 3.5719
2021-05-21 22:07:31 - Epoch: 28, Step: 150/502, Avg Loss: 5.3395, Avg Regression Loss 2.2448, Avg Classification Loss: 3.0947
2021-05-21 22:07:35 - Epoch: 28, Step: 160/502, Avg Loss: 5.5886, Avg Regression Loss 2.2799, Avg Classification Loss: 3.3087
2021-05-21 22:07:40 - Epoch: 28, Step: 170/502, Avg Loss: 4.8747, Avg Regression Loss 1.7659, Avg Classification Loss: 3.1089
2021-05-21 22:07:45 - Epoch: 28, Step: 180/502, Avg Loss: 4.9189, Avg Regression Loss 1.5485, Avg Classification Loss: 3.3704
2021-05-21 22:07:50 - Epoch: 28, Step: 190/502, Avg Loss: 5.2066, Avg Regression Loss 1.9991, Avg Classification Loss: 3.2075
2021-05-21 22:07:55 - Epoch: 28, Step: 200/502, Avg Loss: 5.2680, Avg Regression Loss 1.9516, Avg Classification Loss: 3.3164
2021-05-21 22:08:00 - Epoch: 28, Step: 210/502, Avg Loss: 5.9262, Avg Regression Loss 2.7243, Avg Classification Loss: 3.2019
2021-05-21 22:08:07 - Epoch: 28, Step: 220/502, Avg Loss: 5.1136, Avg Regression Loss 1.6975, Avg Classification Loss: 3.4161
2021-05-21 22:08:12 - Epoch: 28, Step: 230/502, Avg Loss: 5.3048, Avg Regression Loss 2.0385, Avg Classification Loss: 3.2663
2021-05-21 22:08:17 - Epoch: 28, Step: 240/502, Avg Loss: 4.9325, Avg Regression Loss 1.7042, Avg Classification Loss: 3.2283
2021-05-21 22:08:21 - Epoch: 28, Step: 250/502, Avg Loss: 5.8315, Avg Regression Loss 2.2816, Avg Classification Loss: 3.5499
2021-05-21 22:08:26 - Epoch: 28, Step: 260/502, Avg Loss: 4.8832, Avg Regression Loss 1.7294, Avg Classification Loss: 3.1537
2021-05-21 22:08:31 - Epoch: 28, Step: 270/502, Avg Loss: 4.9424, Avg Regression Loss 1.8022, Avg Classification Loss: 3.1402
2021-05-21 22:08:36 - Epoch: 28, Step: 280/502, Avg Loss: 5.0368, Avg Regression Loss 1.6965, Avg Classification Loss: 3.3403
2021-05-21 22:08:44 - Epoch: 28, Step: 290/502, Avg Loss: 5.3131, Avg Regression Loss 1.9176, Avg Classification Loss: 3.3954
2021-05-21 22:08:49 - Epoch: 28, Step: 300/502, Avg Loss: 5.5794, Avg Regression Loss 2.2705, Avg Classification Loss: 3.3090
2021-05-21 22:08:54 - Epoch: 28, Step: 310/502, Avg Loss: 4.6135, Avg Regression Loss 1.5198, Avg Classification Loss: 3.0937
2021-05-21 22:08:59 - Epoch: 28, Step: 320/502, Avg Loss: 4.8059, Avg Regression Loss 1.6573, Avg Classification Loss: 3.1487
2021-05-21 22:09:04 - Epoch: 28, Step: 330/502, Avg Loss: 4.6510, Avg Regression Loss 1.4085, Avg Classification Loss: 3.2426
2021-05-21 22:09:09 - Epoch: 28, Step: 340/502, Avg Loss: 4.8629, Avg Regression Loss 1.8011, Avg Classification Loss: 3.0618
2021-05-21 22:09:14 - Epoch: 28, Step: 350/502, Avg Loss: 4.3692, Avg Regression Loss 1.2896, Avg Classification Loss: 3.0796
2021-05-21 22:09:21 - Epoch: 28, Step: 360/502, Avg Loss: 5.0806, Avg Regression Loss 1.8974, Avg Classification Loss: 3.1832
2021-05-21 22:09:26 - Epoch: 28, Step: 370/502, Avg Loss: 4.7783, Avg Regression Loss 1.5661, Avg Classification Loss: 3.2122
2021-05-21 22:09:30 - Epoch: 28, Step: 380/502, Avg Loss: 5.0839, Avg Regression Loss 1.9961, Avg Classification Loss: 3.0878
2021-05-21 22:09:35 - Epoch: 28, Step: 390/502, Avg Loss: 4.1712, Avg Regression Loss 1.3241, Avg Classification Loss: 2.8471
2021-05-21 22:09:40 - Epoch: 28, Step: 400/502, Avg Loss: 5.2326, Avg Regression Loss 2.1461, Avg Classification Loss: 3.0865
2021-05-21 22:09:44 - Epoch: 28, Step: 410/502, Avg Loss: 4.6645, Avg Regression Loss 1.3536, Avg Classification Loss: 3.3110
2021-05-21 22:09:49 - Epoch: 28, Step: 420/502, Avg Loss: 4.2291, Avg Regression Loss 1.2645, Avg Classification Loss: 2.9646
2021-05-21 22:09:54 - Epoch: 28, Step: 430/502, Avg Loss: 4.3787, Avg Regression Loss 1.3338, Avg Classification Loss: 3.0449
2021-05-21 22:09:58 - Epoch: 28, Step: 440/502, Avg Loss: 4.3631, Avg Regression Loss 1.3426, Avg Classification Loss: 3.0205
2021-05-21 22:10:03 - Epoch: 28, Step: 450/502, Avg Loss: 4.9332, Avg Regression Loss 1.8682, Avg Classification Loss: 3.0650
2021-05-21 22:10:09 - Epoch: 28, Step: 460/502, Avg Loss: 4.6847, Avg Regression Loss 1.5212, Avg Classification Loss: 3.1635
2021-05-21 22:10:14 - Epoch: 28, Step: 470/502, Avg Loss: 5.7918, Avg Regression Loss 2.6656, Avg Classification Loss: 3.1262
2021-05-21 22:10:18 - Epoch: 28, Step: 480/502, Avg Loss: 4.7881, Avg Regression Loss 1.6019, Avg Classification Loss: 3.1863
2021-05-21 22:10:23 - Epoch: 28, Step: 490/502, Avg Loss: 6.2922, Avg Regression Loss 3.0842, Avg Classification Loss: 3.2079
2021-05-21 22:10:28 - Epoch: 28, Step: 500/502, Avg Loss: 5.7922, Avg Regression Loss 2.3546, Avg Classification Loss: 3.4376
2021-05-21 22:11:29 - Epoch: 28, Validation Loss: 4.0087, Validation Regression Loss 1.0905, Validation Classification Loss: 2.9182
2021-05-21 22:11:29 - Saved model models/smd/mb1-ssd-Epoch-28-Loss-4.008681194240828.pth
2021-05-21 22:11:37 - Epoch: 29, Step: 10/502, Avg Loss: 6.0060, Avg Regression Loss 2.4873, Avg Classification Loss: 3.5187
2021-05-21 22:11:42 - Epoch: 29, Step: 20/502, Avg Loss: 4.9638, Avg Regression Loss 1.7890, Avg Classification Loss: 3.1748
2021-05-21 22:11:46 - Epoch: 29, Step: 30/502, Avg Loss: 5.1824, Avg Regression Loss 1.9102, Avg Classification Loss: 3.2722
2021-05-21 22:11:53 - Epoch: 29, Step: 40/502, Avg Loss: 5.6187, Avg Regression Loss 2.3970, Avg Classification Loss: 3.2216
2021-05-21 22:11:58 - Epoch: 29, Step: 50/502, Avg Loss: 4.3347, Avg Regression Loss 1.4737, Avg Classification Loss: 2.8610
2021-05-21 22:12:03 - Epoch: 29, Step: 60/502, Avg Loss: 5.3905, Avg Regression Loss 2.1406, Avg Classification Loss: 3.2500
2021-05-21 22:12:08 - Epoch: 29, Step: 70/502, Avg Loss: 4.4785, Avg Regression Loss 1.4177, Avg Classification Loss: 3.0608
2021-05-21 22:12:12 - Epoch: 29, Step: 80/502, Avg Loss: 4.2353, Avg Regression Loss 1.4074, Avg Classification Loss: 2.8279
2021-05-21 22:12:17 - Epoch: 29, Step: 90/502, Avg Loss: 4.8587, Avg Regression Loss 1.8331, Avg Classification Loss: 3.0256
2021-05-21 22:12:33 - Epoch: 29, Step: 100/502, Avg Loss: 4.4993, Avg Regression Loss 1.3856, Avg Classification Loss: 3.1137
2021-05-21 22:12:38 - Epoch: 29, Step: 110/502, Avg Loss: 4.1317, Avg Regression Loss 1.3002, Avg Classification Loss: 2.8315
2021-05-21 22:12:43 - Epoch: 29, Step: 120/502, Avg Loss: 4.3723, Avg Regression Loss 1.2748, Avg Classification Loss: 3.0975
2021-05-21 22:12:47 - Epoch: 29, Step: 130/502, Avg Loss: 4.7499, Avg Regression Loss 1.5760, Avg Classification Loss: 3.1739
2021-05-21 22:12:52 - Epoch: 29, Step: 140/502, Avg Loss: 5.3601, Avg Regression Loss 2.1231, Avg Classification Loss: 3.2370
2021-05-21 22:12:57 - Epoch: 29, Step: 150/502, Avg Loss: 4.3328, Avg Regression Loss 1.5075, Avg Classification Loss: 2.8253
2021-05-21 22:13:04 - Epoch: 29, Step: 160/502, Avg Loss: 5.0938, Avg Regression Loss 1.8386, Avg Classification Loss: 3.2552
2021-05-21 22:13:09 - Epoch: 29, Step: 170/502, Avg Loss: 4.9772, Avg Regression Loss 1.6677, Avg Classification Loss: 3.3094
2021-05-21 22:13:13 - Epoch: 29, Step: 180/502, Avg Loss: 4.9745, Avg Regression Loss 1.7267, Avg Classification Loss: 3.2478
2021-05-21 22:13:18 - Epoch: 29, Step: 190/502, Avg Loss: 4.5562, Avg Regression Loss 1.5284, Avg Classification Loss: 3.0278
2021-05-21 22:13:28 - Epoch: 29, Step: 200/502, Avg Loss: 5.7356, Avg Regression Loss 2.5717, Avg Classification Loss: 3.1639
2021-05-21 22:13:33 - Epoch: 29, Step: 210/502, Avg Loss: 4.4675, Avg Regression Loss 1.5716, Avg Classification Loss: 2.8959
2021-05-21 22:13:38 - Epoch: 29, Step: 220/502, Avg Loss: 4.7401, Avg Regression Loss 1.7791, Avg Classification Loss: 2.9610
2021-05-21 22:13:43 - Epoch: 29, Step: 230/502, Avg Loss: 4.7285, Avg Regression Loss 1.8014, Avg Classification Loss: 2.9271
2021-05-21 22:13:48 - Epoch: 29, Step: 240/502, Avg Loss: 5.5823, Avg Regression Loss 2.1585, Avg Classification Loss: 3.4238
2021-05-21 22:13:53 - Epoch: 29, Step: 250/502, Avg Loss: 5.2816, Avg Regression Loss 1.9929, Avg Classification Loss: 3.2888
2021-05-21 22:13:58 - Epoch: 29, Step: 260/502, Avg Loss: 5.4267, Avg Regression Loss 2.1444, Avg Classification Loss: 3.2822
2021-05-21 22:14:02 - Epoch: 29, Step: 270/502, Avg Loss: 4.2183, Avg Regression Loss 1.2736, Avg Classification Loss: 2.9448
2021-05-21 22:14:07 - Epoch: 29, Step: 280/502, Avg Loss: 3.9758, Avg Regression Loss 1.1512, Avg Classification Loss: 2.8246
2021-05-21 22:14:12 - Epoch: 29, Step: 290/502, Avg Loss: 4.5745, Avg Regression Loss 1.5564, Avg Classification Loss: 3.0181
2021-05-21 22:14:17 - Epoch: 29, Step: 300/502, Avg Loss: 4.0019, Avg Regression Loss 1.0357, Avg Classification Loss: 2.9663
2021-05-21 22:14:22 - Epoch: 29, Step: 310/502, Avg Loss: 4.7731, Avg Regression Loss 1.7349, Avg Classification Loss: 3.0382
2021-05-21 22:14:26 - Epoch: 29, Step: 320/502, Avg Loss: 4.5238, Avg Regression Loss 1.5535, Avg Classification Loss: 2.9703
2021-05-21 22:14:31 - Epoch: 29, Step: 330/502, Avg Loss: 4.8569, Avg Regression Loss 1.9114, Avg Classification Loss: 2.9455
2021-05-21 22:14:36 - Epoch: 29, Step: 340/502, Avg Loss: 3.9436, Avg Regression Loss 1.1342, Avg Classification Loss: 2.8094
2021-05-21 22:14:42 - Epoch: 29, Step: 350/502, Avg Loss: 4.9825, Avg Regression Loss 1.8263, Avg Classification Loss: 3.1562
2021-05-21 22:14:46 - Epoch: 29, Step: 360/502, Avg Loss: 4.8599, Avg Regression Loss 1.7810, Avg Classification Loss: 3.0789
2021-05-21 22:14:51 - Epoch: 29, Step: 370/502, Avg Loss: 4.2029, Avg Regression Loss 1.3386, Avg Classification Loss: 2.8643
2021-05-21 22:14:58 - Epoch: 29, Step: 380/502, Avg Loss: 5.3734, Avg Regression Loss 2.2332, Avg Classification Loss: 3.1403
2021-05-21 22:15:05 - Epoch: 29, Step: 390/502, Avg Loss: 5.0846, Avg Regression Loss 1.7412, Avg Classification Loss: 3.3434
2021-05-21 22:15:10 - Epoch: 29, Step: 400/502, Avg Loss: 5.0594, Avg Regression Loss 1.9115, Avg Classification Loss: 3.1479
2021-05-21 22:15:15 - Epoch: 29, Step: 410/502, Avg Loss: 4.2916, Avg Regression Loss 1.3329, Avg Classification Loss: 2.9587
2021-05-21 22:15:20 - Epoch: 29, Step: 420/502, Avg Loss: 4.5644, Avg Regression Loss 1.4891, Avg Classification Loss: 3.0753
2021-05-21 22:15:26 - Epoch: 29, Step: 430/502, Avg Loss: 5.4004, Avg Regression Loss 2.1625, Avg Classification Loss: 3.2378
2021-05-21 22:15:31 - Epoch: 29, Step: 440/502, Avg Loss: 3.7794, Avg Regression Loss 0.9288, Avg Classification Loss: 2.8505
2021-05-21 22:15:36 - Epoch: 29, Step: 450/502, Avg Loss: 4.5804, Avg Regression Loss 1.8753, Avg Classification Loss: 2.7050
2021-05-21 22:15:41 - Epoch: 29, Step: 460/502, Avg Loss: 4.9737, Avg Regression Loss 1.8054, Avg Classification Loss: 3.1684
2021-05-21 22:15:56 - Epoch: 29, Step: 470/502, Avg Loss: 4.6665, Avg Regression Loss 1.6322, Avg Classification Loss: 3.0343
2021-05-21 22:16:00 - Epoch: 29, Step: 480/502, Avg Loss: 4.8834, Avg Regression Loss 1.8028, Avg Classification Loss: 3.0806
2021-05-21 22:16:05 - Epoch: 29, Step: 490/502, Avg Loss: 4.8157, Avg Regression Loss 1.7293, Avg Classification Loss: 3.0864
2021-05-21 22:16:11 - Epoch: 29, Step: 500/502, Avg Loss: 4.7945, Avg Regression Loss 1.4807, Avg Classification Loss: 3.3138
2021-05-21 22:17:11 - Epoch: 29, Validation Loss: 3.7586, Validation Regression Loss 0.9866, Validation Classification Loss: 2.7720
2021-05-21 22:17:11 - Saved model models/smd/mb1-ssd-Epoch-29-Loss-3.7585835190883197.pth
2021-05-21 22:17:17 - Epoch: 30, Step: 10/502, Avg Loss: 4.9566, Avg Regression Loss 1.7175, Avg Classification Loss: 3.2391
2021-05-21 22:17:23 - Epoch: 30, Step: 20/502, Avg Loss: 4.5659, Avg Regression Loss 1.5609, Avg Classification Loss: 3.0050
2021-05-21 22:17:29 - Epoch: 30, Step: 30/502, Avg Loss: 4.7671, Avg Regression Loss 1.7278, Avg Classification Loss: 3.0393
2021-05-21 22:17:34 - Epoch: 30, Step: 40/502, Avg Loss: 4.0063, Avg Regression Loss 1.1917, Avg Classification Loss: 2.8145
2021-05-21 22:17:38 - Epoch: 30, Step: 50/502, Avg Loss: 4.1348, Avg Regression Loss 1.1425, Avg Classification Loss: 2.9923
2021-05-21 22:17:43 - Epoch: 30, Step: 60/502, Avg Loss: 4.9963, Avg Regression Loss 1.7418, Avg Classification Loss: 3.2545
2021-05-21 22:17:49 - Epoch: 30, Step: 70/502, Avg Loss: 4.7433, Avg Regression Loss 1.5000, Avg Classification Loss: 3.2433
2021-05-21 22:17:54 - Epoch: 30, Step: 80/502, Avg Loss: 4.4607, Avg Regression Loss 1.5386, Avg Classification Loss: 2.9221
2021-05-21 22:17:59 - Epoch: 30, Step: 90/502, Avg Loss: 4.8129, Avg Regression Loss 1.7525, Avg Classification Loss: 3.0603
2021-05-21 22:18:04 - Epoch: 30, Step: 100/502, Avg Loss: 4.6266, Avg Regression Loss 1.7207, Avg Classification Loss: 2.9059
2021-05-21 22:18:10 - Epoch: 30, Step: 110/502, Avg Loss: 5.4892, Avg Regression Loss 2.2966, Avg Classification Loss: 3.1926
2021-05-21 22:18:15 - Epoch: 30, Step: 120/502, Avg Loss: 5.1982, Avg Regression Loss 1.8444, Avg Classification Loss: 3.3538
2021-05-21 22:18:21 - Epoch: 30, Step: 130/502, Avg Loss: 5.1159, Avg Regression Loss 1.9395, Avg Classification Loss: 3.1764
2021-05-21 22:18:25 - Epoch: 30, Step: 140/502, Avg Loss: 4.9737, Avg Regression Loss 1.6539, Avg Classification Loss: 3.3197
2021-05-21 22:18:30 - Epoch: 30, Step: 150/502, Avg Loss: 4.4470, Avg Regression Loss 1.5127, Avg Classification Loss: 2.9343
2021-05-21 22:18:35 - Epoch: 30, Step: 160/502, Avg Loss: 5.1174, Avg Regression Loss 1.6403, Avg Classification Loss: 3.4771
2021-05-21 22:18:40 - Epoch: 30, Step: 170/502, Avg Loss: 4.7080, Avg Regression Loss 1.5523, Avg Classification Loss: 3.1556
2021-05-21 22:18:44 - Epoch: 30, Step: 180/502, Avg Loss: 4.6771, Avg Regression Loss 1.6621, Avg Classification Loss: 3.0150
2021-05-21 22:18:49 - Epoch: 30, Step: 190/502, Avg Loss: 4.6402, Avg Regression Loss 1.6065, Avg Classification Loss: 3.0337
2021-05-21 22:18:54 - Epoch: 30, Step: 200/502, Avg Loss: 4.7097, Avg Regression Loss 1.8228, Avg Classification Loss: 2.8869
2021-05-21 22:18:58 - Epoch: 30, Step: 210/502, Avg Loss: 4.4902, Avg Regression Loss 1.6687, Avg Classification Loss: 2.8215
2021-05-21 22:19:03 - Epoch: 30, Step: 220/502, Avg Loss: 4.2212, Avg Regression Loss 1.2301, Avg Classification Loss: 2.9910
2021-05-21 22:19:08 - Epoch: 30, Step: 230/502, Avg Loss: 4.6516, Avg Regression Loss 1.8330, Avg Classification Loss: 2.8186
2021-05-21 22:19:16 - Epoch: 30, Step: 240/502, Avg Loss: 5.1875, Avg Regression Loss 2.0346, Avg Classification Loss: 3.1529
2021-05-21 22:19:21 - Epoch: 30, Step: 250/502, Avg Loss: 4.9407, Avg Regression Loss 2.1119, Avg Classification Loss: 2.8288
2021-05-21 22:19:30 - Epoch: 30, Step: 260/502, Avg Loss: 4.7421, Avg Regression Loss 1.5338, Avg Classification Loss: 3.2083
2021-05-21 22:19:34 - Epoch: 30, Step: 270/502, Avg Loss: 5.0493, Avg Regression Loss 2.0990, Avg Classification Loss: 2.9503
2021-05-21 22:19:39 - Epoch: 30, Step: 280/502, Avg Loss: 4.3675, Avg Regression Loss 1.5835, Avg Classification Loss: 2.7840
2021-05-21 22:19:44 - Epoch: 30, Step: 290/502, Avg Loss: 4.0723, Avg Regression Loss 1.0323, Avg Classification Loss: 3.0399
2021-05-21 22:19:49 - Epoch: 30, Step: 300/502, Avg Loss: 4.7622, Avg Regression Loss 1.8564, Avg Classification Loss: 2.9058
2021-05-21 22:19:54 - Epoch: 30, Step: 310/502, Avg Loss: 4.6437, Avg Regression Loss 1.8160, Avg Classification Loss: 2.8277
2021-05-21 22:19:58 - Epoch: 30, Step: 320/502, Avg Loss: 4.6425, Avg Regression Loss 1.6989, Avg Classification Loss: 2.9436
2021-05-21 22:20:04 - Epoch: 30, Step: 330/502, Avg Loss: 5.2382, Avg Regression Loss 1.9706, Avg Classification Loss: 3.2676
2021-05-21 22:20:10 - Epoch: 30, Step: 340/502, Avg Loss: 4.6147, Avg Regression Loss 1.4340, Avg Classification Loss: 3.1807
2021-05-21 22:20:15 - Epoch: 30, Step: 350/502, Avg Loss: 4.3680, Avg Regression Loss 1.5098, Avg Classification Loss: 2.8583
2021-05-21 22:20:28 - Epoch: 30, Step: 360/502, Avg Loss: 4.8518, Avg Regression Loss 1.6497, Avg Classification Loss: 3.2021
2021-05-21 22:20:32 - Epoch: 30, Step: 370/502, Avg Loss: 4.5329, Avg Regression Loss 1.5905, Avg Classification Loss: 2.9423
2021-05-21 22:20:37 - Epoch: 30, Step: 380/502, Avg Loss: 3.6253, Avg Regression Loss 0.9573, Avg Classification Loss: 2.6680
2021-05-21 22:20:42 - Epoch: 30, Step: 390/502, Avg Loss: 4.7497, Avg Regression Loss 1.8189, Avg Classification Loss: 2.9307
2021-05-21 22:20:47 - Epoch: 30, Step: 400/502, Avg Loss: 3.9263, Avg Regression Loss 1.1292, Avg Classification Loss: 2.7971
2021-05-21 22:20:52 - Epoch: 30, Step: 410/502, Avg Loss: 4.4586, Avg Regression Loss 1.1306, Avg Classification Loss: 3.3280
2021-05-21 22:20:57 - Epoch: 30, Step: 420/502, Avg Loss: 4.9549, Avg Regression Loss 2.0664, Avg Classification Loss: 2.8885
2021-05-21 22:21:02 - Epoch: 30, Step: 430/502, Avg Loss: 5.0019, Avg Regression Loss 1.7005, Avg Classification Loss: 3.3014
2021-05-21 22:21:07 - Epoch: 30, Step: 440/502, Avg Loss: 4.3847, Avg Regression Loss 1.3662, Avg Classification Loss: 3.0185
2021-05-21 22:21:12 - Epoch: 30, Step: 450/502, Avg Loss: 4.3624, Avg Regression Loss 1.2866, Avg Classification Loss: 3.0759
2021-05-21 22:21:17 - Epoch: 30, Step: 460/502, Avg Loss: 4.7064, Avg Regression Loss 1.5384, Avg Classification Loss: 3.1680
2021-05-21 22:21:21 - Epoch: 30, Step: 470/502, Avg Loss: 4.1512, Avg Regression Loss 1.3048, Avg Classification Loss: 2.8463
2021-05-21 22:21:26 - Epoch: 30, Step: 480/502, Avg Loss: 4.2174, Avg Regression Loss 1.1631, Avg Classification Loss: 3.0544
2021-05-21 22:21:31 - Epoch: 30, Step: 490/502, Avg Loss: 4.3663, Avg Regression Loss 1.4269, Avg Classification Loss: 2.9395
2021-05-21 22:21:35 - Epoch: 30, Step: 500/502, Avg Loss: 4.0467, Avg Regression Loss 1.2246, Avg Classification Loss: 2.8222
2021-05-21 22:22:35 - Epoch: 30, Validation Loss: 3.6494, Validation Regression Loss 0.9428, Validation Classification Loss: 2.7066
2021-05-21 22:22:35 - Saved model models/smd/mb1-ssd-Epoch-30-Loss-3.649414563321497.pth
2021-05-21 22:22:42 - Epoch: 31, Step: 10/502, Avg Loss: 4.6364, Avg Regression Loss 1.4560, Avg Classification Loss: 3.1804
2021-05-21 22:22:47 - Epoch: 31, Step: 20/502, Avg Loss: 4.3938, Avg Regression Loss 1.3144, Avg Classification Loss: 3.0793
2021-05-21 22:22:52 - Epoch: 31, Step: 30/502, Avg Loss: 4.4090, Avg Regression Loss 1.3322, Avg Classification Loss: 3.0768
2021-05-21 22:22:57 - Epoch: 31, Step: 40/502, Avg Loss: 4.1596, Avg Regression Loss 1.1211, Avg Classification Loss: 3.0385
2021-05-21 22:23:01 - Epoch: 31, Step: 50/502, Avg Loss: 3.8499, Avg Regression Loss 1.0342, Avg Classification Loss: 2.8157
2021-05-21 22:23:06 - Epoch: 31, Step: 60/502, Avg Loss: 4.2069, Avg Regression Loss 1.2637, Avg Classification Loss: 2.9432
2021-05-21 22:23:11 - Epoch: 31, Step: 70/502, Avg Loss: 4.3046, Avg Regression Loss 1.4641, Avg Classification Loss: 2.8404
2021-05-21 22:23:15 - Epoch: 31, Step: 80/502, Avg Loss: 4.4006, Avg Regression Loss 1.5254, Avg Classification Loss: 2.8752
2021-05-21 22:23:21 - Epoch: 31, Step: 90/502, Avg Loss: 4.3681, Avg Regression Loss 1.2632, Avg Classification Loss: 3.1050
2021-05-21 22:23:26 - Epoch: 31, Step: 100/502, Avg Loss: 4.1202, Avg Regression Loss 1.3251, Avg Classification Loss: 2.7952
2021-05-21 22:23:31 - Epoch: 31, Step: 110/502, Avg Loss: 3.5913, Avg Regression Loss 0.9123, Avg Classification Loss: 2.6790
2021-05-21 22:23:37 - Epoch: 31, Step: 120/502, Avg Loss: 4.5881, Avg Regression Loss 1.7940, Avg Classification Loss: 2.7941
2021-05-21 22:23:42 - Epoch: 31, Step: 130/502, Avg Loss: 4.5170, Avg Regression Loss 1.3499, Avg Classification Loss: 3.1671
2021-05-21 22:23:47 - Epoch: 31, Step: 140/502, Avg Loss: 4.0878, Avg Regression Loss 1.1532, Avg Classification Loss: 2.9346
2021-05-21 22:23:52 - Epoch: 31, Step: 150/502, Avg Loss: 4.6015, Avg Regression Loss 1.5320, Avg Classification Loss: 3.0695
2021-05-21 22:23:56 - Epoch: 31, Step: 160/502, Avg Loss: 4.1303, Avg Regression Loss 1.3228, Avg Classification Loss: 2.8076
2021-05-21 22:24:02 - Epoch: 31, Step: 170/502, Avg Loss: 5.3722, Avg Regression Loss 2.1585, Avg Classification Loss: 3.2137
2021-05-21 22:24:07 - Epoch: 31, Step: 180/502, Avg Loss: 4.9035, Avg Regression Loss 1.6833, Avg Classification Loss: 3.2202
2021-05-21 22:24:11 - Epoch: 31, Step: 190/502, Avg Loss: 4.0040, Avg Regression Loss 1.2497, Avg Classification Loss: 2.7544
2021-05-21 22:24:28 - Epoch: 31, Step: 200/502, Avg Loss: 4.4572, Avg Regression Loss 1.3634, Avg Classification Loss: 3.0938
2021-05-21 22:24:33 - Epoch: 31, Step: 210/502, Avg Loss: 4.0206, Avg Regression Loss 1.1053, Avg Classification Loss: 2.9153
2021-05-21 22:24:38 - Epoch: 31, Step: 220/502, Avg Loss: 4.3738, Avg Regression Loss 1.5454, Avg Classification Loss: 2.8284
2021-05-21 22:24:43 - Epoch: 31, Step: 230/502, Avg Loss: 4.1782, Avg Regression Loss 1.2560, Avg Classification Loss: 2.9222
2021-05-21 22:24:48 - Epoch: 31, Step: 240/502, Avg Loss: 5.1244, Avg Regression Loss 2.0758, Avg Classification Loss: 3.0486
2021-05-21 22:24:53 - Epoch: 31, Step: 250/502, Avg Loss: 4.5637, Avg Regression Loss 1.6952, Avg Classification Loss: 2.8685
2021-05-21 22:24:58 - Epoch: 31, Step: 260/502, Avg Loss: 4.2395, Avg Regression Loss 1.4721, Avg Classification Loss: 2.7674
2021-05-21 22:25:03 - Epoch: 31, Step: 270/502, Avg Loss: 4.7242, Avg Regression Loss 1.6340, Avg Classification Loss: 3.0902
2021-05-21 22:25:08 - Epoch: 31, Step: 280/502, Avg Loss: 4.4976, Avg Regression Loss 1.5509, Avg Classification Loss: 2.9466
2021-05-21 22:25:15 - Epoch: 31, Step: 290/502, Avg Loss: 4.4209, Avg Regression Loss 1.3931, Avg Classification Loss: 3.0278
2021-05-21 22:25:19 - Epoch: 31, Step: 300/502, Avg Loss: 4.2617, Avg Regression Loss 1.3580, Avg Classification Loss: 2.9037
2021-05-21 22:25:25 - Epoch: 31, Step: 310/502, Avg Loss: 4.4676, Avg Regression Loss 1.5843, Avg Classification Loss: 2.8833
2021-05-21 22:25:30 - Epoch: 31, Step: 320/502, Avg Loss: 4.5243, Avg Regression Loss 1.5550, Avg Classification Loss: 2.9694
2021-05-21 22:25:34 - Epoch: 31, Step: 330/502, Avg Loss: 4.2407, Avg Regression Loss 1.1186, Avg Classification Loss: 3.1222
2021-05-21 22:25:41 - Epoch: 31, Step: 340/502, Avg Loss: 4.2540, Avg Regression Loss 1.2997, Avg Classification Loss: 2.9543
2021-05-21 22:25:46 - Epoch: 31, Step: 350/502, Avg Loss: 4.9094, Avg Regression Loss 1.7556, Avg Classification Loss: 3.1538
2021-05-21 22:25:52 - Epoch: 31, Step: 360/502, Avg Loss: 4.3332, Avg Regression Loss 1.3700, Avg Classification Loss: 2.9633
2021-05-21 22:25:57 - Epoch: 31, Step: 370/502, Avg Loss: 3.5315, Avg Regression Loss 0.9331, Avg Classification Loss: 2.5984
2021-05-21 22:26:01 - Epoch: 31, Step: 380/502, Avg Loss: 4.4498, Avg Regression Loss 1.5495, Avg Classification Loss: 2.9003
2021-05-21 22:26:06 - Epoch: 31, Step: 390/502, Avg Loss: 4.0470, Avg Regression Loss 1.1222, Avg Classification Loss: 2.9248
2021-05-21 22:26:11 - Epoch: 31, Step: 400/502, Avg Loss: 4.6832, Avg Regression Loss 1.7130, Avg Classification Loss: 2.9702
2021-05-21 22:26:16 - Epoch: 31, Step: 410/502, Avg Loss: 3.6369, Avg Regression Loss 0.8941, Avg Classification Loss: 2.7428
2021-05-21 22:26:20 - Epoch: 31, Step: 420/502, Avg Loss: 4.8804, Avg Regression Loss 1.7086, Avg Classification Loss: 3.1718
2021-05-21 22:26:26 - Epoch: 31, Step: 430/502, Avg Loss: 4.4932, Avg Regression Loss 1.6510, Avg Classification Loss: 2.8422
2021-05-21 22:26:31 - Epoch: 31, Step: 440/502, Avg Loss: 4.5134, Avg Regression Loss 1.7242, Avg Classification Loss: 2.7891
2021-05-21 22:26:36 - Epoch: 31, Step: 450/502, Avg Loss: 4.1432, Avg Regression Loss 1.2882, Avg Classification Loss: 2.8550
2021-05-21 22:26:42 - Epoch: 31, Step: 460/502, Avg Loss: 5.2858, Avg Regression Loss 2.2746, Avg Classification Loss: 3.0112
2021-05-21 22:26:47 - Epoch: 31, Step: 470/502, Avg Loss: 4.4356, Avg Regression Loss 1.7081, Avg Classification Loss: 2.7274
2021-05-21 22:26:52 - Epoch: 31, Step: 480/502, Avg Loss: 4.5918, Avg Regression Loss 1.7138, Avg Classification Loss: 2.8780
2021-05-21 22:27:11 - Epoch: 31, Step: 490/502, Avg Loss: 4.7676, Avg Regression Loss 1.7865, Avg Classification Loss: 2.9812
2021-05-21 22:27:17 - Epoch: 31, Step: 500/502, Avg Loss: 4.9003, Avg Regression Loss 1.6935, Avg Classification Loss: 3.2068
2021-05-21 22:28:18 - Epoch: 31, Validation Loss: 3.5844, Validation Regression Loss 0.9115, Validation Classification Loss: 2.6729
2021-05-21 22:28:19 - Saved model models/smd/mb1-ssd-Epoch-31-Loss-3.584392716210202.pth
2021-05-21 22:28:25 - Epoch: 32, Step: 10/502, Avg Loss: 4.7010, Avg Regression Loss 1.7199, Avg Classification Loss: 2.9812
2021-05-21 22:28:34 - Epoch: 32, Step: 20/502, Avg Loss: 5.1191, Avg Regression Loss 1.9347, Avg Classification Loss: 3.1844
2021-05-21 22:28:39 - Epoch: 32, Step: 30/502, Avg Loss: 4.1930, Avg Regression Loss 1.2221, Avg Classification Loss: 2.9709
2021-05-21 22:28:44 - Epoch: 32, Step: 40/502, Avg Loss: 4.2296, Avg Regression Loss 1.3297, Avg Classification Loss: 2.8999
2021-05-21 22:28:48 - Epoch: 32, Step: 50/502, Avg Loss: 4.1336, Avg Regression Loss 1.2620, Avg Classification Loss: 2.8716
2021-05-21 22:28:53 - Epoch: 32, Step: 60/502, Avg Loss: 3.9548, Avg Regression Loss 1.0649, Avg Classification Loss: 2.8899
2021-05-21 22:28:58 - Epoch: 32, Step: 70/502, Avg Loss: 5.2585, Avg Regression Loss 2.1860, Avg Classification Loss: 3.0726
2021-05-21 22:29:03 - Epoch: 32, Step: 80/502, Avg Loss: 4.0227, Avg Regression Loss 1.2255, Avg Classification Loss: 2.7972
2021-05-21 22:29:08 - Epoch: 32, Step: 90/502, Avg Loss: 4.4596, Avg Regression Loss 1.5410, Avg Classification Loss: 2.9186
2021-05-21 22:29:13 - Epoch: 32, Step: 100/502, Avg Loss: 4.0432, Avg Regression Loss 1.0316, Avg Classification Loss: 3.0115
2021-05-21 22:29:18 - Epoch: 32, Step: 110/502, Avg Loss: 4.1084, Avg Regression Loss 1.2622, Avg Classification Loss: 2.8462
2021-05-21 22:29:22 - Epoch: 32, Step: 120/502, Avg Loss: 4.6194, Avg Regression Loss 1.4424, Avg Classification Loss: 3.1770
2021-05-21 22:29:27 - Epoch: 32, Step: 130/502, Avg Loss: 4.6495, Avg Regression Loss 1.7671, Avg Classification Loss: 2.8824
2021-05-21 22:29:32 - Epoch: 32, Step: 140/502, Avg Loss: 4.1161, Avg Regression Loss 1.1367, Avg Classification Loss: 2.9794
2021-05-21 22:29:37 - Epoch: 32, Step: 150/502, Avg Loss: 4.0963, Avg Regression Loss 1.3751, Avg Classification Loss: 2.7213
2021-05-21 22:29:43 - Epoch: 32, Step: 160/502, Avg Loss: 4.1628, Avg Regression Loss 1.2034, Avg Classification Loss: 2.9594
2021-05-21 22:29:47 - Epoch: 32, Step: 170/502, Avg Loss: 4.5834, Avg Regression Loss 1.3028, Avg Classification Loss: 3.2806
2021-05-21 22:29:52 - Epoch: 32, Step: 180/502, Avg Loss: 4.1688, Avg Regression Loss 1.0074, Avg Classification Loss: 3.1614
2021-05-21 22:29:57 - Epoch: 32, Step: 190/502, Avg Loss: 4.4259, Avg Regression Loss 1.5477, Avg Classification Loss: 2.8782
2021-05-21 22:30:02 - Epoch: 32, Step: 200/502, Avg Loss: 4.3764, Avg Regression Loss 1.5250, Avg Classification Loss: 2.8514
2021-05-21 22:30:07 - Epoch: 32, Step: 210/502, Avg Loss: 4.2371, Avg Regression Loss 1.2616, Avg Classification Loss: 2.9755
2021-05-21 22:30:17 - Epoch: 32, Step: 220/502, Avg Loss: 4.6610, Avg Regression Loss 1.8608, Avg Classification Loss: 2.8003
2021-05-21 22:30:22 - Epoch: 32, Step: 230/502, Avg Loss: 5.1531, Avg Regression Loss 1.9308, Avg Classification Loss: 3.2224
2021-05-21 22:30:33 - Epoch: 32, Step: 240/502, Avg Loss: 4.2474, Avg Regression Loss 1.4910, Avg Classification Loss: 2.7564
2021-05-21 22:30:38 - Epoch: 32, Step: 250/502, Avg Loss: 4.1099, Avg Regression Loss 1.3667, Avg Classification Loss: 2.7432
2021-05-21 22:30:44 - Epoch: 32, Step: 260/502, Avg Loss: 4.6018, Avg Regression Loss 1.6469, Avg Classification Loss: 2.9549
2021-05-21 22:30:49 - Epoch: 32, Step: 270/502, Avg Loss: 4.0431, Avg Regression Loss 1.0955, Avg Classification Loss: 2.9476
2021-05-21 22:30:54 - Epoch: 32, Step: 280/502, Avg Loss: 4.1280, Avg Regression Loss 1.1734, Avg Classification Loss: 2.9546
2021-05-21 22:30:59 - Epoch: 32, Step: 290/502, Avg Loss: 3.8589, Avg Regression Loss 1.1161, Avg Classification Loss: 2.7427
2021-05-21 22:31:04 - Epoch: 32, Step: 300/502, Avg Loss: 4.1451, Avg Regression Loss 1.3828, Avg Classification Loss: 2.7623
2021-05-21 22:31:09 - Epoch: 32, Step: 310/502, Avg Loss: 3.8823, Avg Regression Loss 1.2619, Avg Classification Loss: 2.6204
2021-05-21 22:31:14 - Epoch: 32, Step: 320/502, Avg Loss: 3.7528, Avg Regression Loss 1.0669, Avg Classification Loss: 2.6859
2021-05-21 22:31:19 - Epoch: 32, Step: 330/502, Avg Loss: 3.9740, Avg Regression Loss 1.0905, Avg Classification Loss: 2.8835
2021-05-21 22:31:23 - Epoch: 32, Step: 340/502, Avg Loss: 4.4843, Avg Regression Loss 1.6197, Avg Classification Loss: 2.8646
2021-05-21 22:31:28 - Epoch: 32, Step: 350/502, Avg Loss: 4.4459, Avg Regression Loss 1.3259, Avg Classification Loss: 3.1200
2021-05-21 22:31:40 - Epoch: 32, Step: 360/502, Avg Loss: 4.4160, Avg Regression Loss 1.4694, Avg Classification Loss: 2.9466
2021-05-21 22:31:45 - Epoch: 32, Step: 370/502, Avg Loss: 4.6362, Avg Regression Loss 1.4610, Avg Classification Loss: 3.1752
2021-05-21 22:31:51 - Epoch: 32, Step: 380/502, Avg Loss: 5.7173, Avg Regression Loss 2.4596, Avg Classification Loss: 3.2577
2021-05-21 22:31:56 - Epoch: 32, Step: 390/502, Avg Loss: 5.6095, Avg Regression Loss 2.3513, Avg Classification Loss: 3.2582
2021-05-21 22:32:01 - Epoch: 32, Step: 400/502, Avg Loss: 3.9567, Avg Regression Loss 1.1836, Avg Classification Loss: 2.7731
2021-05-21 22:32:06 - Epoch: 32, Step: 410/502, Avg Loss: 4.1082, Avg Regression Loss 1.3316, Avg Classification Loss: 2.7766
2021-05-21 22:32:11 - Epoch: 32, Step: 420/502, Avg Loss: 5.0223, Avg Regression Loss 1.6890, Avg Classification Loss: 3.3333
2021-05-21 22:32:15 - Epoch: 32, Step: 430/502, Avg Loss: 4.1827, Avg Regression Loss 1.2962, Avg Classification Loss: 2.8865
2021-05-21 22:32:20 - Epoch: 32, Step: 440/502, Avg Loss: 4.5890, Avg Regression Loss 1.5837, Avg Classification Loss: 3.0053
2021-05-21 22:32:25 - Epoch: 32, Step: 450/502, Avg Loss: 4.4506, Avg Regression Loss 1.5744, Avg Classification Loss: 2.8762
2021-05-21 22:32:29 - Epoch: 32, Step: 460/502, Avg Loss: 4.3270, Avg Regression Loss 1.3609, Avg Classification Loss: 2.9661
2021-05-21 22:32:37 - Epoch: 32, Step: 470/502, Avg Loss: 5.1718, Avg Regression Loss 1.9262, Avg Classification Loss: 3.2456
2021-05-21 22:32:49 - Epoch: 32, Step: 480/502, Avg Loss: 3.8904, Avg Regression Loss 1.2113, Avg Classification Loss: 2.6791
2021-05-21 22:32:55 - Epoch: 32, Step: 490/502, Avg Loss: 3.9450, Avg Regression Loss 1.0442, Avg Classification Loss: 2.9008
2021-05-21 22:33:00 - Epoch: 32, Step: 500/502, Avg Loss: 4.2740, Avg Regression Loss 1.3740, Avg Classification Loss: 2.9001
2021-05-21 22:34:01 - Epoch: 32, Validation Loss: 3.6353, Validation Regression Loss 0.8906, Validation Classification Loss: 2.7447
2021-05-21 22:34:02 - Saved model models/smd/mb1-ssd-Epoch-32-Loss-3.6353448242305286.pth
2021-05-21 22:34:08 - Epoch: 33, Step: 10/502, Avg Loss: 4.4157, Avg Regression Loss 1.4249, Avg Classification Loss: 2.9907
2021-05-21 22:34:17 - Epoch: 33, Step: 20/502, Avg Loss: 4.4783, Avg Regression Loss 1.5150, Avg Classification Loss: 2.9633
2021-05-21 22:34:22 - Epoch: 33, Step: 30/502, Avg Loss: 4.9051, Avg Regression Loss 1.8479, Avg Classification Loss: 3.0572
2021-05-21 22:34:27 - Epoch: 33, Step: 40/502, Avg Loss: 4.5137, Avg Regression Loss 1.5683, Avg Classification Loss: 2.9454
2021-05-21 22:34:31 - Epoch: 33, Step: 50/502, Avg Loss: 4.0093, Avg Regression Loss 1.4074, Avg Classification Loss: 2.6019
2021-05-21 22:34:36 - Epoch: 33, Step: 60/502, Avg Loss: 4.7221, Avg Regression Loss 1.9273, Avg Classification Loss: 2.7948
2021-05-21 22:34:41 - Epoch: 33, Step: 70/502, Avg Loss: 4.0208, Avg Regression Loss 1.0953, Avg Classification Loss: 2.9256
2021-05-21 22:34:47 - Epoch: 33, Step: 80/502, Avg Loss: 4.4854, Avg Regression Loss 1.5429, Avg Classification Loss: 2.9425
2021-05-21 22:34:52 - Epoch: 33, Step: 90/502, Avg Loss: 4.6939, Avg Regression Loss 1.5614, Avg Classification Loss: 3.1325
2021-05-21 22:34:57 - Epoch: 33, Step: 100/502, Avg Loss: 4.2365, Avg Regression Loss 1.4458, Avg Classification Loss: 2.7907
2021-05-21 22:35:06 - Epoch: 33, Step: 110/502, Avg Loss: 4.0421, Avg Regression Loss 1.2441, Avg Classification Loss: 2.7981
2021-05-21 22:35:13 - Epoch: 33, Step: 120/502, Avg Loss: 4.8505, Avg Regression Loss 1.6846, Avg Classification Loss: 3.1659
2021-05-21 22:35:18 - Epoch: 33, Step: 130/502, Avg Loss: 4.4530, Avg Regression Loss 1.4048, Avg Classification Loss: 3.0482
2021-05-21 22:35:24 - Epoch: 33, Step: 140/502, Avg Loss: 4.5327, Avg Regression Loss 1.5288, Avg Classification Loss: 3.0039
2021-05-21 22:35:31 - Epoch: 33, Step: 150/502, Avg Loss: 4.4465, Avg Regression Loss 1.4997, Avg Classification Loss: 2.9469
2021-05-21 22:35:36 - Epoch: 33, Step: 160/502, Avg Loss: 5.0984, Avg Regression Loss 2.0388, Avg Classification Loss: 3.0597
2021-05-21 22:35:41 - Epoch: 33, Step: 170/502, Avg Loss: 4.1718, Avg Regression Loss 1.3845, Avg Classification Loss: 2.7873
2021-05-21 22:35:46 - Epoch: 33, Step: 180/502, Avg Loss: 4.9766, Avg Regression Loss 1.7299, Avg Classification Loss: 3.2467
2021-05-21 22:35:51 - Epoch: 33, Step: 190/502, Avg Loss: 4.4640, Avg Regression Loss 1.4539, Avg Classification Loss: 3.0100
2021-05-21 22:35:55 - Epoch: 33, Step: 200/502, Avg Loss: 4.4583, Avg Regression Loss 1.7326, Avg Classification Loss: 2.7256
2021-05-21 22:36:01 - Epoch: 33, Step: 210/502, Avg Loss: 4.5935, Avg Regression Loss 1.7881, Avg Classification Loss: 2.8054
2021-05-21 22:36:06 - Epoch: 33, Step: 220/502, Avg Loss: 5.2694, Avg Regression Loss 2.1410, Avg Classification Loss: 3.1284
2021-05-21 22:36:12 - Epoch: 33, Step: 230/502, Avg Loss: 4.3608, Avg Regression Loss 1.4339, Avg Classification Loss: 2.9269
2021-05-21 22:36:18 - Epoch: 33, Step: 240/502, Avg Loss: 4.0588, Avg Regression Loss 1.2338, Avg Classification Loss: 2.8250
2021-05-21 22:36:23 - Epoch: 33, Step: 250/502, Avg Loss: 5.1366, Avg Regression Loss 2.1022, Avg Classification Loss: 3.0344
2021-05-21 22:36:28 - Epoch: 33, Step: 260/502, Avg Loss: 4.7638, Avg Regression Loss 1.7754, Avg Classification Loss: 2.9884
2021-05-21 22:36:35 - Epoch: 33, Step: 270/502, Avg Loss: 3.6879, Avg Regression Loss 1.0669, Avg Classification Loss: 2.6210
2021-05-21 22:36:39 - Epoch: 33, Step: 280/502, Avg Loss: 4.0431, Avg Regression Loss 1.4178, Avg Classification Loss: 2.6253
2021-05-21 22:36:44 - Epoch: 33, Step: 290/502, Avg Loss: 4.1147, Avg Regression Loss 1.2921, Avg Classification Loss: 2.8226
2021-05-21 22:36:49 - Epoch: 33, Step: 300/502, Avg Loss: 4.1267, Avg Regression Loss 1.3761, Avg Classification Loss: 2.7506
2021-05-21 22:36:54 - Epoch: 33, Step: 310/502, Avg Loss: 4.3274, Avg Regression Loss 1.3875, Avg Classification Loss: 2.9399
2021-05-21 22:37:07 - Epoch: 33, Step: 320/502, Avg Loss: 4.5443, Avg Regression Loss 1.4064, Avg Classification Loss: 3.1379
2021-05-21 22:37:12 - Epoch: 33, Step: 330/502, Avg Loss: 4.3275, Avg Regression Loss 1.4023, Avg Classification Loss: 2.9251
2021-05-21 22:37:17 - Epoch: 33, Step: 340/502, Avg Loss: 4.7761, Avg Regression Loss 1.7369, Avg Classification Loss: 3.0391
2021-05-21 22:37:22 - Epoch: 33, Step: 350/502, Avg Loss: 4.7455, Avg Regression Loss 1.4869, Avg Classification Loss: 3.2586
2021-05-21 22:37:28 - Epoch: 33, Step: 360/502, Avg Loss: 4.4341, Avg Regression Loss 1.4306, Avg Classification Loss: 3.0034
2021-05-21 22:37:33 - Epoch: 33, Step: 370/502, Avg Loss: 3.9683, Avg Regression Loss 1.2829, Avg Classification Loss: 2.6854
2021-05-21 22:37:37 - Epoch: 33, Step: 380/502, Avg Loss: 4.0681, Avg Regression Loss 1.3952, Avg Classification Loss: 2.6729
2021-05-21 22:37:43 - Epoch: 33, Step: 390/502, Avg Loss: 4.2080, Avg Regression Loss 1.3843, Avg Classification Loss: 2.8237
2021-05-21 22:37:48 - Epoch: 33, Step: 400/502, Avg Loss: 3.9788, Avg Regression Loss 1.1622, Avg Classification Loss: 2.8166
2021-05-21 22:37:53 - Epoch: 33, Step: 410/502, Avg Loss: 4.3506, Avg Regression Loss 1.4572, Avg Classification Loss: 2.8934
2021-05-21 22:37:58 - Epoch: 33, Step: 420/502, Avg Loss: 4.0233, Avg Regression Loss 1.2354, Avg Classification Loss: 2.7879
2021-05-21 22:38:03 - Epoch: 33, Step: 430/502, Avg Loss: 4.3328, Avg Regression Loss 1.5092, Avg Classification Loss: 2.8235
2021-05-21 22:38:07 - Epoch: 33, Step: 440/502, Avg Loss: 3.5967, Avg Regression Loss 0.7542, Avg Classification Loss: 2.8425
2021-05-21 22:38:12 - Epoch: 33, Step: 450/502, Avg Loss: 4.1287, Avg Regression Loss 1.1970, Avg Classification Loss: 2.9317
2021-05-21 22:38:17 - Epoch: 33, Step: 460/502, Avg Loss: 3.9185, Avg Regression Loss 0.9189, Avg Classification Loss: 2.9996
2021-05-21 22:38:21 - Epoch: 33, Step: 470/502, Avg Loss: 3.6241, Avg Regression Loss 0.7400, Avg Classification Loss: 2.8841
2021-05-21 22:38:26 - Epoch: 33, Step: 480/502, Avg Loss: 4.4756, Avg Regression Loss 1.5783, Avg Classification Loss: 2.8973
2021-05-21 22:38:31 - Epoch: 33, Step: 490/502, Avg Loss: 5.3991, Avg Regression Loss 2.3965, Avg Classification Loss: 3.0025
2021-05-21 22:38:36 - Epoch: 33, Step: 500/502, Avg Loss: 3.6655, Avg Regression Loss 1.0338, Avg Classification Loss: 2.6317
2021-05-21 22:39:36 - Epoch: 33, Validation Loss: 3.6955, Validation Regression Loss 0.9441, Validation Classification Loss: 2.7514
2021-05-21 22:39:36 - Saved model models/smd/mb1-ssd-Epoch-33-Loss-3.6955030116426992.pth
2021-05-21 22:39:42 - Epoch: 34, Step: 10/502, Avg Loss: 4.0205, Avg Regression Loss 1.2090, Avg Classification Loss: 2.8115
2021-05-21 22:39:50 - Epoch: 34, Step: 20/502, Avg Loss: 4.3871, Avg Regression Loss 1.5382, Avg Classification Loss: 2.8489
2021-05-21 22:39:54 - Epoch: 34, Step: 30/502, Avg Loss: 4.1282, Avg Regression Loss 1.3947, Avg Classification Loss: 2.7335
2021-05-21 22:39:59 - Epoch: 34, Step: 40/502, Avg Loss: 4.8037, Avg Regression Loss 1.7051, Avg Classification Loss: 3.0987
2021-05-21 22:40:04 - Epoch: 34, Step: 50/502, Avg Loss: 4.1629, Avg Regression Loss 1.4602, Avg Classification Loss: 2.7027
2021-05-21 22:40:08 - Epoch: 34, Step: 60/502, Avg Loss: 4.0386, Avg Regression Loss 1.3321, Avg Classification Loss: 2.7065
2021-05-21 22:40:14 - Epoch: 34, Step: 70/502, Avg Loss: 5.2227, Avg Regression Loss 2.1242, Avg Classification Loss: 3.0986
2021-05-21 22:40:19 - Epoch: 34, Step: 80/502, Avg Loss: 4.0369, Avg Regression Loss 1.2052, Avg Classification Loss: 2.8317
2021-05-21 22:40:25 - Epoch: 34, Step: 90/502, Avg Loss: 4.4109, Avg Regression Loss 1.6133, Avg Classification Loss: 2.7976
2021-05-21 22:40:30 - Epoch: 34, Step: 100/502, Avg Loss: 4.6796, Avg Regression Loss 1.5287, Avg Classification Loss: 3.1509
2021-05-21 22:40:35 - Epoch: 34, Step: 110/502, Avg Loss: 4.3050, Avg Regression Loss 1.4203, Avg Classification Loss: 2.8847
2021-05-21 22:40:40 - Epoch: 34, Step: 120/502, Avg Loss: 4.6929, Avg Regression Loss 1.8267, Avg Classification Loss: 2.8662
2021-05-21 22:40:45 - Epoch: 34, Step: 130/502, Avg Loss: 4.5440, Avg Regression Loss 1.6125, Avg Classification Loss: 2.9315
2021-05-21 22:40:50 - Epoch: 34, Step: 140/502, Avg Loss: 3.7156, Avg Regression Loss 0.9766, Avg Classification Loss: 2.7390
2021-05-21 22:40:55 - Epoch: 34, Step: 150/502, Avg Loss: 5.1074, Avg Regression Loss 2.2574, Avg Classification Loss: 2.8500
2021-05-21 22:41:01 - Epoch: 34, Step: 160/502, Avg Loss: 4.1647, Avg Regression Loss 1.4211, Avg Classification Loss: 2.7436
2021-05-21 22:41:06 - Epoch: 34, Step: 170/502, Avg Loss: 4.8762, Avg Regression Loss 1.8469, Avg Classification Loss: 3.0293
2021-05-21 22:41:10 - Epoch: 34, Step: 180/502, Avg Loss: 4.5271, Avg Regression Loss 1.3660, Avg Classification Loss: 3.1612
2021-05-21 22:41:15 - Epoch: 34, Step: 190/502, Avg Loss: 4.1529, Avg Regression Loss 1.4834, Avg Classification Loss: 2.6695
2021-05-21 22:41:22 - Epoch: 34, Step: 200/502, Avg Loss: 5.0167, Avg Regression Loss 1.8785, Avg Classification Loss: 3.1381
2021-05-21 22:41:27 - Epoch: 34, Step: 210/502, Avg Loss: 4.3074, Avg Regression Loss 1.3866, Avg Classification Loss: 2.9208
2021-05-21 22:41:38 - Epoch: 34, Step: 220/502, Avg Loss: 4.2568, Avg Regression Loss 1.3562, Avg Classification Loss: 2.9006
2021-05-21 22:41:43 - Epoch: 34, Step: 230/502, Avg Loss: 4.4124, Avg Regression Loss 1.5805, Avg Classification Loss: 2.8319
2021-05-21 22:41:53 - Epoch: 34, Step: 240/502, Avg Loss: 4.4333, Avg Regression Loss 1.4908, Avg Classification Loss: 2.9425
2021-05-21 22:41:59 - Epoch: 34, Step: 250/502, Avg Loss: 4.2803, Avg Regression Loss 1.3833, Avg Classification Loss: 2.8970
2021-05-21 22:42:03 - Epoch: 34, Step: 260/502, Avg Loss: 4.5279, Avg Regression Loss 1.7142, Avg Classification Loss: 2.8137
2021-05-21 22:42:08 - Epoch: 34, Step: 270/502, Avg Loss: 3.6506, Avg Regression Loss 0.8772, Avg Classification Loss: 2.7734
2021-05-21 22:42:13 - Epoch: 34, Step: 280/502, Avg Loss: 4.0384, Avg Regression Loss 1.2897, Avg Classification Loss: 2.7487
2021-05-21 22:42:20 - Epoch: 34, Step: 290/502, Avg Loss: 4.1863, Avg Regression Loss 1.4572, Avg Classification Loss: 2.7291
2021-05-21 22:42:25 - Epoch: 34, Step: 300/502, Avg Loss: 4.3472, Avg Regression Loss 1.3895, Avg Classification Loss: 2.9577
2021-05-21 22:42:29 - Epoch: 34, Step: 310/502, Avg Loss: 4.2994, Avg Regression Loss 1.3567, Avg Classification Loss: 2.9427
2021-05-21 22:42:37 - Epoch: 34, Step: 320/502, Avg Loss: 4.2524, Avg Regression Loss 1.1104, Avg Classification Loss: 3.1419
2021-05-21 22:42:42 - Epoch: 34, Step: 330/502, Avg Loss: 4.1341, Avg Regression Loss 1.1853, Avg Classification Loss: 2.9488
2021-05-21 22:42:47 - Epoch: 34, Step: 340/502, Avg Loss: 4.2368, Avg Regression Loss 1.4507, Avg Classification Loss: 2.7860
2021-05-21 22:42:51 - Epoch: 34, Step: 350/502, Avg Loss: 4.1068, Avg Regression Loss 0.9149, Avg Classification Loss: 3.1919
2021-05-21 22:42:58 - Epoch: 34, Step: 360/502, Avg Loss: 4.0539, Avg Regression Loss 1.2729, Avg Classification Loss: 2.7810
2021-05-21 22:43:03 - Epoch: 34, Step: 370/502, Avg Loss: 3.9162, Avg Regression Loss 1.3444, Avg Classification Loss: 2.5719
2021-05-21 22:43:09 - Epoch: 34, Step: 380/502, Avg Loss: 5.2527, Avg Regression Loss 2.2297, Avg Classification Loss: 3.0230
2021-05-21 22:43:14 - Epoch: 34, Step: 390/502, Avg Loss: 4.0764, Avg Regression Loss 1.0352, Avg Classification Loss: 3.0412
2021-05-21 22:43:19 - Epoch: 34, Step: 400/502, Avg Loss: 4.1190, Avg Regression Loss 1.1814, Avg Classification Loss: 2.9376
2021-05-21 22:43:24 - Epoch: 34, Step: 410/502, Avg Loss: 4.2695, Avg Regression Loss 1.4105, Avg Classification Loss: 2.8589
2021-05-21 22:43:29 - Epoch: 34, Step: 420/502, Avg Loss: 4.1187, Avg Regression Loss 1.1960, Avg Classification Loss: 2.9227
2021-05-21 22:43:34 - Epoch: 34, Step: 430/502, Avg Loss: 4.2834, Avg Regression Loss 1.3553, Avg Classification Loss: 2.9281
2021-05-21 22:43:40 - Epoch: 34, Step: 440/502, Avg Loss: 4.4949, Avg Regression Loss 1.7389, Avg Classification Loss: 2.7560
2021-05-21 22:43:44 - Epoch: 34, Step: 450/502, Avg Loss: 5.0264, Avg Regression Loss 1.9198, Avg Classification Loss: 3.1066
2021-05-21 22:43:49 - Epoch: 34, Step: 460/502, Avg Loss: 4.5368, Avg Regression Loss 1.4054, Avg Classification Loss: 3.1314
2021-05-21 22:43:54 - Epoch: 34, Step: 470/502, Avg Loss: 4.0836, Avg Regression Loss 1.1660, Avg Classification Loss: 2.9176
2021-05-21 22:43:58 - Epoch: 34, Step: 480/502, Avg Loss: 4.1959, Avg Regression Loss 1.3947, Avg Classification Loss: 2.8012
2021-05-21 22:44:03 - Epoch: 34, Step: 490/502, Avg Loss: 4.4028, Avg Regression Loss 1.4166, Avg Classification Loss: 2.9862
2021-05-21 22:44:09 - Epoch: 34, Step: 500/502, Avg Loss: 4.0384, Avg Regression Loss 1.3500, Avg Classification Loss: 2.6884
2021-05-21 22:45:10 - Epoch: 34, Validation Loss: 3.5942, Validation Regression Loss 0.9558, Validation Classification Loss: 2.6384
2021-05-21 22:45:10 - Saved model models/smd/mb1-ssd-Epoch-34-Loss-3.594158842031699.pth
2021-05-21 22:45:18 - Epoch: 35, Step: 10/502, Avg Loss: 4.4657, Avg Regression Loss 1.5331, Avg Classification Loss: 2.9326
2021-05-21 22:45:25 - Epoch: 35, Step: 20/502, Avg Loss: 4.3791, Avg Regression Loss 1.4033, Avg Classification Loss: 2.9758
2021-05-21 22:45:32 - Epoch: 35, Step: 30/502, Avg Loss: 3.8816, Avg Regression Loss 1.3571, Avg Classification Loss: 2.5245
2021-05-21 22:45:37 - Epoch: 35, Step: 40/502, Avg Loss: 5.5435, Avg Regression Loss 2.2578, Avg Classification Loss: 3.2858
2021-05-21 22:45:42 - Epoch: 35, Step: 50/502, Avg Loss: 4.0273, Avg Regression Loss 1.3762, Avg Classification Loss: 2.6512
2021-05-21 22:45:47 - Epoch: 35, Step: 60/502, Avg Loss: 3.8702, Avg Regression Loss 1.1631, Avg Classification Loss: 2.7072
2021-05-21 22:45:51 - Epoch: 35, Step: 70/502, Avg Loss: 3.7238, Avg Regression Loss 1.2133, Avg Classification Loss: 2.5105
2021-05-21 22:45:56 - Epoch: 35, Step: 80/502, Avg Loss: 4.2693, Avg Regression Loss 1.3674, Avg Classification Loss: 2.9018
2021-05-21 22:46:04 - Epoch: 35, Step: 90/502, Avg Loss: 4.7385, Avg Regression Loss 1.6122, Avg Classification Loss: 3.1263
2021-05-21 22:46:09 - Epoch: 35, Step: 100/502, Avg Loss: 4.5907, Avg Regression Loss 1.6631, Avg Classification Loss: 2.9276
2021-05-21 22:46:13 - Epoch: 35, Step: 110/502, Avg Loss: 3.6685, Avg Regression Loss 1.0647, Avg Classification Loss: 2.6039
2021-05-21 22:46:22 - Epoch: 35, Step: 120/502, Avg Loss: 3.8947, Avg Regression Loss 1.1889, Avg Classification Loss: 2.7058
2021-05-21 22:46:27 - Epoch: 35, Step: 130/502, Avg Loss: 4.1449, Avg Regression Loss 1.2715, Avg Classification Loss: 2.8733
2021-05-21 22:46:32 - Epoch: 35, Step: 140/502, Avg Loss: 3.8804, Avg Regression Loss 1.0596, Avg Classification Loss: 2.8208
2021-05-21 22:46:37 - Epoch: 35, Step: 150/502, Avg Loss: 4.1191, Avg Regression Loss 1.2310, Avg Classification Loss: 2.8881
2021-05-21 22:46:49 - Epoch: 35, Step: 160/502, Avg Loss: 4.1585, Avg Regression Loss 1.5413, Avg Classification Loss: 2.6172
2021-05-21 22:46:54 - Epoch: 35, Step: 170/502, Avg Loss: 3.5911, Avg Regression Loss 0.9384, Avg Classification Loss: 2.6527
2021-05-21 22:46:59 - Epoch: 35, Step: 180/502, Avg Loss: 4.2601, Avg Regression Loss 1.3873, Avg Classification Loss: 2.8728
2021-05-21 22:47:03 - Epoch: 35, Step: 190/502, Avg Loss: 4.8544, Avg Regression Loss 2.1310, Avg Classification Loss: 2.7234
2021-05-21 22:47:08 - Epoch: 35, Step: 200/502, Avg Loss: 4.3335, Avg Regression Loss 1.5378, Avg Classification Loss: 2.7958
2021-05-21 22:47:13 - Epoch: 35, Step: 210/502, Avg Loss: 4.4569, Avg Regression Loss 1.6935, Avg Classification Loss: 2.7633
2021-05-21 22:47:18 - Epoch: 35, Step: 220/502, Avg Loss: 3.9317, Avg Regression Loss 1.3946, Avg Classification Loss: 2.5371
2021-05-21 22:47:23 - Epoch: 35, Step: 230/502, Avg Loss: 3.8958, Avg Regression Loss 1.1489, Avg Classification Loss: 2.7469
2021-05-21 22:47:28 - Epoch: 35, Step: 240/502, Avg Loss: 4.5145, Avg Regression Loss 1.5893, Avg Classification Loss: 2.9252
2021-05-21 22:47:33 - Epoch: 35, Step: 250/502, Avg Loss: 3.8367, Avg Regression Loss 1.2808, Avg Classification Loss: 2.5559
2021-05-21 22:47:38 - Epoch: 35, Step: 260/502, Avg Loss: 4.2339, Avg Regression Loss 1.3336, Avg Classification Loss: 2.9002
2021-05-21 22:47:44 - Epoch: 35, Step: 270/502, Avg Loss: 3.8779, Avg Regression Loss 1.1300, Avg Classification Loss: 2.7479
2021-05-21 22:47:48 - Epoch: 35, Step: 280/502, Avg Loss: 3.2009, Avg Regression Loss 0.6579, Avg Classification Loss: 2.5430
2021-05-21 22:47:53 - Epoch: 35, Step: 290/502, Avg Loss: 4.7459, Avg Regression Loss 1.7406, Avg Classification Loss: 3.0054
2021-05-21 22:48:01 - Epoch: 35, Step: 300/502, Avg Loss: 4.1643, Avg Regression Loss 1.5160, Avg Classification Loss: 2.6483
2021-05-21 22:48:05 - Epoch: 35, Step: 310/502, Avg Loss: 3.9369, Avg Regression Loss 1.1754, Avg Classification Loss: 2.7615
2021-05-21 22:48:10 - Epoch: 35, Step: 320/502, Avg Loss: 4.0893, Avg Regression Loss 1.3051, Avg Classification Loss: 2.7842
2021-05-21 22:48:15 - Epoch: 35, Step: 330/502, Avg Loss: 4.4480, Avg Regression Loss 1.3272, Avg Classification Loss: 3.1208
2021-05-21 22:48:21 - Epoch: 35, Step: 340/502, Avg Loss: 4.2582, Avg Regression Loss 1.4510, Avg Classification Loss: 2.8072
2021-05-21 22:48:25 - Epoch: 35, Step: 350/502, Avg Loss: 4.0146, Avg Regression Loss 1.5318, Avg Classification Loss: 2.4828
2021-05-21 22:48:30 - Epoch: 35, Step: 360/502, Avg Loss: 3.7075, Avg Regression Loss 1.0968, Avg Classification Loss: 2.6107
2021-05-21 22:48:35 - Epoch: 35, Step: 370/502, Avg Loss: 3.9896, Avg Regression Loss 1.4406, Avg Classification Loss: 2.5489
2021-05-21 22:48:39 - Epoch: 35, Step: 380/502, Avg Loss: 4.3142, Avg Regression Loss 1.5301, Avg Classification Loss: 2.7841
2021-05-21 22:48:44 - Epoch: 35, Step: 390/502, Avg Loss: 4.2144, Avg Regression Loss 1.4196, Avg Classification Loss: 2.7948
2021-05-21 22:48:49 - Epoch: 35, Step: 400/502, Avg Loss: 4.1351, Avg Regression Loss 1.4718, Avg Classification Loss: 2.6633
2021-05-21 22:48:54 - Epoch: 35, Step: 410/502, Avg Loss: 4.2845, Avg Regression Loss 1.4135, Avg Classification Loss: 2.8710
2021-05-21 22:48:59 - Epoch: 35, Step: 420/502, Avg Loss: 5.0661, Avg Regression Loss 1.9768, Avg Classification Loss: 3.0893
2021-05-21 22:49:04 - Epoch: 35, Step: 430/502, Avg Loss: 5.6302, Avg Regression Loss 2.4690, Avg Classification Loss: 3.1611
2021-05-21 22:49:09 - Epoch: 35, Step: 440/502, Avg Loss: 4.7753, Avg Regression Loss 1.6469, Avg Classification Loss: 3.1283
2021-05-21 22:49:14 - Epoch: 35, Step: 450/502, Avg Loss: 3.9876, Avg Regression Loss 1.1678, Avg Classification Loss: 2.8198
2021-05-21 22:49:19 - Epoch: 35, Step: 460/502, Avg Loss: 4.3689, Avg Regression Loss 1.3613, Avg Classification Loss: 3.0076
2021-05-21 22:49:24 - Epoch: 35, Step: 470/502, Avg Loss: 4.6789, Avg Regression Loss 1.6988, Avg Classification Loss: 2.9801
2021-05-21 22:49:41 - Epoch: 35, Step: 480/502, Avg Loss: 3.5476, Avg Regression Loss 0.9876, Avg Classification Loss: 2.5599
2021-05-21 22:49:46 - Epoch: 35, Step: 490/502, Avg Loss: 3.7308, Avg Regression Loss 0.9368, Avg Classification Loss: 2.7940
2021-05-21 22:49:52 - Epoch: 35, Step: 500/502, Avg Loss: 4.5420, Avg Regression Loss 1.6581, Avg Classification Loss: 2.8839
2021-05-21 22:50:54 - Epoch: 35, Validation Loss: 3.7809, Validation Regression Loss 1.0580, Validation Classification Loss: 2.7229
2021-05-21 22:50:54 - Saved model models/smd/mb1-ssd-Epoch-35-Loss-3.780874768576299.pth
2021-05-21 22:51:00 - Epoch: 36, Step: 10/502, Avg Loss: 3.7511, Avg Regression Loss 0.8807, Avg Classification Loss: 2.8704
2021-05-21 22:51:10 - Epoch: 36, Step: 20/502, Avg Loss: 4.4797, Avg Regression Loss 1.7580, Avg Classification Loss: 2.7217
2021-05-21 22:51:16 - Epoch: 36, Step: 30/502, Avg Loss: 4.2989, Avg Regression Loss 1.5212, Avg Classification Loss: 2.7777
2021-05-21 22:51:20 - Epoch: 36, Step: 40/502, Avg Loss: 4.0774, Avg Regression Loss 1.0556, Avg Classification Loss: 3.0218
2021-05-21 22:51:25 - Epoch: 36, Step: 50/502, Avg Loss: 3.6996, Avg Regression Loss 1.0219, Avg Classification Loss: 2.6777
2021-05-21 22:51:30 - Epoch: 36, Step: 60/502, Avg Loss: 3.8885, Avg Regression Loss 1.1404, Avg Classification Loss: 2.7482
2021-05-21 22:51:34 - Epoch: 36, Step: 70/502, Avg Loss: 3.6688, Avg Regression Loss 0.8892, Avg Classification Loss: 2.7796
2021-05-21 22:51:39 - Epoch: 36, Step: 80/502, Avg Loss: 3.8243, Avg Regression Loss 1.2858, Avg Classification Loss: 2.5384
2021-05-21 22:51:45 - Epoch: 36, Step: 90/502, Avg Loss: 5.2189, Avg Regression Loss 2.1742, Avg Classification Loss: 3.0447
2021-05-21 22:51:50 - Epoch: 36, Step: 100/502, Avg Loss: 4.0135, Avg Regression Loss 1.2041, Avg Classification Loss: 2.8094
2021-05-21 22:51:55 - Epoch: 36, Step: 110/502, Avg Loss: 4.2712, Avg Regression Loss 1.5004, Avg Classification Loss: 2.7709
2021-05-21 22:52:00 - Epoch: 36, Step: 120/502, Avg Loss: 4.7102, Avg Regression Loss 1.7855, Avg Classification Loss: 2.9248
2021-05-21 22:52:05 - Epoch: 36, Step: 130/502, Avg Loss: 4.3952, Avg Regression Loss 1.5444, Avg Classification Loss: 2.8508
2021-05-21 22:52:10 - Epoch: 36, Step: 140/502, Avg Loss: 4.5001, Avg Regression Loss 1.6058, Avg Classification Loss: 2.8943
2021-05-21 22:52:16 - Epoch: 36, Step: 150/502, Avg Loss: 4.1964, Avg Regression Loss 1.4313, Avg Classification Loss: 2.7652
2021-05-21 22:52:21 - Epoch: 36, Step: 160/502, Avg Loss: 4.6328, Avg Regression Loss 1.5882, Avg Classification Loss: 3.0446
2021-05-21 22:52:25 - Epoch: 36, Step: 170/502, Avg Loss: 4.2442, Avg Regression Loss 1.2279, Avg Classification Loss: 3.0163
2021-05-21 22:52:30 - Epoch: 36, Step: 180/502, Avg Loss: 4.0105, Avg Regression Loss 1.3309, Avg Classification Loss: 2.6796
2021-05-21 22:52:35 - Epoch: 36, Step: 190/502, Avg Loss: 4.4761, Avg Regression Loss 1.6229, Avg Classification Loss: 2.8532
2021-05-21 22:52:40 - Epoch: 36, Step: 200/502, Avg Loss: 4.3350, Avg Regression Loss 1.4531, Avg Classification Loss: 2.8819
2021-05-21 22:52:45 - Epoch: 36, Step: 210/502, Avg Loss: 4.1753, Avg Regression Loss 1.3584, Avg Classification Loss: 2.8169
2021-05-21 22:52:55 - Epoch: 36, Step: 220/502, Avg Loss: 3.9937, Avg Regression Loss 1.0775, Avg Classification Loss: 2.9163
2021-05-21 22:52:59 - Epoch: 36, Step: 230/502, Avg Loss: 4.0577, Avg Regression Loss 1.1910, Avg Classification Loss: 2.8667
2021-05-21 22:53:04 - Epoch: 36, Step: 240/502, Avg Loss: 4.0264, Avg Regression Loss 1.2158, Avg Classification Loss: 2.8106
2021-05-21 22:53:09 - Epoch: 36, Step: 250/502, Avg Loss: 4.3725, Avg Regression Loss 1.5446, Avg Classification Loss: 2.8279
2021-05-21 22:53:14 - Epoch: 36, Step: 260/502, Avg Loss: 3.8876, Avg Regression Loss 1.0248, Avg Classification Loss: 2.8629
2021-05-21 22:53:19 - Epoch: 36, Step: 270/502, Avg Loss: 4.4147, Avg Regression Loss 1.4439, Avg Classification Loss: 2.9708
2021-05-21 22:53:24 - Epoch: 36, Step: 280/502, Avg Loss: 4.0594, Avg Regression Loss 1.2046, Avg Classification Loss: 2.8548
2021-05-21 22:53:29 - Epoch: 36, Step: 290/502, Avg Loss: 3.8847, Avg Regression Loss 1.1306, Avg Classification Loss: 2.7540
2021-05-21 22:53:34 - Epoch: 36, Step: 300/502, Avg Loss: 4.4748, Avg Regression Loss 1.3978, Avg Classification Loss: 3.0770
2021-05-21 22:53:39 - Epoch: 36, Step: 310/502, Avg Loss: 3.9983, Avg Regression Loss 1.3648, Avg Classification Loss: 2.6335
2021-05-21 22:53:44 - Epoch: 36, Step: 320/502, Avg Loss: 3.8730, Avg Regression Loss 1.0942, Avg Classification Loss: 2.7788
2021-05-21 22:53:49 - Epoch: 36, Step: 330/502, Avg Loss: 3.9813, Avg Regression Loss 1.0771, Avg Classification Loss: 2.9042
2021-05-21 22:53:54 - Epoch: 36, Step: 340/502, Avg Loss: 3.6923, Avg Regression Loss 0.9756, Avg Classification Loss: 2.7167
2021-05-21 22:53:58 - Epoch: 36, Step: 350/502, Avg Loss: 3.6806, Avg Regression Loss 0.8867, Avg Classification Loss: 2.7939
2021-05-21 22:54:03 - Epoch: 36, Step: 360/502, Avg Loss: 3.8910, Avg Regression Loss 1.0139, Avg Classification Loss: 2.8771
2021-05-21 22:54:08 - Epoch: 36, Step: 370/502, Avg Loss: 4.1668, Avg Regression Loss 1.4813, Avg Classification Loss: 2.6854
2021-05-21 22:54:14 - Epoch: 36, Step: 380/502, Avg Loss: 4.7104, Avg Regression Loss 1.5697, Avg Classification Loss: 3.1407
2021-05-21 22:54:19 - Epoch: 36, Step: 390/502, Avg Loss: 4.7115, Avg Regression Loss 1.5891, Avg Classification Loss: 3.1224
2021-05-21 22:54:24 - Epoch: 36, Step: 400/502, Avg Loss: 3.9490, Avg Regression Loss 0.9735, Avg Classification Loss: 2.9755
2021-05-21 22:54:29 - Epoch: 36, Step: 410/502, Avg Loss: 4.5601, Avg Regression Loss 1.6817, Avg Classification Loss: 2.8784
2021-05-21 22:54:34 - Epoch: 36, Step: 420/502, Avg Loss: 4.3064, Avg Regression Loss 1.5550, Avg Classification Loss: 2.7514
2021-05-21 22:54:39 - Epoch: 36, Step: 430/502, Avg Loss: 4.1076, Avg Regression Loss 1.3041, Avg Classification Loss: 2.8035
2021-05-21 22:54:44 - Epoch: 36, Step: 440/502, Avg Loss: 3.5987, Avg Regression Loss 0.9938, Avg Classification Loss: 2.6049
2021-05-21 22:54:48 - Epoch: 36, Step: 450/502, Avg Loss: 3.3088, Avg Regression Loss 0.8285, Avg Classification Loss: 2.4803
2021-05-21 22:54:56 - Epoch: 36, Step: 460/502, Avg Loss: 4.0275, Avg Regression Loss 1.0852, Avg Classification Loss: 2.9423
2021-05-21 22:55:01 - Epoch: 36, Step: 470/502, Avg Loss: 4.0806, Avg Regression Loss 1.2977, Avg Classification Loss: 2.7829
2021-05-21 22:55:06 - Epoch: 36, Step: 480/502, Avg Loss: 4.3801, Avg Regression Loss 1.4720, Avg Classification Loss: 2.9081
2021-05-21 22:55:11 - Epoch: 36, Step: 490/502, Avg Loss: 4.9905, Avg Regression Loss 2.0660, Avg Classification Loss: 2.9246
2021-05-21 22:55:18 - Epoch: 36, Step: 500/502, Avg Loss: 4.2106, Avg Regression Loss 1.4874, Avg Classification Loss: 2.7232
2021-05-21 22:56:17 - Epoch: 36, Validation Loss: 3.3401, Validation Regression Loss 0.8170, Validation Classification Loss: 2.5231
2021-05-21 22:56:17 - Saved model models/smd/mb1-ssd-Epoch-36-Loss-3.3401028107836903.pth
2021-05-21 22:56:24 - Epoch: 37, Step: 10/502, Avg Loss: 4.2385, Avg Regression Loss 1.2483, Avg Classification Loss: 2.9902
2021-05-21 22:56:30 - Epoch: 37, Step: 20/502, Avg Loss: 3.7762, Avg Regression Loss 1.2685, Avg Classification Loss: 2.5076
2021-05-21 22:56:36 - Epoch: 37, Step: 30/502, Avg Loss: 4.3754, Avg Regression Loss 1.3100, Avg Classification Loss: 3.0654
2021-05-21 22:56:40 - Epoch: 37, Step: 40/502, Avg Loss: 3.5818, Avg Regression Loss 1.0182, Avg Classification Loss: 2.5636
2021-05-21 22:56:45 - Epoch: 37, Step: 50/502, Avg Loss: 3.8831, Avg Regression Loss 1.2395, Avg Classification Loss: 2.6436
2021-05-21 22:56:51 - Epoch: 37, Step: 60/502, Avg Loss: 3.6706, Avg Regression Loss 0.9039, Avg Classification Loss: 2.7667
2021-05-21 22:56:56 - Epoch: 37, Step: 70/502, Avg Loss: 4.1815, Avg Regression Loss 1.3387, Avg Classification Loss: 2.8428
2021-05-21 22:57:00 - Epoch: 37, Step: 80/502, Avg Loss: 3.9858, Avg Regression Loss 1.1235, Avg Classification Loss: 2.8624
2021-05-21 22:57:07 - Epoch: 37, Step: 90/502, Avg Loss: 4.8653, Avg Regression Loss 1.9715, Avg Classification Loss: 2.8938
2021-05-21 22:57:11 - Epoch: 37, Step: 100/502, Avg Loss: 4.4402, Avg Regression Loss 1.5847, Avg Classification Loss: 2.8555
2021-05-21 22:57:30 - Epoch: 37, Step: 110/502, Avg Loss: 4.2089, Avg Regression Loss 1.4419, Avg Classification Loss: 2.7670
2021-05-21 22:57:35 - Epoch: 37, Step: 120/502, Avg Loss: 4.0746, Avg Regression Loss 1.3034, Avg Classification Loss: 2.7712
2021-05-21 22:57:39 - Epoch: 37, Step: 130/502, Avg Loss: 4.2895, Avg Regression Loss 1.4749, Avg Classification Loss: 2.8146
2021-05-21 22:57:44 - Epoch: 37, Step: 140/502, Avg Loss: 4.3962, Avg Regression Loss 1.5169, Avg Classification Loss: 2.8793
2021-05-21 22:57:49 - Epoch: 37, Step: 150/502, Avg Loss: 4.3320, Avg Regression Loss 1.7373, Avg Classification Loss: 2.5947
2021-05-21 22:57:55 - Epoch: 37, Step: 160/502, Avg Loss: 4.1243, Avg Regression Loss 1.2602, Avg Classification Loss: 2.8641
2021-05-21 22:57:59 - Epoch: 37, Step: 170/502, Avg Loss: 3.5959, Avg Regression Loss 0.9582, Avg Classification Loss: 2.6377
2021-05-21 22:58:04 - Epoch: 37, Step: 180/502, Avg Loss: 3.9994, Avg Regression Loss 1.2320, Avg Classification Loss: 2.7675
2021-05-21 22:58:09 - Epoch: 37, Step: 190/502, Avg Loss: 4.5338, Avg Regression Loss 1.6722, Avg Classification Loss: 2.8616
2021-05-21 22:58:14 - Epoch: 37, Step: 200/502, Avg Loss: 4.1288, Avg Regression Loss 1.5270, Avg Classification Loss: 2.6018
2021-05-21 22:58:22 - Epoch: 37, Step: 210/502, Avg Loss: 5.0596, Avg Regression Loss 2.2772, Avg Classification Loss: 2.7823
2021-05-21 22:58:26 - Epoch: 37, Step: 220/502, Avg Loss: 4.4379, Avg Regression Loss 1.6156, Avg Classification Loss: 2.8223
2021-05-21 22:58:32 - Epoch: 37, Step: 230/502, Avg Loss: 4.5117, Avg Regression Loss 1.5488, Avg Classification Loss: 2.9629
2021-05-21 22:58:37 - Epoch: 37, Step: 240/502, Avg Loss: 4.2097, Avg Regression Loss 1.2956, Avg Classification Loss: 2.9141
2021-05-21 22:58:42 - Epoch: 37, Step: 250/502, Avg Loss: 4.0955, Avg Regression Loss 1.4350, Avg Classification Loss: 2.6606
2021-05-21 22:58:47 - Epoch: 37, Step: 260/502, Avg Loss: 4.2168, Avg Regression Loss 1.3227, Avg Classification Loss: 2.8941
2021-05-21 22:58:52 - Epoch: 37, Step: 270/502, Avg Loss: 3.6662, Avg Regression Loss 1.1249, Avg Classification Loss: 2.5413
2021-05-21 22:58:56 - Epoch: 37, Step: 280/502, Avg Loss: 4.1371, Avg Regression Loss 1.4906, Avg Classification Loss: 2.6464
2021-05-21 22:59:01 - Epoch: 37, Step: 290/502, Avg Loss: 4.2358, Avg Regression Loss 1.5039, Avg Classification Loss: 2.7319
2021-05-21 22:59:07 - Epoch: 37, Step: 300/502, Avg Loss: 4.0361, Avg Regression Loss 1.3196, Avg Classification Loss: 2.7165
2021-05-21 22:59:12 - Epoch: 37, Step: 310/502, Avg Loss: 3.7347, Avg Regression Loss 0.9968, Avg Classification Loss: 2.7379
2021-05-21 22:59:17 - Epoch: 37, Step: 320/502, Avg Loss: 3.6456, Avg Regression Loss 0.9200, Avg Classification Loss: 2.7256
2021-05-21 22:59:21 - Epoch: 37, Step: 330/502, Avg Loss: 3.5099, Avg Regression Loss 0.9722, Avg Classification Loss: 2.5377
2021-05-21 22:59:27 - Epoch: 37, Step: 340/502, Avg Loss: 4.9128, Avg Regression Loss 1.7504, Avg Classification Loss: 3.1624
2021-05-21 22:59:32 - Epoch: 37, Step: 350/502, Avg Loss: 3.8906, Avg Regression Loss 1.1508, Avg Classification Loss: 2.7398
2021-05-21 22:59:37 - Epoch: 37, Step: 360/502, Avg Loss: 4.1164, Avg Regression Loss 1.2018, Avg Classification Loss: 2.9146
2021-05-21 22:59:42 - Epoch: 37, Step: 370/502, Avg Loss: 4.2784, Avg Regression Loss 1.4965, Avg Classification Loss: 2.7818
2021-05-21 22:59:46 - Epoch: 37, Step: 380/502, Avg Loss: 4.1121, Avg Regression Loss 1.3265, Avg Classification Loss: 2.7856
2021-05-21 22:59:51 - Epoch: 37, Step: 390/502, Avg Loss: 5.0563, Avg Regression Loss 2.0490, Avg Classification Loss: 3.0074
2021-05-21 22:59:56 - Epoch: 37, Step: 400/502, Avg Loss: 3.7218, Avg Regression Loss 1.0464, Avg Classification Loss: 2.6754
2021-05-21 23:00:01 - Epoch: 37, Step: 410/502, Avg Loss: 3.7061, Avg Regression Loss 1.0104, Avg Classification Loss: 2.6957
2021-05-21 23:00:05 - Epoch: 37, Step: 420/502, Avg Loss: 3.5742, Avg Regression Loss 0.7673, Avg Classification Loss: 2.8069
2021-05-21 23:00:10 - Epoch: 37, Step: 430/502, Avg Loss: 3.2915, Avg Regression Loss 0.7944, Avg Classification Loss: 2.4971
2021-05-21 23:00:15 - Epoch: 37, Step: 440/502, Avg Loss: 4.1349, Avg Regression Loss 1.3360, Avg Classification Loss: 2.7989
2021-05-21 23:00:19 - Epoch: 37, Step: 450/502, Avg Loss: 3.7760, Avg Regression Loss 0.9556, Avg Classification Loss: 2.8204
2021-05-21 23:00:26 - Epoch: 37, Step: 460/502, Avg Loss: 4.7119, Avg Regression Loss 1.7690, Avg Classification Loss: 2.9430
2021-05-21 23:00:30 - Epoch: 37, Step: 470/502, Avg Loss: 3.9515, Avg Regression Loss 1.4012, Avg Classification Loss: 2.5503
2021-05-21 23:00:35 - Epoch: 37, Step: 480/502, Avg Loss: 4.3357, Avg Regression Loss 1.3523, Avg Classification Loss: 2.9834
2021-05-21 23:00:40 - Epoch: 37, Step: 490/502, Avg Loss: 4.6225, Avg Regression Loss 1.5416, Avg Classification Loss: 3.0809
2021-05-21 23:00:44 - Epoch: 37, Step: 500/502, Avg Loss: 3.4547, Avg Regression Loss 0.8331, Avg Classification Loss: 2.6216
2021-05-21 23:01:46 - Epoch: 37, Validation Loss: 3.7298, Validation Regression Loss 1.0601, Validation Classification Loss: 2.6697
2021-05-21 23:01:46 - Saved model models/smd/mb1-ssd-Epoch-37-Loss-3.7298340721434333.pth
2021-05-21 23:01:52 - Epoch: 38, Step: 10/502, Avg Loss: 4.9535, Avg Regression Loss 1.9492, Avg Classification Loss: 3.0042
2021-05-21 23:01:57 - Epoch: 38, Step: 20/502, Avg Loss: 3.8005, Avg Regression Loss 1.1378, Avg Classification Loss: 2.6627
2021-05-21 23:02:03 - Epoch: 38, Step: 30/502, Avg Loss: 3.7702, Avg Regression Loss 1.1183, Avg Classification Loss: 2.6519
2021-05-21 23:02:08 - Epoch: 38, Step: 40/502, Avg Loss: 4.0991, Avg Regression Loss 1.1847, Avg Classification Loss: 2.9144
2021-05-21 23:02:13 - Epoch: 38, Step: 50/502, Avg Loss: 4.1724, Avg Regression Loss 1.3833, Avg Classification Loss: 2.7891
2021-05-21 23:02:21 - Epoch: 38, Step: 60/502, Avg Loss: 4.6445, Avg Regression Loss 1.7966, Avg Classification Loss: 2.8480
2021-05-21 23:02:26 - Epoch: 38, Step: 70/502, Avg Loss: 4.2611, Avg Regression Loss 1.5717, Avg Classification Loss: 2.6893
2021-05-21 23:02:30 - Epoch: 38, Step: 80/502, Avg Loss: 4.2955, Avg Regression Loss 1.3130, Avg Classification Loss: 2.9825
2021-05-21 23:02:38 - Epoch: 38, Step: 90/502, Avg Loss: 4.3000, Avg Regression Loss 1.4600, Avg Classification Loss: 2.8400
2021-05-21 23:02:47 - Epoch: 38, Step: 100/502, Avg Loss: 3.6396, Avg Regression Loss 0.9575, Avg Classification Loss: 2.6821
2021-05-21 23:02:53 - Epoch: 38, Step: 110/502, Avg Loss: 4.8503, Avg Regression Loss 1.8935, Avg Classification Loss: 2.9568
2021-05-21 23:02:57 - Epoch: 38, Step: 120/502, Avg Loss: 4.1489, Avg Regression Loss 1.3660, Avg Classification Loss: 2.7829
2021-05-21 23:03:02 - Epoch: 38, Step: 130/502, Avg Loss: 3.6592, Avg Regression Loss 0.9624, Avg Classification Loss: 2.6968
2021-05-21 23:03:09 - Epoch: 38, Step: 140/502, Avg Loss: 4.4680, Avg Regression Loss 1.6336, Avg Classification Loss: 2.8344
2021-05-21 23:03:15 - Epoch: 38, Step: 150/502, Avg Loss: 4.3606, Avg Regression Loss 1.4434, Avg Classification Loss: 2.9172
2021-05-21 23:03:20 - Epoch: 38, Step: 160/502, Avg Loss: 5.2771, Avg Regression Loss 2.1925, Avg Classification Loss: 3.0846
2021-05-21 23:03:26 - Epoch: 38, Step: 170/502, Avg Loss: 4.8455, Avg Regression Loss 1.8529, Avg Classification Loss: 2.9926
2021-05-21 23:03:31 - Epoch: 38, Step: 180/502, Avg Loss: 3.7570, Avg Regression Loss 1.1055, Avg Classification Loss: 2.6515
2021-05-21 23:03:37 - Epoch: 38, Step: 190/502, Avg Loss: 3.5829, Avg Regression Loss 1.0235, Avg Classification Loss: 2.5594
2021-05-21 23:03:46 - Epoch: 38, Step: 200/502, Avg Loss: 4.5541, Avg Regression Loss 1.4801, Avg Classification Loss: 3.0740
2021-05-21 23:03:51 - Epoch: 38, Step: 210/502, Avg Loss: 4.1673, Avg Regression Loss 1.3355, Avg Classification Loss: 2.8318
2021-05-21 23:03:57 - Epoch: 38, Step: 220/502, Avg Loss: 3.9843, Avg Regression Loss 1.1724, Avg Classification Loss: 2.8119
2021-05-21 23:04:02 - Epoch: 38, Step: 230/502, Avg Loss: 4.3532, Avg Regression Loss 1.5648, Avg Classification Loss: 2.7884
2021-05-21 23:04:07 - Epoch: 38, Step: 240/502, Avg Loss: 3.8706, Avg Regression Loss 1.0937, Avg Classification Loss: 2.7769
2021-05-21 23:04:12 - Epoch: 38, Step: 250/502, Avg Loss: 3.9241, Avg Regression Loss 1.1906, Avg Classification Loss: 2.7335
2021-05-21 23:04:16 - Epoch: 38, Step: 260/502, Avg Loss: 4.0241, Avg Regression Loss 1.2712, Avg Classification Loss: 2.7529
2021-05-21 23:04:21 - Epoch: 38, Step: 270/502, Avg Loss: 4.1404, Avg Regression Loss 1.2288, Avg Classification Loss: 2.9116
2021-05-21 23:04:26 - Epoch: 38, Step: 280/502, Avg Loss: 4.5374, Avg Regression Loss 1.5698, Avg Classification Loss: 2.9676
2021-05-21 23:04:32 - Epoch: 38, Step: 290/502, Avg Loss: 4.8162, Avg Regression Loss 1.7523, Avg Classification Loss: 3.0639
2021-05-21 23:04:37 - Epoch: 38, Step: 300/502, Avg Loss: 3.6716, Avg Regression Loss 1.0829, Avg Classification Loss: 2.5887
2021-05-21 23:04:42 - Epoch: 38, Step: 310/502, Avg Loss: 3.9477, Avg Regression Loss 1.2656, Avg Classification Loss: 2.6821
2021-05-21 23:04:46 - Epoch: 38, Step: 320/502, Avg Loss: 3.8137, Avg Regression Loss 1.0383, Avg Classification Loss: 2.7754
2021-05-21 23:04:51 - Epoch: 38, Step: 330/502, Avg Loss: 3.8000, Avg Regression Loss 1.0922, Avg Classification Loss: 2.7078
2021-05-21 23:04:56 - Epoch: 38, Step: 340/502, Avg Loss: 3.8629, Avg Regression Loss 1.2941, Avg Classification Loss: 2.5687
2021-05-21 23:05:01 - Epoch: 38, Step: 350/502, Avg Loss: 3.8834, Avg Regression Loss 1.2692, Avg Classification Loss: 2.6141
2021-05-21 23:05:06 - Epoch: 38, Step: 360/502, Avg Loss: 3.9265, Avg Regression Loss 1.2484, Avg Classification Loss: 2.6782
2021-05-21 23:05:10 - Epoch: 38, Step: 370/502, Avg Loss: 3.6670, Avg Regression Loss 1.1017, Avg Classification Loss: 2.5653
2021-05-21 23:05:17 - Epoch: 38, Step: 380/502, Avg Loss: 4.3231, Avg Regression Loss 1.4023, Avg Classification Loss: 2.9207
2021-05-21 23:05:22 - Epoch: 38, Step: 390/502, Avg Loss: 4.0044, Avg Regression Loss 1.4004, Avg Classification Loss: 2.6040
2021-05-21 23:05:27 - Epoch: 38, Step: 400/502, Avg Loss: 3.8306, Avg Regression Loss 1.1158, Avg Classification Loss: 2.7147
2021-05-21 23:05:31 - Epoch: 38, Step: 410/502, Avg Loss: 4.2352, Avg Regression Loss 1.1622, Avg Classification Loss: 3.0731
2021-05-21 23:05:37 - Epoch: 38, Step: 420/502, Avg Loss: 4.0751, Avg Regression Loss 1.2088, Avg Classification Loss: 2.8663
2021-05-21 23:05:43 - Epoch: 38, Step: 430/502, Avg Loss: 5.0562, Avg Regression Loss 1.9046, Avg Classification Loss: 3.1517
2021-05-21 23:05:47 - Epoch: 38, Step: 440/502, Avg Loss: 4.4445, Avg Regression Loss 1.6290, Avg Classification Loss: 2.8155
2021-05-21 23:05:52 - Epoch: 38, Step: 450/502, Avg Loss: 4.2831, Avg Regression Loss 1.2668, Avg Classification Loss: 3.0163
2021-05-21 23:05:59 - Epoch: 38, Step: 460/502, Avg Loss: 4.0626, Avg Regression Loss 1.4340, Avg Classification Loss: 2.6285
2021-05-21 23:06:04 - Epoch: 38, Step: 470/502, Avg Loss: 4.9703, Avg Regression Loss 1.8101, Avg Classification Loss: 3.1603
2021-05-21 23:06:08 - Epoch: 38, Step: 480/502, Avg Loss: 4.4163, Avg Regression Loss 1.5244, Avg Classification Loss: 2.8919
2021-05-21 23:06:15 - Epoch: 38, Step: 490/502, Avg Loss: 4.6044, Avg Regression Loss 1.8143, Avg Classification Loss: 2.7902
2021-05-21 23:06:19 - Epoch: 38, Step: 500/502, Avg Loss: 3.9981, Avg Regression Loss 1.0950, Avg Classification Loss: 2.9031
2021-05-21 23:07:20 - Epoch: 38, Validation Loss: 3.3123, Validation Regression Loss 0.7990, Validation Classification Loss: 2.5133
2021-05-21 23:07:20 - Saved model models/smd/mb1-ssd-Epoch-38-Loss-3.312284255882658.pth
2021-05-21 23:07:26 - Epoch: 39, Step: 10/502, Avg Loss: 4.5300, Avg Regression Loss 1.4554, Avg Classification Loss: 3.0746
2021-05-21 23:07:34 - Epoch: 39, Step: 20/502, Avg Loss: 4.5555, Avg Regression Loss 1.6164, Avg Classification Loss: 2.9391
2021-05-21 23:07:39 - Epoch: 39, Step: 30/502, Avg Loss: 3.6212, Avg Regression Loss 1.1375, Avg Classification Loss: 2.4837
2021-05-21 23:07:44 - Epoch: 39, Step: 40/502, Avg Loss: 3.6750, Avg Regression Loss 0.9193, Avg Classification Loss: 2.7557
2021-05-21 23:07:49 - Epoch: 39, Step: 50/502, Avg Loss: 3.4716, Avg Regression Loss 0.9868, Avg Classification Loss: 2.4848
2021-05-21 23:07:55 - Epoch: 39, Step: 60/502, Avg Loss: 3.6925, Avg Regression Loss 1.1012, Avg Classification Loss: 2.5914
2021-05-21 23:08:00 - Epoch: 39, Step: 70/502, Avg Loss: 3.9815, Avg Regression Loss 1.0440, Avg Classification Loss: 2.9375
2021-05-21 23:08:05 - Epoch: 39, Step: 80/502, Avg Loss: 4.0907, Avg Regression Loss 1.3161, Avg Classification Loss: 2.7746
2021-05-21 23:08:11 - Epoch: 39, Step: 90/502, Avg Loss: 3.9189, Avg Regression Loss 0.9536, Avg Classification Loss: 2.9652
2021-05-21 23:08:22 - Epoch: 39, Step: 100/502, Avg Loss: 4.1103, Avg Regression Loss 1.1921, Avg Classification Loss: 2.9182
2021-05-21 23:08:27 - Epoch: 39, Step: 110/502, Avg Loss: 4.4612, Avg Regression Loss 1.5801, Avg Classification Loss: 2.8811
2021-05-21 23:08:33 - Epoch: 39, Step: 120/502, Avg Loss: 4.1679, Avg Regression Loss 1.6055, Avg Classification Loss: 2.5624
2021-05-21 23:08:38 - Epoch: 39, Step: 130/502, Avg Loss: 3.3029, Avg Regression Loss 0.9382, Avg Classification Loss: 2.3647
2021-05-21 23:08:43 - Epoch: 39, Step: 140/502, Avg Loss: 4.2064, Avg Regression Loss 1.5640, Avg Classification Loss: 2.6423
2021-05-21 23:08:47 - Epoch: 39, Step: 150/502, Avg Loss: 4.1411, Avg Regression Loss 1.6228, Avg Classification Loss: 2.5183
2021-05-21 23:08:53 - Epoch: 39, Step: 160/502, Avg Loss: 4.1765, Avg Regression Loss 1.3764, Avg Classification Loss: 2.8001
2021-05-21 23:08:58 - Epoch: 39, Step: 170/502, Avg Loss: 3.5157, Avg Regression Loss 0.9232, Avg Classification Loss: 2.5925
2021-05-21 23:09:02 - Epoch: 39, Step: 180/502, Avg Loss: 3.9146, Avg Regression Loss 1.2610, Avg Classification Loss: 2.6537
2021-05-21 23:09:07 - Epoch: 39, Step: 190/502, Avg Loss: 3.8963, Avg Regression Loss 1.2072, Avg Classification Loss: 2.6891
2021-05-21 23:09:12 - Epoch: 39, Step: 200/502, Avg Loss: 4.3689, Avg Regression Loss 1.6207, Avg Classification Loss: 2.7481
2021-05-21 23:09:26 - Epoch: 39, Step: 210/502, Avg Loss: 4.5653, Avg Regression Loss 1.6641, Avg Classification Loss: 2.9012
2021-05-21 23:09:31 - Epoch: 39, Step: 220/502, Avg Loss: 4.1650, Avg Regression Loss 1.4192, Avg Classification Loss: 2.7458
2021-05-21 23:09:37 - Epoch: 39, Step: 230/502, Avg Loss: 3.7906, Avg Regression Loss 1.2158, Avg Classification Loss: 2.5748
2021-05-21 23:09:42 - Epoch: 39, Step: 240/502, Avg Loss: 4.0145, Avg Regression Loss 1.2426, Avg Classification Loss: 2.7719
2021-05-21 23:09:47 - Epoch: 39, Step: 250/502, Avg Loss: 4.6504, Avg Regression Loss 1.3092, Avg Classification Loss: 3.3411
2021-05-21 23:09:52 - Epoch: 39, Step: 260/502, Avg Loss: 3.9221, Avg Regression Loss 1.2828, Avg Classification Loss: 2.6393
2021-05-21 23:09:57 - Epoch: 39, Step: 270/502, Avg Loss: 4.0150, Avg Regression Loss 1.3099, Avg Classification Loss: 2.7051
2021-05-21 23:10:02 - Epoch: 39, Step: 280/502, Avg Loss: 4.3363, Avg Regression Loss 1.5033, Avg Classification Loss: 2.8331
2021-05-21 23:10:07 - Epoch: 39, Step: 290/502, Avg Loss: 3.6823, Avg Regression Loss 1.0894, Avg Classification Loss: 2.5929
2021-05-21 23:10:12 - Epoch: 39, Step: 300/502, Avg Loss: 3.8788, Avg Regression Loss 1.2168, Avg Classification Loss: 2.6620
2021-05-21 23:10:17 - Epoch: 39, Step: 310/502, Avg Loss: 3.7450, Avg Regression Loss 0.9611, Avg Classification Loss: 2.7838
2021-05-21 23:10:22 - Epoch: 39, Step: 320/502, Avg Loss: 4.5560, Avg Regression Loss 1.6935, Avg Classification Loss: 2.8624
2021-05-21 23:10:26 - Epoch: 39, Step: 330/502, Avg Loss: 4.1220, Avg Regression Loss 1.3854, Avg Classification Loss: 2.7367
2021-05-21 23:10:32 - Epoch: 39, Step: 340/502, Avg Loss: 4.0622, Avg Regression Loss 1.2145, Avg Classification Loss: 2.8477
2021-05-21 23:10:37 - Epoch: 39, Step: 350/502, Avg Loss: 3.7562, Avg Regression Loss 1.0553, Avg Classification Loss: 2.7009
2021-05-21 23:10:42 - Epoch: 39, Step: 360/502, Avg Loss: 3.7731, Avg Regression Loss 1.0475, Avg Classification Loss: 2.7256
2021-05-21 23:10:47 - Epoch: 39, Step: 370/502, Avg Loss: 3.9603, Avg Regression Loss 1.1101, Avg Classification Loss: 2.8502
2021-05-21 23:10:52 - Epoch: 39, Step: 380/502, Avg Loss: 3.7431, Avg Regression Loss 1.1716, Avg Classification Loss: 2.5714
2021-05-21 23:10:58 - Epoch: 39, Step: 390/502, Avg Loss: 4.2449, Avg Regression Loss 1.6486, Avg Classification Loss: 2.5963
2021-05-21 23:11:03 - Epoch: 39, Step: 400/502, Avg Loss: 4.5866, Avg Regression Loss 1.6427, Avg Classification Loss: 2.9438
2021-05-21 23:11:07 - Epoch: 39, Step: 410/502, Avg Loss: 3.5844, Avg Regression Loss 1.0839, Avg Classification Loss: 2.5005
2021-05-21 23:11:12 - Epoch: 39, Step: 420/502, Avg Loss: 4.2906, Avg Regression Loss 1.4960, Avg Classification Loss: 2.7946
2021-05-21 23:11:17 - Epoch: 39, Step: 430/502, Avg Loss: 4.4876, Avg Regression Loss 1.8272, Avg Classification Loss: 2.6605
2021-05-21 23:11:22 - Epoch: 39, Step: 440/502, Avg Loss: 4.3190, Avg Regression Loss 1.5706, Avg Classification Loss: 2.7484
2021-05-21 23:11:27 - Epoch: 39, Step: 450/502, Avg Loss: 4.5533, Avg Regression Loss 1.7079, Avg Classification Loss: 2.8454
2021-05-21 23:11:32 - Epoch: 39, Step: 460/502, Avg Loss: 3.0215, Avg Regression Loss 0.6353, Avg Classification Loss: 2.3862
2021-05-21 23:11:38 - Epoch: 39, Step: 470/502, Avg Loss: 3.4753, Avg Regression Loss 0.8256, Avg Classification Loss: 2.6497
2021-05-21 23:11:43 - Epoch: 39, Step: 480/502, Avg Loss: 3.6738, Avg Regression Loss 1.2760, Avg Classification Loss: 2.3978
2021-05-21 23:11:47 - Epoch: 39, Step: 490/502, Avg Loss: 3.9064, Avg Regression Loss 1.3136, Avg Classification Loss: 2.5928
2021-05-21 23:11:52 - Epoch: 39, Step: 500/502, Avg Loss: 4.2284, Avg Regression Loss 1.3983, Avg Classification Loss: 2.8302
2021-05-21 23:12:55 - Epoch: 39, Validation Loss: 3.2923, Validation Regression Loss 0.7740, Validation Classification Loss: 2.5183
2021-05-21 23:12:56 - Saved model models/smd/mb1-ssd-Epoch-39-Loss-3.2923248426847724.pth
2021-05-21 23:13:02 - Epoch: 40, Step: 10/502, Avg Loss: 4.9237, Avg Regression Loss 1.6597, Avg Classification Loss: 3.2639
2021-05-21 23:13:09 - Epoch: 40, Step: 20/502, Avg Loss: 4.4487, Avg Regression Loss 1.4921, Avg Classification Loss: 2.9566
2021-05-21 23:13:15 - Epoch: 40, Step: 30/502, Avg Loss: 4.8886, Avg Regression Loss 1.8658, Avg Classification Loss: 3.0228
2021-05-21 23:13:20 - Epoch: 40, Step: 40/502, Avg Loss: 4.9260, Avg Regression Loss 2.0171, Avg Classification Loss: 2.9089
2021-05-21 23:13:25 - Epoch: 40, Step: 50/502, Avg Loss: 4.0296, Avg Regression Loss 1.4461, Avg Classification Loss: 2.5836
2021-05-21 23:13:29 - Epoch: 40, Step: 60/502, Avg Loss: 4.3079, Avg Regression Loss 1.6340, Avg Classification Loss: 2.6739
2021-05-21 23:13:34 - Epoch: 40, Step: 70/502, Avg Loss: 3.9844, Avg Regression Loss 0.8724, Avg Classification Loss: 3.1120
2021-05-21 23:13:39 - Epoch: 40, Step: 80/502, Avg Loss: 3.8357, Avg Regression Loss 1.0684, Avg Classification Loss: 2.7673
2021-05-21 23:13:44 - Epoch: 40, Step: 90/502, Avg Loss: 4.7020, Avg Regression Loss 1.8458, Avg Classification Loss: 2.8562
2021-05-21 23:13:49 - Epoch: 40, Step: 100/502, Avg Loss: 3.4377, Avg Regression Loss 0.9243, Avg Classification Loss: 2.5133
2021-05-21 23:13:54 - Epoch: 40, Step: 110/502, Avg Loss: 3.9529, Avg Regression Loss 1.0764, Avg Classification Loss: 2.8765
2021-05-21 23:13:59 - Epoch: 40, Step: 120/502, Avg Loss: 4.0821, Avg Regression Loss 1.0594, Avg Classification Loss: 3.0227
2021-05-21 23:14:03 - Epoch: 40, Step: 130/502, Avg Loss: 4.1970, Avg Regression Loss 1.3425, Avg Classification Loss: 2.8545
2021-05-21 23:14:08 - Epoch: 40, Step: 140/502, Avg Loss: 3.7148, Avg Regression Loss 1.0797, Avg Classification Loss: 2.6351
2021-05-21 23:14:19 - Epoch: 40, Step: 150/502, Avg Loss: 3.9607, Avg Regression Loss 1.1941, Avg Classification Loss: 2.7666
2021-05-21 23:14:24 - Epoch: 40, Step: 160/502, Avg Loss: 3.9467, Avg Regression Loss 1.3285, Avg Classification Loss: 2.6181
2021-05-21 23:14:29 - Epoch: 40, Step: 170/502, Avg Loss: 4.4878, Avg Regression Loss 1.7803, Avg Classification Loss: 2.7075
2021-05-21 23:14:34 - Epoch: 40, Step: 180/502, Avg Loss: 4.0811, Avg Regression Loss 1.1788, Avg Classification Loss: 2.9023
2021-05-21 23:14:38 - Epoch: 40, Step: 190/502, Avg Loss: 3.9912, Avg Regression Loss 1.3133, Avg Classification Loss: 2.6779
2021-05-21 23:14:44 - Epoch: 40, Step: 200/502, Avg Loss: 4.1276, Avg Regression Loss 1.3767, Avg Classification Loss: 2.7509
2021-05-21 23:14:49 - Epoch: 40, Step: 210/502, Avg Loss: 3.6493, Avg Regression Loss 1.0514, Avg Classification Loss: 2.5979
2021-05-21 23:14:57 - Epoch: 40, Step: 220/502, Avg Loss: 4.0707, Avg Regression Loss 1.3376, Avg Classification Loss: 2.7331
2021-05-21 23:15:02 - Epoch: 40, Step: 230/502, Avg Loss: 3.9224, Avg Regression Loss 1.2764, Avg Classification Loss: 2.6460
2021-05-21 23:15:07 - Epoch: 40, Step: 240/502, Avg Loss: 4.3965, Avg Regression Loss 1.6252, Avg Classification Loss: 2.7713
2021-05-21 23:15:12 - Epoch: 40, Step: 250/502, Avg Loss: 3.6188, Avg Regression Loss 1.0443, Avg Classification Loss: 2.5745
2021-05-21 23:15:18 - Epoch: 40, Step: 260/502, Avg Loss: 3.7781, Avg Regression Loss 1.1514, Avg Classification Loss: 2.6267
2021-05-21 23:15:23 - Epoch: 40, Step: 270/502, Avg Loss: 4.1263, Avg Regression Loss 1.3660, Avg Classification Loss: 2.7603
2021-05-21 23:15:28 - Epoch: 40, Step: 280/502, Avg Loss: 3.6494, Avg Regression Loss 1.0299, Avg Classification Loss: 2.6195
2021-05-21 23:15:33 - Epoch: 40, Step: 290/502, Avg Loss: 3.5295, Avg Regression Loss 0.9632, Avg Classification Loss: 2.5663
2021-05-21 23:15:38 - Epoch: 40, Step: 300/502, Avg Loss: 4.0860, Avg Regression Loss 1.4201, Avg Classification Loss: 2.6659
2021-05-21 23:15:43 - Epoch: 40, Step: 310/502, Avg Loss: 3.8167, Avg Regression Loss 0.9171, Avg Classification Loss: 2.8996
2021-05-21 23:15:48 - Epoch: 40, Step: 320/502, Avg Loss: 3.6384, Avg Regression Loss 0.8426, Avg Classification Loss: 2.7958
2021-05-21 23:15:54 - Epoch: 40, Step: 330/502, Avg Loss: 4.2636, Avg Regression Loss 1.4710, Avg Classification Loss: 2.7926
2021-05-21 23:15:59 - Epoch: 40, Step: 340/502, Avg Loss: 4.3363, Avg Regression Loss 1.6701, Avg Classification Loss: 2.6662
2021-05-21 23:16:04 - Epoch: 40, Step: 350/502, Avg Loss: 3.7099, Avg Regression Loss 1.2130, Avg Classification Loss: 2.4969
2021-05-21 23:16:09 - Epoch: 40, Step: 360/502, Avg Loss: 3.8036, Avg Regression Loss 1.1355, Avg Classification Loss: 2.6681
2021-05-21 23:16:14 - Epoch: 40, Step: 370/502, Avg Loss: 3.5286, Avg Regression Loss 1.0344, Avg Classification Loss: 2.4942
2021-05-21 23:16:20 - Epoch: 40, Step: 380/502, Avg Loss: 4.2976, Avg Regression Loss 1.4679, Avg Classification Loss: 2.8297
2021-05-21 23:16:25 - Epoch: 40, Step: 390/502, Avg Loss: 3.9406, Avg Regression Loss 1.3833, Avg Classification Loss: 2.5573
2021-05-21 23:16:30 - Epoch: 40, Step: 400/502, Avg Loss: 3.8561, Avg Regression Loss 1.1502, Avg Classification Loss: 2.7059
2021-05-21 23:16:35 - Epoch: 40, Step: 410/502, Avg Loss: 4.1126, Avg Regression Loss 1.2495, Avg Classification Loss: 2.8631
2021-05-21 23:16:40 - Epoch: 40, Step: 420/502, Avg Loss: 4.1964, Avg Regression Loss 1.3763, Avg Classification Loss: 2.8201
2021-05-21 23:16:45 - Epoch: 40, Step: 430/502, Avg Loss: 3.7031, Avg Regression Loss 1.1258, Avg Classification Loss: 2.5774
2021-05-21 23:16:50 - Epoch: 40, Step: 440/502, Avg Loss: 3.5878, Avg Regression Loss 0.9018, Avg Classification Loss: 2.6860
2021-05-21 23:16:57 - Epoch: 40, Step: 450/502, Avg Loss: 4.0673, Avg Regression Loss 1.3477, Avg Classification Loss: 2.7196
2021-05-21 23:17:01 - Epoch: 40, Step: 460/502, Avg Loss: 3.5699, Avg Regression Loss 1.1639, Avg Classification Loss: 2.4060
2021-05-21 23:17:06 - Epoch: 40, Step: 470/502, Avg Loss: 4.2573, Avg Regression Loss 1.4830, Avg Classification Loss: 2.7743
2021-05-21 23:17:11 - Epoch: 40, Step: 480/502, Avg Loss: 4.8625, Avg Regression Loss 2.0135, Avg Classification Loss: 2.8490
2021-05-21 23:17:16 - Epoch: 40, Step: 490/502, Avg Loss: 4.2487, Avg Regression Loss 1.4383, Avg Classification Loss: 2.8104
2021-05-21 23:17:22 - Epoch: 40, Step: 500/502, Avg Loss: 4.4788, Avg Regression Loss 1.6487, Avg Classification Loss: 2.8301
2021-05-21 23:18:21 - Epoch: 40, Validation Loss: 3.6264, Validation Regression Loss 0.8310, Validation Classification Loss: 2.7954
2021-05-21 23:18:21 - Saved model models/smd/mb1-ssd-Epoch-40-Loss-3.6264265436100294.pth
2021-05-21 23:18:28 - Epoch: 41, Step: 10/502, Avg Loss: 4.3375, Avg Regression Loss 1.1595, Avg Classification Loss: 3.1780
2021-05-21 23:18:34 - Epoch: 41, Step: 20/502, Avg Loss: 4.2566, Avg Regression Loss 1.3402, Avg Classification Loss: 2.9163
2021-05-21 23:18:40 - Epoch: 41, Step: 30/502, Avg Loss: 4.6409, Avg Regression Loss 1.6002, Avg Classification Loss: 3.0406
2021-05-21 23:18:44 - Epoch: 41, Step: 40/502, Avg Loss: 4.3315, Avg Regression Loss 1.4040, Avg Classification Loss: 2.9275
2021-05-21 23:18:49 - Epoch: 41, Step: 50/502, Avg Loss: 3.8042, Avg Regression Loss 1.1205, Avg Classification Loss: 2.6837
2021-05-21 23:18:54 - Epoch: 41, Step: 60/502, Avg Loss: 3.4254, Avg Regression Loss 0.8465, Avg Classification Loss: 2.5790
2021-05-21 23:18:58 - Epoch: 41, Step: 70/502, Avg Loss: 3.9224, Avg Regression Loss 1.1760, Avg Classification Loss: 2.7464
2021-05-21 23:19:03 - Epoch: 41, Step: 80/502, Avg Loss: 3.7708, Avg Regression Loss 1.0504, Avg Classification Loss: 2.7204
2021-05-21 23:19:09 - Epoch: 41, Step: 90/502, Avg Loss: 4.1341, Avg Regression Loss 1.4299, Avg Classification Loss: 2.7042
2021-05-21 23:19:15 - Epoch: 41, Step: 100/502, Avg Loss: 3.4284, Avg Regression Loss 1.1305, Avg Classification Loss: 2.2980
2021-05-21 23:19:20 - Epoch: 41, Step: 110/502, Avg Loss: 4.2163, Avg Regression Loss 1.3408, Avg Classification Loss: 2.8755
2021-05-21 23:19:32 - Epoch: 41, Step: 120/502, Avg Loss: 4.4639, Avg Regression Loss 1.6468, Avg Classification Loss: 2.8171
2021-05-21 23:19:37 - Epoch: 41, Step: 130/502, Avg Loss: 4.0251, Avg Regression Loss 1.2975, Avg Classification Loss: 2.7276
2021-05-21 23:19:42 - Epoch: 41, Step: 140/502, Avg Loss: 4.3865, Avg Regression Loss 1.6344, Avg Classification Loss: 2.7521
2021-05-21 23:19:47 - Epoch: 41, Step: 150/502, Avg Loss: 3.8095, Avg Regression Loss 1.1335, Avg Classification Loss: 2.6760
2021-05-21 23:19:58 - Epoch: 41, Step: 160/502, Avg Loss: 3.7292, Avg Regression Loss 1.0912, Avg Classification Loss: 2.6380
2021-05-21 23:20:04 - Epoch: 41, Step: 170/502, Avg Loss: 4.7702, Avg Regression Loss 1.9944, Avg Classification Loss: 2.7758
2021-05-21 23:20:08 - Epoch: 41, Step: 180/502, Avg Loss: 3.7490, Avg Regression Loss 1.2259, Avg Classification Loss: 2.5231
2021-05-21 23:20:13 - Epoch: 41, Step: 190/502, Avg Loss: 4.5618, Avg Regression Loss 1.7083, Avg Classification Loss: 2.8536
2021-05-21 23:20:18 - Epoch: 41, Step: 200/502, Avg Loss: 4.2027, Avg Regression Loss 1.1457, Avg Classification Loss: 3.0570
2021-05-21 23:20:23 - Epoch: 41, Step: 210/502, Avg Loss: 3.8130, Avg Regression Loss 1.1454, Avg Classification Loss: 2.6676
2021-05-21 23:20:28 - Epoch: 41, Step: 220/502, Avg Loss: 4.1309, Avg Regression Loss 1.4298, Avg Classification Loss: 2.7011
2021-05-21 23:20:33 - Epoch: 41, Step: 230/502, Avg Loss: 4.1971, Avg Regression Loss 1.4780, Avg Classification Loss: 2.7191
2021-05-21 23:20:38 - Epoch: 41, Step: 240/502, Avg Loss: 4.3038, Avg Regression Loss 1.5686, Avg Classification Loss: 2.7352
2021-05-21 23:20:44 - Epoch: 41, Step: 250/502, Avg Loss: 4.0069, Avg Regression Loss 1.1894, Avg Classification Loss: 2.8176
2021-05-21 23:20:48 - Epoch: 41, Step: 260/502, Avg Loss: 4.1803, Avg Regression Loss 1.2378, Avg Classification Loss: 2.9424
2021-05-21 23:20:53 - Epoch: 41, Step: 270/502, Avg Loss: 3.7548, Avg Regression Loss 1.0153, Avg Classification Loss: 2.7394
2021-05-21 23:20:58 - Epoch: 41, Step: 280/502, Avg Loss: 3.7472, Avg Regression Loss 1.0556, Avg Classification Loss: 2.6916
2021-05-21 23:21:02 - Epoch: 41, Step: 290/502, Avg Loss: 4.2869, Avg Regression Loss 1.5048, Avg Classification Loss: 2.7822
2021-05-21 23:21:10 - Epoch: 41, Step: 300/502, Avg Loss: 3.6118, Avg Regression Loss 1.2698, Avg Classification Loss: 2.3420
2021-05-21 23:21:15 - Epoch: 41, Step: 310/502, Avg Loss: 3.3683, Avg Regression Loss 0.8790, Avg Classification Loss: 2.4893
2021-05-21 23:21:19 - Epoch: 41, Step: 320/502, Avg Loss: 3.8808, Avg Regression Loss 1.1759, Avg Classification Loss: 2.7049
2021-05-21 23:21:24 - Epoch: 41, Step: 330/502, Avg Loss: 3.3702, Avg Regression Loss 0.8761, Avg Classification Loss: 2.4941
2021-05-21 23:21:29 - Epoch: 41, Step: 340/502, Avg Loss: 4.0120, Avg Regression Loss 1.3048, Avg Classification Loss: 2.7072
2021-05-21 23:21:34 - Epoch: 41, Step: 350/502, Avg Loss: 3.7158, Avg Regression Loss 0.9761, Avg Classification Loss: 2.7396
2021-05-21 23:21:39 - Epoch: 41, Step: 360/502, Avg Loss: 4.2120, Avg Regression Loss 1.2135, Avg Classification Loss: 2.9985
2021-05-21 23:21:44 - Epoch: 41, Step: 370/502, Avg Loss: 3.5731, Avg Regression Loss 0.8836, Avg Classification Loss: 2.6895
2021-05-21 23:21:49 - Epoch: 41, Step: 380/502, Avg Loss: 3.5668, Avg Regression Loss 1.1376, Avg Classification Loss: 2.4292
2021-05-21 23:21:55 - Epoch: 41, Step: 390/502, Avg Loss: 4.6618, Avg Regression Loss 1.8184, Avg Classification Loss: 2.8434
2021-05-21 23:22:00 - Epoch: 41, Step: 400/502, Avg Loss: 3.6150, Avg Regression Loss 1.0569, Avg Classification Loss: 2.5581
2021-05-21 23:22:05 - Epoch: 41, Step: 410/502, Avg Loss: 4.2870, Avg Regression Loss 1.4323, Avg Classification Loss: 2.8547
2021-05-21 23:22:10 - Epoch: 41, Step: 420/502, Avg Loss: 3.3521, Avg Regression Loss 0.9483, Avg Classification Loss: 2.4039
2021-05-21 23:22:15 - Epoch: 41, Step: 430/502, Avg Loss: 3.7778, Avg Regression Loss 1.0657, Avg Classification Loss: 2.7121
2021-05-21 23:22:20 - Epoch: 41, Step: 440/502, Avg Loss: 3.9808, Avg Regression Loss 1.3921, Avg Classification Loss: 2.5886
2021-05-21 23:22:25 - Epoch: 41, Step: 450/502, Avg Loss: 4.5402, Avg Regression Loss 1.7123, Avg Classification Loss: 2.8279
2021-05-21 23:22:31 - Epoch: 41, Step: 460/502, Avg Loss: 4.7068, Avg Regression Loss 1.7177, Avg Classification Loss: 2.9891
2021-05-21 23:22:39 - Epoch: 41, Step: 470/502, Avg Loss: 4.5175, Avg Regression Loss 1.5073, Avg Classification Loss: 3.0102
2021-05-21 23:22:44 - Epoch: 41, Step: 480/502, Avg Loss: 3.2870, Avg Regression Loss 0.7336, Avg Classification Loss: 2.5534
2021-05-21 23:22:49 - Epoch: 41, Step: 490/502, Avg Loss: 3.8707, Avg Regression Loss 1.1788, Avg Classification Loss: 2.6919
2021-05-21 23:22:54 - Epoch: 41, Step: 500/502, Avg Loss: 3.7952, Avg Regression Loss 1.3338, Avg Classification Loss: 2.4614
2021-05-21 23:23:55 - Epoch: 41, Validation Loss: 3.3652, Validation Regression Loss 0.8452, Validation Classification Loss: 2.5200
2021-05-21 23:23:56 - Saved model models/smd/mb1-ssd-Epoch-41-Loss-3.3652198613877315.pth
2021-05-21 23:24:02 - Epoch: 42, Step: 10/502, Avg Loss: 3.8924, Avg Regression Loss 1.2160, Avg Classification Loss: 2.6764
2021-05-21 23:24:09 - Epoch: 42, Step: 20/502, Avg Loss: 4.3557, Avg Regression Loss 1.6604, Avg Classification Loss: 2.6953
2021-05-21 23:24:14 - Epoch: 42, Step: 30/502, Avg Loss: 4.4593, Avg Regression Loss 1.4137, Avg Classification Loss: 3.0456
2021-05-21 23:24:18 - Epoch: 42, Step: 40/502, Avg Loss: 3.7206, Avg Regression Loss 0.8923, Avg Classification Loss: 2.8283
2021-05-21 23:24:23 - Epoch: 42, Step: 50/502, Avg Loss: 3.3620, Avg Regression Loss 0.8647, Avg Classification Loss: 2.4973
2021-05-21 23:24:28 - Epoch: 42, Step: 60/502, Avg Loss: 3.9695, Avg Regression Loss 1.2464, Avg Classification Loss: 2.7232
2021-05-21 23:24:33 - Epoch: 42, Step: 70/502, Avg Loss: 4.3519, Avg Regression Loss 1.4090, Avg Classification Loss: 2.9429
2021-05-21 23:24:37 - Epoch: 42, Step: 80/502, Avg Loss: 4.4020, Avg Regression Loss 1.5963, Avg Classification Loss: 2.8057
2021-05-21 23:24:43 - Epoch: 42, Step: 90/502, Avg Loss: 4.0727, Avg Regression Loss 1.2231, Avg Classification Loss: 2.8495
2021-05-21 23:24:53 - Epoch: 42, Step: 100/502, Avg Loss: 3.9691, Avg Regression Loss 1.4061, Avg Classification Loss: 2.5629
2021-05-21 23:25:06 - Epoch: 42, Step: 110/502, Avg Loss: 4.3396, Avg Regression Loss 1.5543, Avg Classification Loss: 2.7853
2021-05-21 23:25:12 - Epoch: 42, Step: 120/502, Avg Loss: 3.7867, Avg Regression Loss 1.0669, Avg Classification Loss: 2.7198
2021-05-21 23:25:16 - Epoch: 42, Step: 130/502, Avg Loss: 3.6216, Avg Regression Loss 0.8874, Avg Classification Loss: 2.7342
2021-05-21 23:25:21 - Epoch: 42, Step: 140/502, Avg Loss: 4.3769, Avg Regression Loss 1.4581, Avg Classification Loss: 2.9188
2021-05-21 23:25:26 - Epoch: 42, Step: 150/502, Avg Loss: 4.2545, Avg Regression Loss 1.3585, Avg Classification Loss: 2.8960
2021-05-21 23:25:31 - Epoch: 42, Step: 160/502, Avg Loss: 4.0492, Avg Regression Loss 1.3455, Avg Classification Loss: 2.7037
2021-05-21 23:25:37 - Epoch: 42, Step: 170/502, Avg Loss: 4.0567, Avg Regression Loss 1.2809, Avg Classification Loss: 2.7757
2021-05-21 23:25:42 - Epoch: 42, Step: 180/502, Avg Loss: 3.7548, Avg Regression Loss 1.0765, Avg Classification Loss: 2.6783
2021-05-21 23:25:47 - Epoch: 42, Step: 190/502, Avg Loss: 3.4340, Avg Regression Loss 0.6463, Avg Classification Loss: 2.7877
2021-05-21 23:25:52 - Epoch: 42, Step: 200/502, Avg Loss: 4.5449, Avg Regression Loss 1.8627, Avg Classification Loss: 2.6821
2021-05-21 23:25:56 - Epoch: 42, Step: 210/502, Avg Loss: 3.0828, Avg Regression Loss 0.6097, Avg Classification Loss: 2.4730
2021-05-21 23:26:02 - Epoch: 42, Step: 220/502, Avg Loss: 3.6685, Avg Regression Loss 0.9885, Avg Classification Loss: 2.6800
2021-05-21 23:26:09 - Epoch: 42, Step: 230/502, Avg Loss: 4.1959, Avg Regression Loss 1.5022, Avg Classification Loss: 2.6938
2021-05-21 23:26:14 - Epoch: 42, Step: 240/502, Avg Loss: 4.2666, Avg Regression Loss 1.3102, Avg Classification Loss: 2.9564
2021-05-21 23:26:19 - Epoch: 42, Step: 250/502, Avg Loss: 3.9348, Avg Regression Loss 1.2679, Avg Classification Loss: 2.6670
2021-05-21 23:26:24 - Epoch: 42, Step: 260/502, Avg Loss: 3.9779, Avg Regression Loss 1.3751, Avg Classification Loss: 2.6029
2021-05-21 23:26:29 - Epoch: 42, Step: 270/502, Avg Loss: 3.4628, Avg Regression Loss 0.9107, Avg Classification Loss: 2.5521
2021-05-21 23:26:34 - Epoch: 42, Step: 280/502, Avg Loss: 4.1376, Avg Regression Loss 1.3875, Avg Classification Loss: 2.7501
2021-05-21 23:26:38 - Epoch: 42, Step: 290/502, Avg Loss: 4.0611, Avg Regression Loss 1.3498, Avg Classification Loss: 2.7113
2021-05-21 23:26:48 - Epoch: 42, Step: 300/502, Avg Loss: 4.1395, Avg Regression Loss 1.0583, Avg Classification Loss: 3.0812
2021-05-21 23:26:53 - Epoch: 42, Step: 310/502, Avg Loss: 3.8429, Avg Regression Loss 1.1683, Avg Classification Loss: 2.6746
2021-05-21 23:26:59 - Epoch: 42, Step: 320/502, Avg Loss: 4.1479, Avg Regression Loss 1.1660, Avg Classification Loss: 2.9819
2021-05-21 23:27:03 - Epoch: 42, Step: 330/502, Avg Loss: 3.5094, Avg Regression Loss 0.9232, Avg Classification Loss: 2.5862
2021-05-21 23:27:10 - Epoch: 42, Step: 340/502, Avg Loss: 4.8834, Avg Regression Loss 1.6265, Avg Classification Loss: 3.2569
2021-05-21 23:27:15 - Epoch: 42, Step: 350/502, Avg Loss: 4.2754, Avg Regression Loss 1.4270, Avg Classification Loss: 2.8483
2021-05-21 23:27:21 - Epoch: 42, Step: 360/502, Avg Loss: 4.4455, Avg Regression Loss 1.5452, Avg Classification Loss: 2.9002
2021-05-21 23:27:29 - Epoch: 42, Step: 370/502, Avg Loss: 3.4201, Avg Regression Loss 1.0280, Avg Classification Loss: 2.3921
2021-05-21 23:27:35 - Epoch: 42, Step: 380/502, Avg Loss: 4.3836, Avg Regression Loss 1.4504, Avg Classification Loss: 2.9332
2021-05-21 23:27:41 - Epoch: 42, Step: 390/502, Avg Loss: 4.1065, Avg Regression Loss 1.2407, Avg Classification Loss: 2.8658
2021-05-21 23:27:46 - Epoch: 42, Step: 400/502, Avg Loss: 4.0101, Avg Regression Loss 1.2779, Avg Classification Loss: 2.7321
2021-05-21 23:27:51 - Epoch: 42, Step: 410/502, Avg Loss: 3.7950, Avg Regression Loss 0.8858, Avg Classification Loss: 2.9092
2021-05-21 23:27:57 - Epoch: 42, Step: 420/502, Avg Loss: 4.0841, Avg Regression Loss 1.4357, Avg Classification Loss: 2.6484
2021-05-21 23:28:02 - Epoch: 42, Step: 430/502, Avg Loss: 4.2603, Avg Regression Loss 1.7353, Avg Classification Loss: 2.5249
2021-05-21 23:28:06 - Epoch: 42, Step: 440/502, Avg Loss: 3.7234, Avg Regression Loss 1.0892, Avg Classification Loss: 2.6343
2021-05-21 23:28:11 - Epoch: 42, Step: 450/502, Avg Loss: 3.8583, Avg Regression Loss 1.2204, Avg Classification Loss: 2.6379
2021-05-21 23:28:16 - Epoch: 42, Step: 460/502, Avg Loss: 3.6255, Avg Regression Loss 1.0819, Avg Classification Loss: 2.5436
2021-05-21 23:28:22 - Epoch: 42, Step: 470/502, Avg Loss: 3.3489, Avg Regression Loss 0.8693, Avg Classification Loss: 2.4797
2021-05-21 23:28:27 - Epoch: 42, Step: 480/502, Avg Loss: 4.3344, Avg Regression Loss 1.5498, Avg Classification Loss: 2.7846
2021-05-21 23:28:31 - Epoch: 42, Step: 490/502, Avg Loss: 3.5645, Avg Regression Loss 0.9990, Avg Classification Loss: 2.5655
2021-05-21 23:28:37 - Epoch: 42, Step: 500/502, Avg Loss: 4.3240, Avg Regression Loss 1.4931, Avg Classification Loss: 2.8308
2021-05-21 23:29:38 - Epoch: 42, Validation Loss: 3.2234, Validation Regression Loss 0.7886, Validation Classification Loss: 2.4347
2021-05-21 23:29:38 - Saved model models/smd/mb1-ssd-Epoch-42-Loss-3.223350816751381.pth
2021-05-21 23:29:44 - Epoch: 43, Step: 10/502, Avg Loss: 4.8771, Avg Regression Loss 1.7172, Avg Classification Loss: 3.1599
2021-05-21 23:29:51 - Epoch: 43, Step: 20/502, Avg Loss: 3.6601, Avg Regression Loss 1.2144, Avg Classification Loss: 2.4457
2021-05-21 23:29:59 - Epoch: 43, Step: 30/502, Avg Loss: 4.2290, Avg Regression Loss 1.5768, Avg Classification Loss: 2.6522
2021-05-21 23:30:04 - Epoch: 43, Step: 40/502, Avg Loss: 3.9157, Avg Regression Loss 1.3935, Avg Classification Loss: 2.5222
2021-05-21 23:30:08 - Epoch: 43, Step: 50/502, Avg Loss: 3.4924, Avg Regression Loss 0.9797, Avg Classification Loss: 2.5127
2021-05-21 23:30:13 - Epoch: 43, Step: 60/502, Avg Loss: 3.5165, Avg Regression Loss 0.8949, Avg Classification Loss: 2.6216
2021-05-21 23:30:18 - Epoch: 43, Step: 70/502, Avg Loss: 3.4942, Avg Regression Loss 0.9596, Avg Classification Loss: 2.5346
2021-05-21 23:30:22 - Epoch: 43, Step: 80/502, Avg Loss: 3.7284, Avg Regression Loss 1.2684, Avg Classification Loss: 2.4600
2021-05-21 23:30:28 - Epoch: 43, Step: 90/502, Avg Loss: 3.8343, Avg Regression Loss 1.1551, Avg Classification Loss: 2.6791
2021-05-21 23:30:33 - Epoch: 43, Step: 100/502, Avg Loss: 3.4839, Avg Regression Loss 1.0315, Avg Classification Loss: 2.4523
2021-05-21 23:30:44 - Epoch: 43, Step: 110/502, Avg Loss: 3.8943, Avg Regression Loss 1.2361, Avg Classification Loss: 2.6582
2021-05-21 23:30:49 - Epoch: 43, Step: 120/502, Avg Loss: 4.2280, Avg Regression Loss 1.5278, Avg Classification Loss: 2.7002
2021-05-21 23:30:54 - Epoch: 43, Step: 130/502, Avg Loss: 3.9358, Avg Regression Loss 1.1951, Avg Classification Loss: 2.7407
2021-05-21 23:30:59 - Epoch: 43, Step: 140/502, Avg Loss: 3.5207, Avg Regression Loss 0.8320, Avg Classification Loss: 2.6887
2021-05-21 23:31:04 - Epoch: 43, Step: 150/502, Avg Loss: 4.1625, Avg Regression Loss 1.4912, Avg Classification Loss: 2.6713
2021-05-21 23:31:14 - Epoch: 43, Step: 160/502, Avg Loss: 3.4817, Avg Regression Loss 0.9648, Avg Classification Loss: 2.5169
2021-05-21 23:31:19 - Epoch: 43, Step: 170/502, Avg Loss: 3.7494, Avg Regression Loss 1.3009, Avg Classification Loss: 2.4485
2021-05-21 23:31:24 - Epoch: 43, Step: 180/502, Avg Loss: 4.1642, Avg Regression Loss 1.2423, Avg Classification Loss: 2.9219
2021-05-21 23:31:29 - Epoch: 43, Step: 190/502, Avg Loss: 4.4094, Avg Regression Loss 1.4388, Avg Classification Loss: 2.9706
2021-05-21 23:31:34 - Epoch: 43, Step: 200/502, Avg Loss: 3.7497, Avg Regression Loss 0.8364, Avg Classification Loss: 2.9134
2021-05-21 23:31:39 - Epoch: 43, Step: 210/502, Avg Loss: 3.2771, Avg Regression Loss 0.7804, Avg Classification Loss: 2.4968
2021-05-21 23:31:43 - Epoch: 43, Step: 220/502, Avg Loss: 4.4923, Avg Regression Loss 1.6631, Avg Classification Loss: 2.8292
2021-05-21 23:31:49 - Epoch: 43, Step: 230/502, Avg Loss: 4.2409, Avg Regression Loss 1.4726, Avg Classification Loss: 2.7684
2021-05-21 23:31:54 - Epoch: 43, Step: 240/502, Avg Loss: 4.2225, Avg Regression Loss 1.2754, Avg Classification Loss: 2.9471
2021-05-21 23:31:58 - Epoch: 43, Step: 250/502, Avg Loss: 4.1460, Avg Regression Loss 1.3286, Avg Classification Loss: 2.8175
2021-05-21 23:32:03 - Epoch: 43, Step: 260/502, Avg Loss: 3.7547, Avg Regression Loss 1.2476, Avg Classification Loss: 2.5071
2021-05-21 23:32:08 - Epoch: 43, Step: 270/502, Avg Loss: 4.1934, Avg Regression Loss 1.5358, Avg Classification Loss: 2.6576
2021-05-21 23:32:13 - Epoch: 43, Step: 280/502, Avg Loss: 4.1038, Avg Regression Loss 1.4237, Avg Classification Loss: 2.6802
2021-05-21 23:32:18 - Epoch: 43, Step: 290/502, Avg Loss: 3.7859, Avg Regression Loss 1.2002, Avg Classification Loss: 2.5857
2021-05-21 23:32:23 - Epoch: 43, Step: 300/502, Avg Loss: 3.6135, Avg Regression Loss 0.8208, Avg Classification Loss: 2.7928
2021-05-21 23:32:28 - Epoch: 43, Step: 310/502, Avg Loss: 4.3468, Avg Regression Loss 1.7416, Avg Classification Loss: 2.6053
2021-05-21 23:32:32 - Epoch: 43, Step: 320/502, Avg Loss: 3.6317, Avg Regression Loss 0.9813, Avg Classification Loss: 2.6504
2021-05-21 23:32:37 - Epoch: 43, Step: 330/502, Avg Loss: 4.3672, Avg Regression Loss 1.6030, Avg Classification Loss: 2.7642
2021-05-21 23:32:42 - Epoch: 43, Step: 340/502, Avg Loss: 3.7161, Avg Regression Loss 0.9091, Avg Classification Loss: 2.8070
2021-05-21 23:32:47 - Epoch: 43, Step: 350/502, Avg Loss: 3.6273, Avg Regression Loss 1.0103, Avg Classification Loss: 2.6170
2021-05-21 23:32:52 - Epoch: 43, Step: 360/502, Avg Loss: 3.4841, Avg Regression Loss 0.8782, Avg Classification Loss: 2.6059
2021-05-21 23:32:56 - Epoch: 43, Step: 370/502, Avg Loss: 3.1975, Avg Regression Loss 0.9011, Avg Classification Loss: 2.2964
2021-05-21 23:33:01 - Epoch: 43, Step: 380/502, Avg Loss: 3.8458, Avg Regression Loss 1.2610, Avg Classification Loss: 2.5848
2021-05-21 23:33:08 - Epoch: 43, Step: 390/502, Avg Loss: 3.9350, Avg Regression Loss 1.3989, Avg Classification Loss: 2.5362
2021-05-21 23:33:13 - Epoch: 43, Step: 400/502, Avg Loss: 3.5896, Avg Regression Loss 1.0347, Avg Classification Loss: 2.5549
2021-05-21 23:33:18 - Epoch: 43, Step: 410/502, Avg Loss: 4.0080, Avg Regression Loss 1.4231, Avg Classification Loss: 2.5850
2021-05-21 23:33:23 - Epoch: 43, Step: 420/502, Avg Loss: 4.1113, Avg Regression Loss 1.2995, Avg Classification Loss: 2.8117
2021-05-21 23:33:28 - Epoch: 43, Step: 430/502, Avg Loss: 3.6246, Avg Regression Loss 0.9694, Avg Classification Loss: 2.6552
2021-05-21 23:33:34 - Epoch: 43, Step: 440/502, Avg Loss: 4.0969, Avg Regression Loss 1.4413, Avg Classification Loss: 2.6556
2021-05-21 23:33:38 - Epoch: 43, Step: 450/502, Avg Loss: 3.6310, Avg Regression Loss 1.1937, Avg Classification Loss: 2.4372
2021-05-21 23:33:43 - Epoch: 43, Step: 460/502, Avg Loss: 4.0084, Avg Regression Loss 1.2137, Avg Classification Loss: 2.7947
2021-05-21 23:33:48 - Epoch: 43, Step: 470/502, Avg Loss: 3.4656, Avg Regression Loss 0.9171, Avg Classification Loss: 2.5485
2021-05-21 23:33:53 - Epoch: 43, Step: 480/502, Avg Loss: 3.8147, Avg Regression Loss 1.1783, Avg Classification Loss: 2.6364
2021-05-21 23:33:57 - Epoch: 43, Step: 490/502, Avg Loss: 3.2080, Avg Regression Loss 0.7843, Avg Classification Loss: 2.4237
2021-05-21 23:34:03 - Epoch: 43, Step: 500/502, Avg Loss: 3.5557, Avg Regression Loss 0.9307, Avg Classification Loss: 2.6250
2021-05-21 23:35:03 - Epoch: 43, Validation Loss: 3.3032, Validation Regression Loss 0.8492, Validation Classification Loss: 2.4539
2021-05-21 23:35:04 - Saved model models/smd/mb1-ssd-Epoch-43-Loss-3.303187298822213.pth
2021-05-21 23:35:11 - Epoch: 44, Step: 10/502, Avg Loss: 4.3375, Avg Regression Loss 1.3304, Avg Classification Loss: 3.0070
2021-05-21 23:35:24 - Epoch: 44, Step: 20/502, Avg Loss: 3.9581, Avg Regression Loss 1.4387, Avg Classification Loss: 2.5194
2021-05-21 23:35:30 - Epoch: 44, Step: 30/502, Avg Loss: 4.0061, Avg Regression Loss 1.3887, Avg Classification Loss: 2.6175
2021-05-21 23:35:34 - Epoch: 44, Step: 40/502, Avg Loss: 4.2984, Avg Regression Loss 1.4161, Avg Classification Loss: 2.8824
2021-05-21 23:35:39 - Epoch: 44, Step: 50/502, Avg Loss: 3.9518, Avg Regression Loss 1.2939, Avg Classification Loss: 2.6579
2021-05-21 23:35:44 - Epoch: 44, Step: 60/502, Avg Loss: 3.6538, Avg Regression Loss 0.9505, Avg Classification Loss: 2.7034
2021-05-21 23:35:49 - Epoch: 44, Step: 70/502, Avg Loss: 4.1674, Avg Regression Loss 1.5441, Avg Classification Loss: 2.6233
2021-05-21 23:35:54 - Epoch: 44, Step: 80/502, Avg Loss: 3.4550, Avg Regression Loss 0.9735, Avg Classification Loss: 2.4815
2021-05-21 23:35:59 - Epoch: 44, Step: 90/502, Avg Loss: 4.3464, Avg Regression Loss 1.7275, Avg Classification Loss: 2.6189
2021-05-21 23:36:04 - Epoch: 44, Step: 100/502, Avg Loss: 3.2585, Avg Regression Loss 0.9508, Avg Classification Loss: 2.3077
2021-05-21 23:36:08 - Epoch: 44, Step: 110/502, Avg Loss: 3.5063, Avg Regression Loss 0.9790, Avg Classification Loss: 2.5272
2021-05-21 23:36:13 - Epoch: 44, Step: 120/502, Avg Loss: 3.6906, Avg Regression Loss 1.1093, Avg Classification Loss: 2.5813
2021-05-21 23:36:19 - Epoch: 44, Step: 130/502, Avg Loss: 3.8285, Avg Regression Loss 1.2641, Avg Classification Loss: 2.5644
2021-05-21 23:36:24 - Epoch: 44, Step: 140/502, Avg Loss: 4.3426, Avg Regression Loss 1.4405, Avg Classification Loss: 2.9022
2021-05-21 23:36:30 - Epoch: 44, Step: 150/502, Avg Loss: 4.0984, Avg Regression Loss 1.4307, Avg Classification Loss: 2.6677
2021-05-21 23:36:35 - Epoch: 44, Step: 160/502, Avg Loss: 4.3272, Avg Regression Loss 1.2633, Avg Classification Loss: 3.0639
2021-05-21 23:36:41 - Epoch: 44, Step: 170/502, Avg Loss: 4.2974, Avg Regression Loss 1.3918, Avg Classification Loss: 2.9055
2021-05-21 23:36:46 - Epoch: 44, Step: 180/502, Avg Loss: 3.8875, Avg Regression Loss 1.0686, Avg Classification Loss: 2.8190
2021-05-21 23:36:50 - Epoch: 44, Step: 190/502, Avg Loss: 4.0245, Avg Regression Loss 1.2793, Avg Classification Loss: 2.7451
2021-05-21 23:36:55 - Epoch: 44, Step: 200/502, Avg Loss: 3.4809, Avg Regression Loss 1.0082, Avg Classification Loss: 2.4726
2021-05-21 23:37:00 - Epoch: 44, Step: 210/502, Avg Loss: 3.6266, Avg Regression Loss 0.9854, Avg Classification Loss: 2.6413
2021-05-21 23:37:05 - Epoch: 44, Step: 220/502, Avg Loss: 4.1301, Avg Regression Loss 1.3190, Avg Classification Loss: 2.8112
2021-05-21 23:37:10 - Epoch: 44, Step: 230/502, Avg Loss: 3.9498, Avg Regression Loss 1.3218, Avg Classification Loss: 2.6279
2021-05-21 23:37:16 - Epoch: 44, Step: 240/502, Avg Loss: 3.9290, Avg Regression Loss 1.3846, Avg Classification Loss: 2.5444
2021-05-21 23:37:21 - Epoch: 44, Step: 250/502, Avg Loss: 3.4315, Avg Regression Loss 1.0011, Avg Classification Loss: 2.4304
2021-05-21 23:37:26 - Epoch: 44, Step: 260/502, Avg Loss: 3.6497, Avg Regression Loss 0.9443, Avg Classification Loss: 2.7055
2021-05-21 23:37:35 - Epoch: 44, Step: 270/502, Avg Loss: 4.1126, Avg Regression Loss 1.4056, Avg Classification Loss: 2.7070
2021-05-21 23:37:40 - Epoch: 44, Step: 280/502, Avg Loss: 3.7110, Avg Regression Loss 1.0899, Avg Classification Loss: 2.6211
2021-05-21 23:37:44 - Epoch: 44, Step: 290/502, Avg Loss: 3.6745, Avg Regression Loss 0.9613, Avg Classification Loss: 2.7132
2021-05-21 23:37:51 - Epoch: 44, Step: 300/502, Avg Loss: 3.7448, Avg Regression Loss 0.9331, Avg Classification Loss: 2.8117
2021-05-21 23:37:56 - Epoch: 44, Step: 310/502, Avg Loss: 3.5584, Avg Regression Loss 1.1395, Avg Classification Loss: 2.4189
2021-05-21 23:38:01 - Epoch: 44, Step: 320/502, Avg Loss: 3.9458, Avg Regression Loss 1.2836, Avg Classification Loss: 2.6622
2021-05-21 23:38:06 - Epoch: 44, Step: 330/502, Avg Loss: 3.6819, Avg Regression Loss 0.8834, Avg Classification Loss: 2.7985
2021-05-21 23:38:11 - Epoch: 44, Step: 340/502, Avg Loss: 3.5369, Avg Regression Loss 0.8379, Avg Classification Loss: 2.6990
2021-05-21 23:38:15 - Epoch: 44, Step: 350/502, Avg Loss: 3.7936, Avg Regression Loss 0.9661, Avg Classification Loss: 2.8275
2021-05-21 23:38:21 - Epoch: 44, Step: 360/502, Avg Loss: 4.0211, Avg Regression Loss 1.0892, Avg Classification Loss: 2.9318
2021-05-21 23:38:26 - Epoch: 44, Step: 370/502, Avg Loss: 3.8958, Avg Regression Loss 1.2630, Avg Classification Loss: 2.6328
2021-05-21 23:38:31 - Epoch: 44, Step: 380/502, Avg Loss: 3.9920, Avg Regression Loss 1.2271, Avg Classification Loss: 2.7649
2021-05-21 23:38:37 - Epoch: 44, Step: 390/502, Avg Loss: 4.1202, Avg Regression Loss 1.4198, Avg Classification Loss: 2.7004
2021-05-21 23:38:45 - Epoch: 44, Step: 400/502, Avg Loss: 3.9706, Avg Regression Loss 1.4064, Avg Classification Loss: 2.5642
2021-05-21 23:38:50 - Epoch: 44, Step: 410/502, Avg Loss: 3.6512, Avg Regression Loss 1.1504, Avg Classification Loss: 2.5008
2021-05-21 23:38:55 - Epoch: 44, Step: 420/502, Avg Loss: 3.6026, Avg Regression Loss 1.1067, Avg Classification Loss: 2.4960
2021-05-21 23:39:01 - Epoch: 44, Step: 430/502, Avg Loss: 3.8190, Avg Regression Loss 1.2238, Avg Classification Loss: 2.5952
2021-05-21 23:39:06 - Epoch: 44, Step: 440/502, Avg Loss: 4.2355, Avg Regression Loss 1.7457, Avg Classification Loss: 2.4897
2021-05-21 23:39:11 - Epoch: 44, Step: 450/502, Avg Loss: 3.4206, Avg Regression Loss 0.7545, Avg Classification Loss: 2.6661
2021-05-21 23:39:15 - Epoch: 44, Step: 460/502, Avg Loss: 3.5344, Avg Regression Loss 0.9597, Avg Classification Loss: 2.5747
2021-05-21 23:39:21 - Epoch: 44, Step: 470/502, Avg Loss: 3.4654, Avg Regression Loss 0.9994, Avg Classification Loss: 2.4659
2021-05-21 23:39:25 - Epoch: 44, Step: 480/502, Avg Loss: 4.1272, Avg Regression Loss 1.4602, Avg Classification Loss: 2.6670
2021-05-21 23:39:30 - Epoch: 44, Step: 490/502, Avg Loss: 4.2260, Avg Regression Loss 1.2419, Avg Classification Loss: 2.9842
2021-05-21 23:39:36 - Epoch: 44, Step: 500/502, Avg Loss: 4.0050, Avg Regression Loss 1.2226, Avg Classification Loss: 2.7824
2021-05-21 23:40:37 - Epoch: 44, Validation Loss: 3.1844, Validation Regression Loss 0.7521, Validation Classification Loss: 2.4323
2021-05-21 23:40:37 - Saved model models/smd/mb1-ssd-Epoch-44-Loss-3.1844143171709374.pth
2021-05-21 23:40:43 - Epoch: 45, Step: 10/502, Avg Loss: 4.2417, Avg Regression Loss 1.4811, Avg Classification Loss: 2.7606
2021-05-21 23:40:52 - Epoch: 45, Step: 20/502, Avg Loss: 3.8747, Avg Regression Loss 1.1061, Avg Classification Loss: 2.7686
2021-05-21 23:40:57 - Epoch: 45, Step: 30/502, Avg Loss: 4.3214, Avg Regression Loss 1.5159, Avg Classification Loss: 2.8055
2021-05-21 23:41:02 - Epoch: 45, Step: 40/502, Avg Loss: 3.7341, Avg Regression Loss 1.0514, Avg Classification Loss: 2.6827
2021-05-21 23:41:07 - Epoch: 45, Step: 50/502, Avg Loss: 4.0840, Avg Regression Loss 1.4218, Avg Classification Loss: 2.6622
2021-05-21 23:41:19 - Epoch: 45, Step: 60/502, Avg Loss: 3.6303, Avg Regression Loss 0.9039, Avg Classification Loss: 2.7264
2021-05-21 23:41:23 - Epoch: 45, Step: 70/502, Avg Loss: 3.7152, Avg Regression Loss 1.0838, Avg Classification Loss: 2.6314
2021-05-21 23:41:29 - Epoch: 45, Step: 80/502, Avg Loss: 3.7605, Avg Regression Loss 1.0794, Avg Classification Loss: 2.6810
2021-05-21 23:41:34 - Epoch: 45, Step: 90/502, Avg Loss: 4.5533, Avg Regression Loss 1.7523, Avg Classification Loss: 2.8010
2021-05-21 23:41:39 - Epoch: 45, Step: 100/502, Avg Loss: 3.6414, Avg Regression Loss 0.9841, Avg Classification Loss: 2.6573
2021-05-21 23:41:43 - Epoch: 45, Step: 110/502, Avg Loss: 2.9144, Avg Regression Loss 0.6373, Avg Classification Loss: 2.2771
2021-05-21 23:41:50 - Epoch: 45, Step: 120/502, Avg Loss: 4.3893, Avg Regression Loss 1.6108, Avg Classification Loss: 2.7784
2021-05-21 23:41:54 - Epoch: 45, Step: 130/502, Avg Loss: 3.4940, Avg Regression Loss 0.9732, Avg Classification Loss: 2.5207
2021-05-21 23:41:59 - Epoch: 45, Step: 140/502, Avg Loss: 4.2487, Avg Regression Loss 1.5327, Avg Classification Loss: 2.7160
2021-05-21 23:42:05 - Epoch: 45, Step: 150/502, Avg Loss: 3.9818, Avg Regression Loss 1.4309, Avg Classification Loss: 2.5509
2021-05-21 23:42:10 - Epoch: 45, Step: 160/502, Avg Loss: 4.9316, Avg Regression Loss 2.0506, Avg Classification Loss: 2.8810
2021-05-21 23:42:15 - Epoch: 45, Step: 170/502, Avg Loss: 3.5386, Avg Regression Loss 1.0626, Avg Classification Loss: 2.4759
2021-05-21 23:42:20 - Epoch: 45, Step: 180/502, Avg Loss: 4.3408, Avg Regression Loss 1.5089, Avg Classification Loss: 2.8319
2021-05-21 23:42:24 - Epoch: 45, Step: 190/502, Avg Loss: 3.7562, Avg Regression Loss 1.1952, Avg Classification Loss: 2.5610
2021-05-21 23:42:29 - Epoch: 45, Step: 200/502, Avg Loss: 3.8179, Avg Regression Loss 1.0254, Avg Classification Loss: 2.7925
2021-05-21 23:42:34 - Epoch: 45, Step: 210/502, Avg Loss: 4.5727, Avg Regression Loss 1.7523, Avg Classification Loss: 2.8204
2021-05-21 23:42:39 - Epoch: 45, Step: 220/502, Avg Loss: 4.2860, Avg Regression Loss 1.5255, Avg Classification Loss: 2.7605
2021-05-21 23:42:44 - Epoch: 45, Step: 230/502, Avg Loss: 4.0154, Avg Regression Loss 1.0776, Avg Classification Loss: 2.9378
2021-05-21 23:42:50 - Epoch: 45, Step: 240/502, Avg Loss: 3.9446, Avg Regression Loss 1.3613, Avg Classification Loss: 2.5833
2021-05-21 23:42:55 - Epoch: 45, Step: 250/502, Avg Loss: 3.3823, Avg Regression Loss 0.8417, Avg Classification Loss: 2.5406
2021-05-21 23:43:01 - Epoch: 45, Step: 260/502, Avg Loss: 4.2284, Avg Regression Loss 1.5022, Avg Classification Loss: 2.7262
2021-05-21 23:43:05 - Epoch: 45, Step: 270/502, Avg Loss: 3.8394, Avg Regression Loss 0.8942, Avg Classification Loss: 2.9453
2021-05-21 23:43:10 - Epoch: 45, Step: 280/502, Avg Loss: 4.1616, Avg Regression Loss 1.3528, Avg Classification Loss: 2.8088
2021-05-21 23:43:15 - Epoch: 45, Step: 290/502, Avg Loss: 3.7542, Avg Regression Loss 1.1454, Avg Classification Loss: 2.6088
2021-05-21 23:43:20 - Epoch: 45, Step: 300/502, Avg Loss: 3.7984, Avg Regression Loss 1.4693, Avg Classification Loss: 2.3290
2021-05-21 23:43:25 - Epoch: 45, Step: 310/502, Avg Loss: 3.8455, Avg Regression Loss 1.3262, Avg Classification Loss: 2.5193
2021-05-21 23:43:32 - Epoch: 45, Step: 320/502, Avg Loss: 3.1670, Avg Regression Loss 0.6945, Avg Classification Loss: 2.4724
2021-05-21 23:43:37 - Epoch: 45, Step: 330/502, Avg Loss: 4.2334, Avg Regression Loss 1.5011, Avg Classification Loss: 2.7324
2021-05-21 23:43:42 - Epoch: 45, Step: 340/502, Avg Loss: 3.3845, Avg Regression Loss 1.0736, Avg Classification Loss: 2.3108
2021-05-21 23:43:48 - Epoch: 45, Step: 350/502, Avg Loss: 4.0204, Avg Regression Loss 1.1774, Avg Classification Loss: 2.8430
2021-05-21 23:43:52 - Epoch: 45, Step: 360/502, Avg Loss: 3.6745, Avg Regression Loss 1.3225, Avg Classification Loss: 2.3520
2021-05-21 23:43:57 - Epoch: 45, Step: 370/502, Avg Loss: 3.2044, Avg Regression Loss 0.9145, Avg Classification Loss: 2.2899
2021-05-21 23:44:03 - Epoch: 45, Step: 380/502, Avg Loss: 4.1421, Avg Regression Loss 1.7156, Avg Classification Loss: 2.4266
2021-05-21 23:44:08 - Epoch: 45, Step: 390/502, Avg Loss: 3.7043, Avg Regression Loss 1.0293, Avg Classification Loss: 2.6750
2021-05-21 23:44:13 - Epoch: 45, Step: 400/502, Avg Loss: 3.6017, Avg Regression Loss 0.9464, Avg Classification Loss: 2.6553
2021-05-21 23:44:18 - Epoch: 45, Step: 410/502, Avg Loss: 3.3939, Avg Regression Loss 0.9914, Avg Classification Loss: 2.4025
2021-05-21 23:44:32 - Epoch: 45, Step: 420/502, Avg Loss: 4.0038, Avg Regression Loss 1.4727, Avg Classification Loss: 2.5311
2021-05-21 23:44:37 - Epoch: 45, Step: 430/502, Avg Loss: 4.1851, Avg Regression Loss 1.4072, Avg Classification Loss: 2.7778
2021-05-21 23:44:42 - Epoch: 45, Step: 440/502, Avg Loss: 4.1814, Avg Regression Loss 1.4706, Avg Classification Loss: 2.7108
2021-05-21 23:44:47 - Epoch: 45, Step: 450/502, Avg Loss: 3.7756, Avg Regression Loss 1.1318, Avg Classification Loss: 2.6438
2021-05-21 23:44:52 - Epoch: 45, Step: 460/502, Avg Loss: 4.5552, Avg Regression Loss 1.5408, Avg Classification Loss: 3.0144
2021-05-21 23:44:56 - Epoch: 45, Step: 470/502, Avg Loss: 4.5859, Avg Regression Loss 1.7447, Avg Classification Loss: 2.8413
2021-05-21 23:45:01 - Epoch: 45, Step: 480/502, Avg Loss: 3.3517, Avg Regression Loss 1.0754, Avg Classification Loss: 2.2763
2021-05-21 23:45:06 - Epoch: 45, Step: 490/502, Avg Loss: 4.1482, Avg Regression Loss 1.3728, Avg Classification Loss: 2.7754
2021-05-21 23:45:11 - Epoch: 45, Step: 500/502, Avg Loss: 3.6899, Avg Regression Loss 1.3572, Avg Classification Loss: 2.3327

root@MT-desktop:/jetson-inference/python/training/detection/ssd# python3 onnx_export.py --model-dir=models/smd     
Namespace(batch_size=1, height=300, input='', labels='labels.txt', model_dir='models/smd', net='ssd-mobilenet', output='', width=300)
running on device cuda:0
found best checkpoint with loss 3.184414 (models/smd/mb1-ssd-Epoch-44-Loss-3.1844143171709374.pth)
creating network:  ssd-mobilenet
num classes:       6
loading checkpoint:  models/smd/mb1-ssd-Epoch-44-Loss-3.1844143171709374.pth
exporting model to ONNX...
graph(%input_0 : Float(1:270000, 3:90000, 300:300, 300:1),
      %base_net.0.0.weight : Float(32:27, 3:9, 3:3, 3:1),
      %base_net.0.1.weight : Float(32:1),
      %base_net.0.1.bias : Float(32:1),
      %base_net.0.1.running_mean : Float(32:1),
      %base_net.0.1.running_var : Float(32:1),
      %base_net.1.0.weight : Float(32:9, 1:9, 3:3, 3:1),
      %base_net.1.1.weight : Float(32:1),
      %base_net.1.1.bias : Float(32:1),
      %base_net.1.1.running_mean : Float(32:1),
      %base_net.1.1.running_var : Float(32:1),
      %base_net.1.3.weight : Float(64:32, 32:1, 1:1, 1:1),
      %base_net.1.4.weight : Float(64:1),
      %base_net.1.4.bias : Float(64:1),
      %base_net.1.4.running_mean : Float(64:1),
      %base_net.1.4.running_var : Float(64:1),
      %base_net.2.0.weight : Float(64:9, 1:9, 3:3, 3:1),
      %base_net.2.1.weight : Float(64:1),
      %base_net.2.1.bias : Float(64:1),
      %base_net.2.1.running_mean : Float(64:1),
      %base_net.2.1.running_var : Float(64:1),
      %base_net.2.3.weight : Float(128:64, 64:1, 1:1, 1:1),
      %base_net.2.4.weight : Float(128:1),
      %base_net.2.4.bias : Float(128:1),
      %base_net.2.4.running_mean : Float(128:1),
      %base_net.2.4.running_var : Float(128:1),
      %base_net.3.0.weight : Float(128:9, 1:9, 3:3, 3:1),
      %base_net.3.1.weight : Float(128:1),
      %base_net.3.1.bias : Float(128:1),
      %base_net.3.1.running_mean : Float(128:1),
      %base_net.3.1.running_var : Float(128:1),
      %base_net.3.3.weight : Float(128:128, 128:1, 1:1, 1:1),
      %base_net.3.4.weight : Float(128:1),
      %base_net.3.4.bias : Float(128:1),
      %base_net.3.4.running_mean : Float(128:1),
      %base_net.3.4.running_var : Float(128:1),
      %base_net.4.0.weight : Float(128:9, 1:9, 3:3, 3:1),
      %base_net.4.1.weight : Float(128:1),
      %base_net.4.1.bias : Float(128:1),
      %base_net.4.1.running_mean : Float(128:1),
      %base_net.4.1.running_var : Float(128:1),
      %base_net.4.3.weight : Float(256:128, 128:1, 1:1, 1:1),
      %base_net.4.4.weight : Float(256:1),
      %base_net.4.4.bias : Float(256:1),
      %base_net.4.4.running_mean : Float(256:1),
      %base_net.4.4.running_var : Float(256:1),
      %base_net.5.0.weight : Float(256:9, 1:9, 3:3, 3:1),
      %base_net.5.1.weight : Float(256:1),
      %base_net.5.1.bias : Float(256:1),
      %base_net.5.1.running_mean : Float(256:1),
      %base_net.5.1.running_var : Float(256:1),
      %base_net.5.3.weight : Float(256:256, 256:1, 1:1, 1:1),
      %base_net.5.4.weight : Float(256:1),
      %base_net.5.4.bias : Float(256:1),
      %base_net.5.4.running_mean : Float(256:1),
      %base_net.5.4.running_var : Float(256:1),
      %base_net.6.0.weight : Float(256:9, 1:9, 3:3, 3:1),
      %base_net.6.1.weight : Float(256:1),
      %base_net.6.1.bias : Float(256:1),
      %base_net.6.1.running_mean : Float(256:1),
      %base_net.6.1.running_var : Float(256:1),
      %base_net.6.3.weight : Float(512:256, 256:1, 1:1, 1:1),
      %base_net.6.4.weight : Float(512:1),
      %base_net.6.4.bias : Float(512:1),
      %base_net.6.4.running_mean : Float(512:1),
      %base_net.6.4.running_var : Float(512:1),
      %base_net.7.0.weight : Float(512:9, 1:9, 3:3, 3:1),
      %base_net.7.1.weight : Float(512:1),
      %base_net.7.1.bias : Float(512:1),
      %base_net.7.1.running_mean : Float(512:1),
      %base_net.7.1.running_var : Float(512:1),
      %base_net.7.3.weight : Float(512:512, 512:1, 1:1, 1:1),
      %base_net.7.4.weight : Float(512:1),
      %base_net.7.4.bias : Float(512:1),
      %base_net.7.4.running_mean : Float(512:1),
      %base_net.7.4.running_var : Float(512:1),
      %base_net.8.0.weight : Float(512:9, 1:9, 3:3, 3:1),
      %base_net.8.1.weight : Float(512:1),
      %base_net.8.1.bias : Float(512:1),
      %base_net.8.1.running_mean : Float(512:1),
      %base_net.8.1.running_var : Float(512:1),
      %base_net.8.3.weight : Float(512:512, 512:1, 1:1, 1:1),
      %base_net.8.4.weight : Float(512:1),
      %base_net.8.4.bias : Float(512:1),
      %base_net.8.4.running_mean : Float(512:1),
      %base_net.8.4.running_var : Float(512:1),
      %base_net.9.0.weight : Float(512:9, 1:9, 3:3, 3:1),
      %base_net.9.1.weight : Float(512:1),
      %base_net.9.1.bias : Float(512:1),
      %base_net.9.1.running_mean : Float(512:1),
      %base_net.9.1.running_var : Float(512:1),
      %base_net.9.3.weight : Float(512:512, 512:1, 1:1, 1:1),
      %base_net.9.4.weight : Float(512:1),
      %base_net.9.4.bias : Float(512:1),
      %base_net.9.4.running_mean : Float(512:1),
      %base_net.9.4.running_var : Float(512:1),
      %base_net.10.0.weight : Float(512:9, 1:9, 3:3, 3:1),
      %base_net.10.1.weight : Float(512:1),
      %base_net.10.1.bias : Float(512:1),
      %base_net.10.1.running_mean : Float(512:1),
      %base_net.10.1.running_var : Float(512:1),
      %base_net.10.3.weight : Float(512:512, 512:1, 1:1, 1:1),
      %base_net.10.4.weight : Float(512:1),
      %base_net.10.4.bias : Float(512:1),
      %base_net.10.4.running_mean : Float(512:1),
      %base_net.10.4.running_var : Float(512:1),
      %base_net.11.0.weight : Float(512:9, 1:9, 3:3, 3:1),
      %base_net.11.1.weight : Float(512:1),
      %base_net.11.1.bias : Float(512:1),
      %base_net.11.1.running_mean : Float(512:1),
      %base_net.11.1.running_var : Float(512:1),
      %base_net.11.3.weight : Float(512:512, 512:1, 1:1, 1:1),
      %base_net.11.4.weight : Float(512:1),
      %base_net.11.4.bias : Float(512:1),
      %base_net.11.4.running_mean : Float(512:1),
      %base_net.11.4.running_var : Float(512:1),
      %base_net.12.0.weight : Float(512:9, 1:9, 3:3, 3:1),
      %base_net.12.1.weight : Float(512:1),
      %base_net.12.1.bias : Float(512:1),
      %base_net.12.1.running_mean : Float(512:1),
      %base_net.12.1.running_var : Float(512:1),
      %base_net.12.3.weight : Float(1024:512, 512:1, 1:1, 1:1),
      %base_net.12.4.weight : Float(1024:1),
      %base_net.12.4.bias : Float(1024:1),
      %base_net.12.4.running_mean : Float(1024:1),
      %base_net.12.4.running_var : Float(1024:1),
      %base_net.13.0.weight : Float(1024:9, 1:9, 3:3, 3:1),
      %base_net.13.1.weight : Float(1024:1),
      %base_net.13.1.bias : Float(1024:1),
      %base_net.13.1.running_mean : Float(1024:1),
      %base_net.13.1.running_var : Float(1024:1),
      %base_net.13.3.weight : Float(1024:1024, 1024:1, 1:1, 1:1),
      %base_net.13.4.weight : Float(1024:1),
      %base_net.13.4.bias : Float(1024:1),
      %base_net.13.4.running_mean : Float(1024:1),
      %base_net.13.4.running_var : Float(1024:1),
      %extras.0.0.weight : Float(256:1024, 1024:1, 1:1, 1:1),
      %extras.0.0.bias : Float(256:1),
      %extras.0.2.weight : Float(512:2304, 256:9, 3:3, 3:1),
      %extras.0.2.bias : Float(512:1),
      %extras.1.0.weight : Float(128:512, 512:1, 1:1, 1:1),
      %extras.1.0.bias : Float(128:1),
      %extras.1.2.weight : Float(256:1152, 128:9, 3:3, 3:1),
      %extras.1.2.bias : Float(256:1),
      %extras.2.0.weight : Float(128:256, 256:1, 1:1, 1:1),
      %extras.2.0.bias : Float(128:1),
      %extras.2.2.weight : Float(256:1152, 128:9, 3:3, 3:1),
      %extras.2.2.bias : Float(256:1),
      %extras.3.0.weight : Float(128:256, 256:1, 1:1, 1:1),
      %extras.3.0.bias : Float(128:1),
      %extras.3.2.weight : Float(256:1152, 128:9, 3:3, 3:1),
      %extras.3.2.bias : Float(256:1),
      %classification_headers.0.weight : Float(36:4608, 512:9, 3:3, 3:1),
      %classification_headers.0.bias : Float(36:1),
      %classification_headers.1.weight : Float(36:9216, 1024:9, 3:3, 3:1),
      %classification_headers.1.bias : Float(36:1),
      %classification_headers.2.weight : Float(36:4608, 512:9, 3:3, 3:1),
      %classification_headers.2.bias : Float(36:1),
      %classification_headers.3.weight : Float(36:2304, 256:9, 3:3, 3:1),
      %classification_headers.3.bias : Float(36:1),
      %classification_headers.4.weight : Float(36:2304, 256:9, 3:3, 3:1),
      %classification_headers.4.bias : Float(36:1),
      %classification_headers.5.weight : Float(36:2304, 256:9, 3:3, 3:1),
      %classification_headers.5.bias : Float(36:1),
      %regression_headers.0.weight : Float(24:4608, 512:9, 3:3, 3:1),
      %regression_headers.0.bias : Float(24:1),
      %regression_headers.1.weight : Float(24:9216, 1024:9, 3:3, 3:1),
      %regression_headers.1.bias : Float(24:1),
      %regression_headers.2.weight : Float(24:4608, 512:9, 3:3, 3:1),
      %regression_headers.2.bias : Float(24:1),
      %regression_headers.3.weight : Float(24:2304, 256:9, 3:3, 3:1),
      %regression_headers.3.bias : Float(24:1),
      %regression_headers.4.weight : Float(24:2304, 256:9, 3:3, 3:1),
      %regression_headers.4.bias : Float(24:1),
      %regression_headers.5.weight : Float(24:2304, 256:9, 3:3, 3:1),
      %regression_headers.5.bias : Float(24:1),
      %472 : Long(1:1),
      %473 : Long(1:1),
      %474 : Long(1:1),
      %475 : Long(1:1),
      %476 : Long(1:1),
      %477 : Long(1:1),
      %478 : Long(1:1),
      %479 : Long(1:1),
      %480 : Long(1:1),
      %481 : Long(1:1),
      %482 : Long(1:1),
      %483 : Long(1:1),
      %484 : Long(1:1),
      %485 : Long(1:1),
      %486 : Long(1:1),
      %487 : Long(1:1),
      %488 : Long(1:1),
      %489 : Long(1:1),
      %490 : Long(1:1),
      %491 : Long(1:1),
      %492 : Long(1:1),
      %493 : Long(1:1),
      %494 : Long(1:1),
      %495 : Long(1:1)):
  %203 : Float(1:720000, 32:22500, 150:150, 150:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%input_0, %base_net.0.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %204 : Float(1:720000, 32:22500, 150:150, 150:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%203, %base_net.0.1.weight, %base_net.0.1.bias, %base_net.0.1.running_mean, %base_net.0.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %205 : Float(1:720000, 32:22500, 150:150, 150:1) = onnx::Relu(%204) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %206 : Float(1:720000, 32:22500, 150:150, 150:1) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %base_net.1.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %207 : Float(1:720000, 32:22500, 150:150, 150:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%206, %base_net.1.1.weight, %base_net.1.1.bias, %base_net.1.1.running_mean, %base_net.1.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %208 : Float(1:720000, 32:22500, 150:150, 150:1) = onnx::Relu(%207) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %209 : Float(1:1440000, 64:22500, 150:150, 150:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%208, %base_net.1.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %210 : Float(1:1440000, 64:22500, 150:150, 150:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %base_net.1.4.weight, %base_net.1.4.bias, %base_net.1.4.running_mean, %base_net.1.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %211 : Float(1:1440000, 64:22500, 150:150, 150:1) = onnx::Relu(%210) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %212 : Float(1:360000, 64:5625, 75:75, 75:1) = onnx::Conv[dilations=[1, 1], group=64, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%211, %base_net.2.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %213 : Float(1:360000, 64:5625, 75:75, 75:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%212, %base_net.2.1.weight, %base_net.2.1.bias, %base_net.2.1.running_mean, %base_net.2.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %214 : Float(1:360000, 64:5625, 75:75, 75:1) = onnx::Relu(%213) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %215 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%214, %base_net.2.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %216 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%215, %base_net.2.4.weight, %base_net.2.4.bias, %base_net.2.4.running_mean, %base_net.2.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %217 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::Relu(%216) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %218 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::Conv[dilations=[1, 1], group=128, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%217, %base_net.3.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %219 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %base_net.3.1.weight, %base_net.3.1.bias, %base_net.3.1.running_mean, %base_net.3.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %220 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::Relu(%219) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %221 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%220, %base_net.3.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %222 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%221, %base_net.3.4.weight, %base_net.3.4.bias, %base_net.3.4.running_mean, %base_net.3.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %223 : Float(1:720000, 128:5625, 75:75, 75:1) = onnx::Relu(%222) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %224 : Float(1:184832, 128:1444, 38:38, 38:1) = onnx::Conv[dilations=[1, 1], group=128, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%223, %base_net.4.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %225 : Float(1:184832, 128:1444, 38:38, 38:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%224, %base_net.4.1.weight, %base_net.4.1.bias, %base_net.4.1.running_mean, %base_net.4.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %226 : Float(1:184832, 128:1444, 38:38, 38:1) = onnx::Relu(%225) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %227 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%226, %base_net.4.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %228 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %base_net.4.4.weight, %base_net.4.4.bias, %base_net.4.4.running_mean, %base_net.4.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %229 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::Relu(%228) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %230 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::Conv[dilations=[1, 1], group=256, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %base_net.5.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %231 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%230, %base_net.5.1.weight, %base_net.5.1.bias, %base_net.5.1.running_mean, %base_net.5.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %232 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::Relu(%231) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %233 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%232, %base_net.5.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %234 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%233, %base_net.5.4.weight, %base_net.5.4.bias, %base_net.5.4.running_mean, %base_net.5.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %235 : Float(1:369664, 256:1444, 38:38, 38:1) = onnx::Relu(%234) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %236 : Float(1:92416, 256:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=256, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%235, %base_net.6.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %237 : Float(1:92416, 256:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %base_net.6.1.weight, %base_net.6.1.bias, %base_net.6.1.running_mean, %base_net.6.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %238 : Float(1:92416, 256:361, 19:19, 19:1) = onnx::Relu(%237) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %239 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%238, %base_net.6.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %240 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%239, %base_net.6.4.weight, %base_net.6.4.bias, %base_net.6.4.running_mean, %base_net.6.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %241 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%240) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %242 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %base_net.7.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %243 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%242, %base_net.7.1.weight, %base_net.7.1.bias, %base_net.7.1.running_mean, %base_net.7.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %244 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%243) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %245 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%244, %base_net.7.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %246 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%245, %base_net.7.4.weight, %base_net.7.4.bias, %base_net.7.4.running_mean, %base_net.7.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %247 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%246) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %248 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%247, %base_net.8.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %249 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%248, %base_net.8.1.weight, %base_net.8.1.bias, %base_net.8.1.running_mean, %base_net.8.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %250 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%249) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %251 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%250, %base_net.8.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %252 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%251, %base_net.8.4.weight, %base_net.8.4.bias, %base_net.8.4.running_mean, %base_net.8.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %253 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%252) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %254 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%253, %base_net.9.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %255 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%254, %base_net.9.1.weight, %base_net.9.1.bias, %base_net.9.1.running_mean, %base_net.9.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %256 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%255) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %257 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%256, %base_net.9.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %258 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%257, %base_net.9.4.weight, %base_net.9.4.bias, %base_net.9.4.running_mean, %base_net.9.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %259 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%258) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %260 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%259, %base_net.10.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %261 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%260, %base_net.10.1.weight, %base_net.10.1.bias, %base_net.10.1.running_mean, %base_net.10.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %262 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%261) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %263 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%262, %base_net.10.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %264 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%263, %base_net.10.4.weight, %base_net.10.4.bias, %base_net.10.4.running_mean, %base_net.10.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %265 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%264) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %266 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%265, %base_net.11.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %267 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%266, %base_net.11.1.weight, %base_net.11.1.bias, %base_net.11.1.running_mean, %base_net.11.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %268 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%267) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %269 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%268, %base_net.11.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %270 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%269, %base_net.11.4.weight, %base_net.11.4.bias, %base_net.11.4.running_mean, %base_net.11.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %271 : Float(1:184832, 512:361, 19:19, 19:1) = onnx::Relu(%270) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %272 : Float(1:12996, 36:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%271, %classification_headers.0.weight, %classification_headers.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %273 : Float(1:12996, 19:684, 19:36, 36:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%272) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:102:0
  %274 : Tensor = onnx::Shape(%273)
  %275 : Tensor = onnx::Constant[value={0}]()
  %276 : Long() = onnx::Gather[axis=0](%274, %275) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %279 : Tensor = onnx::Unsqueeze[axes=[0]](%276)
  %282 : Tensor = onnx::Concat[axis=0](%279, %472, %473)
  %283 : Float(1:12996, 2166:6, 6:1) = onnx::Reshape(%273, %282) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %284 : Float(1:8664, 24:361, 19:19, 19:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%271, %regression_headers.0.weight, %regression_headers.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %285 : Float(1:8664, 19:456, 19:24, 24:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%284) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:106:0
  %286 : Tensor = onnx::Shape(%285)
  %287 : Tensor = onnx::Constant[value={0}]()
  %288 : Long() = onnx::Gather[axis=0](%286, %287) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %291 : Tensor = onnx::Unsqueeze[axes=[0]](%288)
  %294 : Tensor = onnx::Concat[axis=0](%291, %474, %475)
  %295 : Float(1:8664, 2166:4, 4:1) = onnx::Reshape(%285, %294) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %296 : Float(1:51200, 512:100, 10:10, 10:1) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%271, %base_net.12.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %297 : Float(1:51200, 512:100, 10:10, 10:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%296, %base_net.12.1.weight, %base_net.12.1.bias, %base_net.12.1.running_mean, %base_net.12.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %298 : Float(1:51200, 512:100, 10:10, 10:1) = onnx::Relu(%297) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %299 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%298, %base_net.12.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %300 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%299, %base_net.12.4.weight, %base_net.12.4.bias, %base_net.12.4.running_mean, %base_net.12.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %301 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::Relu(%300) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %302 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::Conv[dilations=[1, 1], group=1024, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%301, %base_net.13.0.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %303 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%302, %base_net.13.1.weight, %base_net.13.1.bias, %base_net.13.1.running_mean, %base_net.13.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %304 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::Relu(%303) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %305 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%304, %base_net.13.3.weight) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %306 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%305, %base_net.13.4.weight, %base_net.13.4.bias, %base_net.13.4.running_mean, %base_net.13.4.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016:0
  %307 : Float(1:102400, 1024:100, 10:10, 10:1) = onnx::Relu(%306) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0
  %308 : Float(1:3600, 36:100, 10:10, 10:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%307, %classification_headers.1.weight, %classification_headers.1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %309 : Float(1:3600, 10:360, 10:36, 36:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%308) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:102:0
  %310 : Tensor = onnx::Shape(%309)
  %311 : Tensor = onnx::Constant[value={0}]()
  %312 : Long() = onnx::Gather[axis=0](%310, %311) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %315 : Tensor = onnx::Unsqueeze[axes=[0]](%312)
  %318 : Tensor = onnx::Concat[axis=0](%315, %476, %477)
  %319 : Float(1:3600, 600:6, 6:1) = onnx::Reshape(%309, %318) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %320 : Float(1:2400, 24:100, 10:10, 10:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%307, %regression_headers.1.weight, %regression_headers.1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %321 : Float(1:2400, 10:240, 10:24, 24:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%320) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:106:0
  %322 : Tensor = onnx::Shape(%321)
  %323 : Tensor = onnx::Constant[value={0}]()
  %324 : Long() = onnx::Gather[axis=0](%322, %323) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %327 : Tensor = onnx::Unsqueeze[axes=[0]](%324)
  %330 : Tensor = onnx::Concat[axis=0](%327, %478, %479)
  %331 : Float(1:2400, 600:4, 4:1) = onnx::Reshape(%321, %330) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %332 : Float(1:25600, 256:100, 10:10, 10:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%307, %extras.0.0.weight, %extras.0.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %333 : Float(1:25600, 256:100, 10:10, 10:1) = onnx::Relu(%332) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %334 : Float(1:12800, 512:25, 5:5, 5:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%333, %extras.0.2.weight, %extras.0.2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %335 : Float(1:12800, 512:25, 5:5, 5:1) = onnx::Relu(%334) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %336 : Float(1:900, 36:25, 5:5, 5:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%335, %classification_headers.2.weight, %classification_headers.2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %337 : Float(1:900, 5:180, 5:36, 36:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%336) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:102:0
  %338 : Tensor = onnx::Shape(%337)
  %339 : Tensor = onnx::Constant[value={0}]()
  %340 : Long() = onnx::Gather[axis=0](%338, %339) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %343 : Tensor = onnx::Unsqueeze[axes=[0]](%340)
  %346 : Tensor = onnx::Concat[axis=0](%343, %480, %481)
  %347 : Float(1:900, 150:6, 6:1) = onnx::Reshape(%337, %346) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %348 : Float(1:600, 24:25, 5:5, 5:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%335, %regression_headers.2.weight, %regression_headers.2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %349 : Float(1:600, 5:120, 5:24, 24:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%348) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:106:0
  %350 : Tensor = onnx::Shape(%349)
  %351 : Tensor = onnx::Constant[value={0}]()
  %352 : Long() = onnx::Gather[axis=0](%350, %351) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %355 : Tensor = onnx::Unsqueeze[axes=[0]](%352)
  %358 : Tensor = onnx::Concat[axis=0](%355, %482, %483)
  %359 : Float(1:600, 150:4, 4:1) = onnx::Reshape(%349, %358) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %360 : Float(1:3200, 128:25, 5:5, 5:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%335, %extras.1.0.weight, %extras.1.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %361 : Float(1:3200, 128:25, 5:5, 5:1) = onnx::Relu(%360) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %362 : Float(1:2304, 256:9, 3:3, 3:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%361, %extras.1.2.weight, %extras.1.2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %363 : Float(1:2304, 256:9, 3:3, 3:1) = onnx::Relu(%362) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %364 : Float(1:324, 36:9, 3:3, 3:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%363, %classification_headers.3.weight, %classification_headers.3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %365 : Float(1:324, 3:108, 3:36, 36:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%364) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:102:0
  %366 : Tensor = onnx::Shape(%365)
  %367 : Tensor = onnx::Constant[value={0}]()
  %368 : Long() = onnx::Gather[axis=0](%366, %367) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %371 : Tensor = onnx::Unsqueeze[axes=[0]](%368)
  %374 : Tensor = onnx::Concat[axis=0](%371, %484, %485)
  %375 : Float(1:324, 54:6, 6:1) = onnx::Reshape(%365, %374) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %376 : Float(1:216, 24:9, 3:3, 3:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%363, %regression_headers.3.weight, %regression_headers.3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %377 : Float(1:216, 3:72, 3:24, 24:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%376) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:106:0
  %378 : Tensor = onnx::Shape(%377)
  %379 : Tensor = onnx::Constant[value={0}]()
  %380 : Long() = onnx::Gather[axis=0](%378, %379) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %383 : Tensor = onnx::Unsqueeze[axes=[0]](%380)
  %386 : Tensor = onnx::Concat[axis=0](%383, %486, %487)
  %387 : Float(1:216, 54:4, 4:1) = onnx::Reshape(%377, %386) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %388 : Float(1:1152, 128:9, 3:3, 3:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%363, %extras.2.0.weight, %extras.2.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %389 : Float(1:1152, 128:9, 3:3, 3:1) = onnx::Relu(%388) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %390 : Float(1:1024, 256:4, 2:2, 2:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%389, %extras.2.2.weight, %extras.2.2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %391 : Float(1:1024, 256:4, 2:2, 2:1) = onnx::Relu(%390) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %392 : Float(1:144, 36:4, 2:2, 2:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%391, %classification_headers.4.weight, %classification_headers.4.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %393 : Float(1:144, 2:72, 2:36, 36:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%392) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:102:0
  %394 : Tensor = onnx::Shape(%393)
  %395 : Tensor = onnx::Constant[value={0}]()
  %396 : Long() = onnx::Gather[axis=0](%394, %395) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %399 : Tensor = onnx::Unsqueeze[axes=[0]](%396)
  %402 : Tensor = onnx::Concat[axis=0](%399, %488, %489)
  %403 : Float(1:144, 24:6, 6:1) = onnx::Reshape(%393, %402) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %404 : Float(1:96, 24:4, 2:2, 2:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%391, %regression_headers.4.weight, %regression_headers.4.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %405 : Float(1:96, 2:48, 2:24, 24:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%404) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:106:0
  %406 : Tensor = onnx::Shape(%405)
  %407 : Tensor = onnx::Constant[value={0}]()
  %408 : Long() = onnx::Gather[axis=0](%406, %407) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %411 : Tensor = onnx::Unsqueeze[axes=[0]](%408)
  %414 : Tensor = onnx::Concat[axis=0](%411, %490, %491)
  %415 : Float(1:96, 24:4, 4:1) = onnx::Reshape(%405, %414) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %416 : Float(1:512, 128:4, 2:2, 2:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%391, %extras.3.0.weight, %extras.3.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %417 : Float(1:512, 128:4, 2:2, 2:1) = onnx::Relu(%416) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %418 : Float(1:256, 256:1, 1:1, 1:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%417, %extras.3.2.weight, %extras.3.2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %419 : Float(1:256, 256:1, 1:1, 1:1) = onnx::Relu(%418) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1119:0
  %420 : Float(1:36, 36:1, 1:1, 1:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%419, %classification_headers.5.weight, %classification_headers.5.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %421 : Float(1:36, 1:1, 1:1, 36:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%420) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:102:0
  %422 : Tensor = onnx::Shape(%421)
  %423 : Tensor = onnx::Constant[value={0}]()
  %424 : Long() = onnx::Gather[axis=0](%422, %423) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %427 : Tensor = onnx::Unsqueeze[axes=[0]](%424)
  %430 : Tensor = onnx::Concat[axis=0](%427, %492, %493)
  %431 : Float(1:36, 6:6, 6:1) = onnx::Reshape(%421, %430) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:103:0
  %432 : Float(1:24, 24:1, 1:1, 1:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%419, %regression_headers.5.weight, %regression_headers.5.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0
  %433 : Float(1:24, 1:1, 1:1, 24:1) = onnx::Transpose[perm=[0, 2, 3, 1]](%432) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:106:0
  %434 : Tensor = onnx::Shape(%433)
  %435 : Tensor = onnx::Constant[value={0}]()
  %436 : Long() = onnx::Gather[axis=0](%434, %435) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %439 : Tensor = onnx::Unsqueeze[axes=[0]](%436)
  %442 : Tensor = onnx::Concat[axis=0](%439, %494, %495)
  %443 : Float(1:24, 6:4, 4:1) = onnx::Reshape(%433, %442) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:107:0
  %444 : Float(1:18000, 3000:6, 6:1) = onnx::Concat[axis=1](%283, %319, %347, %375, %403, %431) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:87:0
  %445 : Float(1:12000, 3000:4, 4:1) = onnx::Concat[axis=1](%295, %331, %359, %387, %415, %443) # /jetson-inference/python/training/detection/ssd/vision/ssd/ssd.py:88:0
  %scores : Float(1:18000, 3000:6, 6:1) = onnx::Softmax[axis=2](%444) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1498:0
  %447 : Float(1:12000, 3000:4, 2:1) = onnx::Slice[axes=[2], ends=[2], starts=[0]](%445) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:104:0
  %448 : Float() = onnx::Constant[value={0.1}]()
  %449 : Float(1:6000, 3000:2, 2:1) = onnx::Mul(%447, %448)
  %450 : Float(1:12000, 3000:4, 2:1) = onnx::Constant[value=<Tensor>]()
  %451 : Float(1:6000, 3000:2, 2:1) = onnx::Mul(%449, %450) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:104:0
  %452 : Float(1:12000, 3000:4, 2:1) = onnx::Constant[value=<Tensor>]()
  %453 : Float(1:6000, 3000:2, 2:1) = onnx::Add(%451, %452) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:104:0
  %454 : Float(1:12000, 3000:4, 2:1) = onnx::Slice[axes=[2], ends=[9223372036854775807], starts=[2]](%445) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:105:0
  %455 : Float() = onnx::Constant[value={0.2}]()
  %456 : Float(1:6000, 3000:2, 2:1) = onnx::Mul(%454, %455)
  %457 : Float(1:6000, 3000:2, 2:1) = onnx::Exp(%456) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:105:0
  %458 : Float(1:12000, 3000:4, 2:1) = onnx::Constant[value=<Tensor>]()
  %459 : Float(1:6000, 3000:2, 2:1) = onnx::Mul(%457, %458) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:105:0
  %460 : Float(1:12000, 3000:4, 4:1) = onnx::Concat[axis=2](%453, %459) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:106:0
  %461 : Float(1:12000, 3000:4, 2:1) = onnx::Slice[axes=[2], ends=[2], starts=[0]](%460) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:208:0
  %462 : Float(1:12000, 3000:4, 2:1) = onnx::Slice[axes=[2], ends=[9223372036854775807], starts=[2]](%460) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:208:0
  %463 : Float() = onnx::Constant[value={2}]()
  %464 : Float(1:6000, 3000:2, 2:1) = onnx::Div(%462, %463)
  %465 : Float(1:6000, 3000:2, 2:1) = onnx::Sub(%461, %464) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:208:0
  %466 : Float(1:12000, 3000:4, 2:1) = onnx::Slice[axes=[2], ends=[2], starts=[0]](%460) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:209:0
  %467 : Float(1:12000, 3000:4, 2:1) = onnx::Slice[axes=[2], ends=[9223372036854775807], starts=[2]](%460) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:209:0
  %468 : Float() = onnx::Constant[value={2}]()
  %469 : Float(1:6000, 3000:2, 2:1) = onnx::Div(%467, %468)
  %470 : Float(1:6000, 3000:2, 2:1) = onnx::Add(%466, %469) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:209:0
  %boxes : Float(1:12000, 3000:4, 4:1) = onnx::Concat[axis=2](%465, %470) # /jetson-inference/python/training/detection/ssd/vision/utils/box_utils.py:209:0
  return (%scores, %boxes)

model exported to:  models/smd/ssd-mobilenet.onnx
task done, exiting program


